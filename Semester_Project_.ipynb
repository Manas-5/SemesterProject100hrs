{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data Generation"
      ],
      "metadata": {
        "id": "zg5-5XgB5J8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data generation using Clean Channel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Clean_Channel(object):\n",
        "    def __init__(self, config):\n",
        "        self.bptt = config.bptt\n",
        "        self.batch_size = config.batch_size\n",
        "        self.gen_logits()\n",
        "\n",
        "    def gen_data(self):\n",
        "        x = tf.cast(tf.random.categorical(logits=self.logits, num_samples=1), dtype='float64')\n",
        "        x = tf.reshape(x, shape=[self.batch_size, self.bptt, 1])\n",
        "        y = x\n",
        "        return x, y\n",
        "\n",
        "    def gen_logits(self):\n",
        "        p_t = 0.5 * tf.ones(shape=[self.batch_size * self.bptt, 1])\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        self.logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1))\n",
        "\n",
        "# Example usage\n",
        "class Config:\n",
        "    bptt = 10\n",
        "    batch_size = 32\n",
        "\n",
        "config = Config()\n",
        "clean_channel = Clean_Channel(config)\n",
        "x, y = clean_channel.gen_data()\n",
        "print(f\"Shape of x: {x.shape}, Shape of y: {y.shape}\")\n",
        "\n",
        "# Print 10 data samples\n",
        "for i in range(10):\n",
        "    print(f\"x[{i}]: {x[i].numpy().flatten()}, y[{i}]: {y[i].numpy().flatten()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSGNYxAO5M8T",
        "outputId": "0a4e079e-dec9-4c17-ebba-4120acf17ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (32, 10, 1), Shape of y: (32, 10, 1)\n",
            "x[0]: [0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000], y[0]: [0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000]\n",
            "x[1]: [1.000 1.000 0.000 0.000 1.000 0.000 1.000 1.000 1.000 0.000], y[1]: [1.000 1.000 0.000 0.000 1.000 0.000 1.000 1.000 1.000 0.000]\n",
            "x[2]: [0.000 1.000 0.000 0.000 1.000 0.000 1.000 0.000 0.000 0.000], y[2]: [0.000 1.000 0.000 0.000 1.000 0.000 1.000 0.000 0.000 0.000]\n",
            "x[3]: [1.000 1.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000], y[3]: [1.000 1.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000]\n",
            "x[4]: [1.000 1.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000], y[4]: [1.000 1.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000]\n",
            "x[5]: [0.000 0.000 0.000 1.000 1.000 0.000 1.000 1.000 0.000 1.000], y[5]: [0.000 0.000 0.000 1.000 1.000 0.000 1.000 1.000 0.000 1.000]\n",
            "x[6]: [1.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000], y[6]: [1.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000]\n",
            "x[7]: [1.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 0.000], y[7]: [1.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 0.000]\n",
            "x[8]: [0.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 0.000], y[8]: [0.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 0.000]\n",
            "x[9]: [0.000 1.000 0.000 1.000 0.000 0.000 1.000 0.000 0.000 0.000], y[9]: [0.000 1.000 0.000 1.000 0.000 0.000 1.000 0.000 0.000 0.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is the clean channel class, this class generates a synthetic dataset for our problem. The configuration parameters are bptt, batch size etc., which allows us to actually control the properties of the data that is being generated."
      ],
      "metadata": {
        "id": "VDFyAtaQDhlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing the shape of the dataset, a batch of sequence is generated with a probabilty of 0.5 for each element, each sequence has lenght specified by bptt(bakpropagation through time) and the number of the sequences in batch is specified by \"batch_size\"\n"
      ],
      "metadata": {
        "id": "0weNGNLBEDdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Generation using ISING Channel and its variants\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.stats import bernoulli\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config.batch_size\n",
        "        self.bptt = config.bptt\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        # self.ising_x_logits = self.gen_logits(self.p_x)\n",
        "        self.ising_x_logits = self.gen_logits(1-self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self,p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1])  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(\n",
        "            tf.concat([p_bar_t, p_t], axis=1))\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0,1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0 :\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype='float64')  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype='float64')  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            # z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype='float64')  # x_0\n",
        "            # z = tf.expand_dims(z, axis=-1)\n",
        "            # self.x = tf.math.floormod(self.x + z, 2)\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype='float64')  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype='float64')\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z,0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "\n",
        "class Ising(object):\n",
        "    def __init__(self, config):\n",
        "        self.p_enc = 1-0.4503\n",
        "        # self.p_enc = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config.batch_size\n",
        "        self.bptt = config.bptt\n",
        "        self.logits_enc = self.gen_logits(self.p_enc)\n",
        "        self.logits_ch = self.gen_logits(self.p_ch)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        # self.s_past = self.gen_ber(self.p_ch)  # gen s_0 as ber(0.5)\n",
        "        # self.s = tf.zeros(shape=[self.batch_size,1,1])\n",
        "        # self.y = self.channel_t(self.s)\n",
        "\n",
        "        # self.s = self.gen_ber(self.logits_ch)\n",
        "        # self.y = self.channel_t(tf.zeros(shape=[self.batch_size,1,1], dtype='float64'))\n",
        "        # self.change_flag = tf.equal(self.s,self.s+tf.ones_like(self.s))  # define a logical true tensor as a beginning\n",
        "        self.s_past = tf.zeros(shape=[self.batch_size,1,1],dtype='float64')\n",
        "        self.s = tf.zeros(shape=[self.batch_size,1,1],dtype='float64')\n",
        "        self.y = tf.zeros(shape=[self.batch_size,1,1],dtype='float64')\n",
        "        self.flag = tf.equal(self.s,self.s+tf.ones_like(self.s))  # set initial flag to false\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1])  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(\n",
        "            tf.concat([p_bar_t, p_t], axis=1))\n",
        "        return logits\n",
        "\n",
        "    def channel_t(self, x):\n",
        "        y_ber = self.gen_ber(self.logits_ch)  # generate ising output where x != s\n",
        "        y = tf.where(tf.equal(x,self.s), x, y_ber)\n",
        "        self.past_s = self.s\n",
        "        self.s = x\n",
        "        return y\n",
        "\n",
        "    def enc_t(self):\n",
        "        # flag_y = tf.equal(self.y, self.past_s)\n",
        "        # self.change_flag = tf.math.logical_and(flag_y, tf.math.logical_not(self.change_flag))\n",
        "        #\n",
        "        # z = self.gen_ber(self.logits_enc)\n",
        "        # x_bar = tf.math.floormod(self.s + z, 2)\n",
        "        #\n",
        "        # x = tf.where(self.change_flag, self.s, x_bar)\n",
        "\n",
        "        flag_y = tf.equal(self.s_past, self.y)  # check if y_{t-1} = s_{t-2}\n",
        "        cond = tf.math.logical_and(self.flag, flag_y)  # check the transmission condition\n",
        "        self.flag = tf.math.logical_not(cond)  # new flag val is according to cond\n",
        "        z = self.gen_ber(self.logits_enc)\n",
        "        x_new = tf.where(tf.equal(z, 0),self.s, 1-self.s )\n",
        "        # x_new = tf.math.floormod(self.s + z, 2)  # generate bitflip x for places where cond is 0\n",
        "\n",
        "        x = tf.where(cond, self.s, x_new)  # set value of x_t\n",
        "        return x\n",
        "\n",
        "    def gen_data(self):\n",
        "        x_l = []\n",
        "        y_l = []\n",
        "\n",
        "        for t in range(self.bptt):\n",
        "            x_ = self.enc_t()\n",
        "            x_l.append(x_)\n",
        "            y_l.append(self.channel_t(x_))\n",
        "\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "\n",
        "        return x,y\n",
        "\n",
        "    def gen_ber(self,logits):\n",
        "        ber = tf.expand_dims(tf.cast(tf.random.categorical(logits=logits, num_samples=1), dtype='float64'),axis=-1)\n",
        "        return ber\n",
        "\n",
        "\n",
        "class Ising_seq(object):\n",
        "    def __init__(self, config):\n",
        "        self.p_enc = 1-0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config.batch_size\n",
        "        self.bptt = config.bptt\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        self.s_past = 0\n",
        "        self.s = 0\n",
        "        self.y = 0\n",
        "        self.flag = False\n",
        "\n",
        "    def channel_t(self, x):\n",
        "        y_ber = bernoulli.rvs(self.p_ch, size=1)  # generate ising output where x != s\n",
        "        if self.s == x:\n",
        "            y = x\n",
        "        else:\n",
        "            y = y_ber\n",
        "\n",
        "        self.past_s = self.s\n",
        "        self.s = x\n",
        "        return y\n",
        "\n",
        "    def enc_t(self):\n",
        "        z = bernoulli.rvs(self.p_enc, size=1)\n",
        "        x_new = (self.s + z) % 2\n",
        "        if self.flag:\n",
        "            if self.y == self.past_s:\n",
        "                x = x_new\n",
        "                self.flag = True\n",
        "            else:\n",
        "                x = self.s\n",
        "                self.flag = False\n",
        "        else:\n",
        "            x = x_new\n",
        "            self.flag = True\n",
        "\n",
        "        return x\n",
        "\n",
        "    def gen_data(self):\n",
        "        x_b = []\n",
        "        y_b = []\n",
        "        for b in range(self.batch_size):\n",
        "            x_l = []\n",
        "            y_l = []\n",
        "            for t in range(self.bptt):\n",
        "                x_ = self.enc_t()\n",
        "                x_l.append(np.expand_dims(x_,axis=0))\n",
        "                y_l.append(np.expand_dims(self.channel_t(x_),axis=0))\n",
        "\n",
        "            x = np.concatenate(x_l, axis=1)\n",
        "            y = np.concatenate(y_l, axis=1)\n",
        "            x_b.append(np.expand_dims(x, axis=2))\n",
        "            y_b.append(np.expand_dims(y, axis=2))\n",
        "\n",
        "        x =np.concatenate(x_b, axis=0)\n",
        "        y =np.concatenate(y_b, axis=0)\n",
        "\n",
        "        return x,y\n",
        "\n",
        "\n",
        "class IsingChannel_ziv(object):\n",
        "    def __init__(self, input_shape=(1000, 1), dtype=tf.int64, **kwargs):\n",
        "        self.shape = input_shape\n",
        "        self.dtype = dtype\n",
        "        self.logits = tf.concat([0.4503 * tf.ones(shape=input_shape), (1 - 0.4503) * tf.ones(shape=input_shape)], axis=1)\n",
        "\n",
        "    def _iter_(self):\n",
        "        batch_size = self.shape[0]\n",
        "        cur_logits = tf.gather_nd(self.logits,\n",
        "                                  tf.stack((tf.range(batch_size, dtype=tf.int64), tf.squeeze(tf.cast(self.s,dtype='int64'))), axis=1))\n",
        "        cur_logits = tf.stack([cur_logits, 1 - cur_logits], axis=1)\n",
        "        new_symbol = tf.random.categorical(logits=cur_logits, num_samples=1, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # new_symbol = tf.cast(tf.expand_dims(new_symbol, axis=-1),dtype='float64')\n",
        "        #\n",
        "        x = tf.where(tf.equal(self.q, 0), self.s, new_symbol)\n",
        "        channel_noise = tf.random.uniform(shape=self.shape, minval=0, maxval=2, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # channel_noise = tf.expand_dims(channel_noise, axis=-1)\n",
        "        #\n",
        "        y = tf.where(tf.equal(channel_noise, 1), x, self.s)\n",
        "        s_plus = x\n",
        "        q_plus = tf.where(tf.equal(self.q, 1),\n",
        "                          tf.where(tf.equal(self.s, y), tf.constant(0, tf.int64), tf.constant(1, tf.int64)),\n",
        "                          tf.constant(1, tf.int64))\n",
        "        # ziv:\n",
        "        # yield x, y\n",
        "        # self.s = s_plus\n",
        "        # self.q = q_plus\n",
        "        # dor:\n",
        "        self.s = s_plus\n",
        "        self.q = q_plus\n",
        "        return [x, y]\n",
        "\n",
        "    def _call_(self):\n",
        "        self.s = tf.zeros(shape=self.shape, dtype=tf.int64)\n",
        "        self.q = tf.ones(shape=self.shape, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # self.s = tf.cast(tf.expand_dims(self.s, axis=-1),dtype='float64')\n",
        "        # self.q = tf.cast(tf.expand_dims(self.q, axis=-1), dtype='float64')\n",
        "        #\n",
        "        return self\n",
        "\n",
        "    def _gen_(self):\n",
        "        x_l = []\n",
        "        y_l = []\n",
        "        for t in range(5):\n",
        "            out = self._iter_()\n",
        "            x_l.append(out[0])\n",
        "            y_l.append(out[1])\n",
        "        x_l = tf.expand_dims(tf.concat(x_l, axis=1),axis=-1)\n",
        "        y_l = tf.expand_dims(tf.concat(y_l, axis=1),axis=-1)\n",
        "\n",
        "        return x_l,y_l\n",
        "\n",
        "class IsingChannel_state(object):\n",
        "    def __init__(self, bptt, input_shape=(1000, 1), dtype=tf.int64, **kwargs):\n",
        "        self.bptt = bptt\n",
        "        self.shape = input_shape\n",
        "        self.dtype = dtype\n",
        "        self.logits = tf.concat([0.4503 * tf.ones(shape=input_shape), (1 - 0.4503) * tf.ones(shape=input_shape)], axis=1)\n",
        "\n",
        "    def _iter_(self):\n",
        "        batch_size = self.shape[0]\n",
        "        cur_logits = tf.gather_nd(self.logits,\n",
        "                                  tf.stack((tf.range(batch_size, dtype=tf.int64), tf.squeeze(tf.cast(self.s,dtype='int64'))), axis=1))\n",
        "        cur_logits = tf.stack([cur_logits, 1 - cur_logits], axis=1)\n",
        "        new_symbol = tf.random.categorical(logits=cur_logits, num_samples=1, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # new_symbol = tf.cast(tf.expand_dims(new_symbol, axis=-1),dtype='float64')\n",
        "        #\n",
        "        x = tf.where(tf.equal(self.q, 0), self.s, new_symbol)\n",
        "        channel_noise = tf.random.uniform(shape=self.shape, minval=0, maxval=2, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # channel_noise = tf.expand_dims(channel_noise, axis=-1)\n",
        "        #\n",
        "        y = tf.where(tf.equal(channel_noise, 1), x, self.s)\n",
        "        s_plus = x\n",
        "        q_plus = tf.where(tf.equal(self.q, 1),\n",
        "                          tf.where(tf.equal(self.s, y), tf.constant(0, tf.int64), tf.constant(1, tf.int64)),\n",
        "                          tf.constant(1, tf.int64))\n",
        "        # ziv:\n",
        "        # yield x, y\n",
        "        # self.s = s_plus\n",
        "        # self.q = q_plus\n",
        "        # dor:\n",
        "        self.s = s_plus\n",
        "        self.q = q_plus\n",
        "        return [x, y]\n",
        "\n",
        "    def _call_(self):\n",
        "        self.s = tf.zeros(shape=self.shape, dtype=tf.int64)\n",
        "        self.q = tf.ones(shape=self.shape, dtype=tf.int64)\n",
        "        # dor:\n",
        "        # self.s = tf.cast(tf.expand_dims(self.s, axis=-1),dtype='float64')\n",
        "        # self.q = tf.cast(tf.expand_dims(self.q, axis=-1), dtype='float64')\n",
        "        #\n",
        "        return self\n",
        "\n",
        "    def _gen_(self):\n",
        "        x_l = []\n",
        "        y_l = []\n",
        "        for t in range(self.bptt):\n",
        "            out = self._iter_()\n",
        "            x_l.append(out[0])\n",
        "            y_l.append(out[1])\n",
        "        x_l = tf.expand_dims(tf.concat(x_l, axis=1),axis=-1)\n",
        "        y_l = tf.expand_dims(tf.concat(y_l, axis=1),axis=-1)\n",
        "\n",
        "        return x_l,y_l"
      ],
      "metadata": {
        "id": "stFLPUpr_WYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming Config class is defined somewhere with appropriate batch_size and bptt values\n",
        "class Config:\n",
        "    batch_size = 32\n",
        "    bptt = 10\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Instantiate and generate data from Ising_Data class\n",
        "ising_data = Ising_Data(config)\n",
        "x_data, y_data = ising_data.gen_data()\n",
        "print(\"Ising_Data generated x data:\", x_data.numpy().flatten())\n",
        "print(\"Ising_Data generated y data:\", y_data.numpy().flatten())\n",
        "\n",
        "# Instantiate and generate data from Ising class\n",
        "ising = Ising(config)\n",
        "x, y = ising.gen_data()\n",
        "print(\"Ising generated x data:\", x.numpy().flatten())\n",
        "print(\"Ising generated y data:\", y.numpy().flatten())\n",
        "\n",
        "# Instantiate and generate data from Ising_seq class\n",
        "ising_seq = Ising_seq(config)\n",
        "x_seq, y_seq = ising_seq.gen_data()\n",
        "print(\"Ising_seq generated x data:\", x_seq.flatten())\n",
        "print(\"Ising_seq generated y data:\", y_seq.flatten())\n",
        "\n",
        "# Instantiate and generate data from IsingChannel_ziv class\n",
        "ising_channel_ziv = IsingChannel_ziv(input_shape=(config.batch_size, 1))\n",
        "ising_channel_ziv = ising_channel_ziv._call_()\n",
        "x_ziv, y_ziv = ising_channel_ziv._gen_()\n",
        "print(\"IsingChannel_ziv generated x data:\", x_ziv.numpy().flatten())\n",
        "print(\"IsingChannel_ziv generated y data:\", y_ziv.numpy().flatten())\n",
        "\n",
        "# Instantiate and generate data from IsingChannel_state class\n",
        "ising_channel_state = IsingChannel_state(bptt=config.bptt, input_shape=(config.batch_size, 1))\n",
        "ising_channel_state = ising_channel_state._call_()\n",
        "x_state, y_state = ising_channel_state._gen_()\n",
        "print(\"IsingChannel_state generated x data:\", x_state.numpy().flatten())\n",
        "print(\"IsingChannel_state generated y data:\", y_state.numpy().flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6PbCVfd_gvD",
        "outputId": "06d051d1-d005-4ddb-b64e-2bff38bd569e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ising_Data generated x data: [1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n",
            "Ising_Data generated y data: [1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000]\n",
            "Ising generated x data: [1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000\n",
            " 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000\n",
            " 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000\n",
            " 1.000 1.000 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 0.000 0.000]\n",
            "Ising generated y data: [1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000 1.000 0.000\n",
            " 0.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000\n",
            " 0.000 1.000 1.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 1.000 1.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 1.000 1.000 0.000 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 0.000 1.000 1.000 0.000 0.000 1.000 0.000 0.000 0.000 1.000\n",
            " 1.000 1.000 0.000 0.000 0.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000\n",
            " 1.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 0.000 0.000 0.000\n",
            " 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
            " 0.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 1.000 0.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 1.000 0.000 0.000 1.000 1.000 1.000 0.000 0.000 0.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000\n",
            " 1.000 1.000 1.000 1.000 0.000 0.000 0.000 1.000 1.000 1.000 0.000 1.000\n",
            " 1.000 1.000 1.000 0.000 0.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 0.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000 1.000 1.000 1.000\n",
            " 1.000 0.000 0.000 1.000 1.000 1.000 1.000 0.000 1.000 1.000 1.000 0.000\n",
            " 1.000 1.000 0.000 1.000 1.000 1.000 0.000 0.000 0.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 1.000 1.000 1.000 0.000 0.000 0.000 1.000 1.000\n",
            " 1.000 0.000 0.000 0.000 0.000 1.000 1.000 0.000 1.000 1.000 1.000 0.000\n",
            " 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 0.000 0.000 0.000 1.000\n",
            " 1.000 0.000 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 1.000 1.000 0.000 0.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n",
            " 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000\n",
            " 1.000 1.000 1.000 0.000 0.000 1.000 1.000 0.000]\n",
            "Ising_seq generated x data: [1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0\n",
            " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1\n",
            " 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0]\n",
            "Ising_seq generated y data: [1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0]\n",
            "IsingChannel_ziv generated x data: [1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 1 1 0 0]\n",
            "IsingChannel_ziv generated y data: [1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0\n",
            " 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 1 1 0 0]\n",
            "IsingChannel_state generated x data: [1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
            " 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "IsingChannel_state generated y data: [0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
            " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ising_Data: Useful for examining more static or less varied configurations of spin states, potentially representing equilibrium states.\n",
        "2. Ising: Useful for analyzing systems with higher variability in spin states, potentially representing systems at different temperatures or under external fields.\n",
        "3. Ising_seq: Useful for studying the time evolution of spin states or sequential changes, potentially aiding in the understanding of dynamic processes within the model."
      ],
      "metadata": {
        "id": "VpIBlZuqFi8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estimating the capacity of channels with memory.**"
      ],
      "metadata": {
        "id": "r1230vfCX1w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# !pip install gym\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define the policy network\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return self.softmax(x)\n",
        "\n",
        "# Define the reinforcement learning algorithm for policy optimization\n",
        "def policy_optimization(env, policy_net, num_episodes, lr):\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    rewards = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Forward pass through the policy network to get action probabilities\n",
        "            state_tensor = torch.FloatTensor(state)\n",
        "            action_probs = policy_net(state_tensor)\n",
        "\n",
        "            # Sample an action from the action probabilities\n",
        "            action = np.random.choice(np.arange(len(action_probs)), p=action_probs.detach().numpy())\n",
        "\n",
        "            # Take the action and observe the next state and reward\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # Calculate the policy gradient loss\n",
        "            loss = -torch.log(action_probs[action]) * reward\n",
        "\n",
        "            # Backpropagate the loss and update the policy network\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Move to the next state\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}\")\n",
        "\n",
        "    # Plot rewards over time\n",
        "    plt.plot(rewards)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.title('Learning Curve')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define environment parameters\n",
        "    input_size = 4  # Example: state space dimension\n",
        "    output_size = 2  # Example: action space dimension\n",
        "    num_episodes = 100\n",
        "    learning_rate = 1e-5\n",
        "\n",
        "    # Initialize the policy network\n",
        "    policy_net = PolicyNetwork(input_size, output_size)\n",
        "\n",
        "    # Initialize the environment (replace this with your specific environment)\n",
        "    env = gym.make('CartPole-v1')\n",
        "\n",
        "    # Run the policy optimization algorithm\n",
        "    policy_optimization(env, policy_net, num_episodes, learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CFCVxGVeX1ek",
        "outputId": "7c148a5a-b213-4960-94b4-64761e7c5f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/100, Total Reward: 11.0\n",
            "Episode 2/100, Total Reward: 10.0\n",
            "Episode 3/100, Total Reward: 13.0\n",
            "Episode 4/100, Total Reward: 14.0\n",
            "Episode 5/100, Total Reward: 9.0\n",
            "Episode 6/100, Total Reward: 18.0\n",
            "Episode 7/100, Total Reward: 17.0\n",
            "Episode 8/100, Total Reward: 13.0\n",
            "Episode 9/100, Total Reward: 31.0\n",
            "Episode 10/100, Total Reward: 11.0\n",
            "Episode 11/100, Total Reward: 18.0\n",
            "Episode 12/100, Total Reward: 17.0\n",
            "Episode 13/100, Total Reward: 11.0\n",
            "Episode 14/100, Total Reward: 10.0\n",
            "Episode 15/100, Total Reward: 28.0\n",
            "Episode 16/100, Total Reward: 13.0\n",
            "Episode 17/100, Total Reward: 13.0\n",
            "Episode 18/100, Total Reward: 25.0\n",
            "Episode 19/100, Total Reward: 10.0\n",
            "Episode 20/100, Total Reward: 17.0\n",
            "Episode 21/100, Total Reward: 16.0\n",
            "Episode 22/100, Total Reward: 13.0\n",
            "Episode 23/100, Total Reward: 12.0\n",
            "Episode 24/100, Total Reward: 18.0\n",
            "Episode 25/100, Total Reward: 13.0\n",
            "Episode 26/100, Total Reward: 8.0\n",
            "Episode 27/100, Total Reward: 13.0\n",
            "Episode 28/100, Total Reward: 19.0\n",
            "Episode 29/100, Total Reward: 13.0\n",
            "Episode 30/100, Total Reward: 15.0\n",
            "Episode 31/100, Total Reward: 11.0\n",
            "Episode 32/100, Total Reward: 12.0\n",
            "Episode 33/100, Total Reward: 9.0\n",
            "Episode 34/100, Total Reward: 15.0\n",
            "Episode 35/100, Total Reward: 12.0\n",
            "Episode 36/100, Total Reward: 12.0\n",
            "Episode 37/100, Total Reward: 10.0\n",
            "Episode 38/100, Total Reward: 11.0\n",
            "Episode 39/100, Total Reward: 24.0\n",
            "Episode 40/100, Total Reward: 15.0\n",
            "Episode 41/100, Total Reward: 16.0\n",
            "Episode 42/100, Total Reward: 14.0\n",
            "Episode 43/100, Total Reward: 16.0\n",
            "Episode 44/100, Total Reward: 9.0\n",
            "Episode 45/100, Total Reward: 8.0\n",
            "Episode 46/100, Total Reward: 25.0\n",
            "Episode 47/100, Total Reward: 12.0\n",
            "Episode 48/100, Total Reward: 11.0\n",
            "Episode 49/100, Total Reward: 14.0\n",
            "Episode 50/100, Total Reward: 15.0\n",
            "Episode 51/100, Total Reward: 22.0\n",
            "Episode 52/100, Total Reward: 9.0\n",
            "Episode 53/100, Total Reward: 13.0\n",
            "Episode 54/100, Total Reward: 19.0\n",
            "Episode 55/100, Total Reward: 10.0\n",
            "Episode 56/100, Total Reward: 15.0\n",
            "Episode 57/100, Total Reward: 16.0\n",
            "Episode 58/100, Total Reward: 40.0\n",
            "Episode 59/100, Total Reward: 22.0\n",
            "Episode 60/100, Total Reward: 20.0\n",
            "Episode 61/100, Total Reward: 14.0\n",
            "Episode 62/100, Total Reward: 12.0\n",
            "Episode 63/100, Total Reward: 11.0\n",
            "Episode 64/100, Total Reward: 22.0\n",
            "Episode 65/100, Total Reward: 9.0\n",
            "Episode 66/100, Total Reward: 11.0\n",
            "Episode 67/100, Total Reward: 17.0\n",
            "Episode 68/100, Total Reward: 19.0\n",
            "Episode 69/100, Total Reward: 9.0\n",
            "Episode 70/100, Total Reward: 11.0\n",
            "Episode 71/100, Total Reward: 26.0\n",
            "Episode 72/100, Total Reward: 9.0\n",
            "Episode 73/100, Total Reward: 12.0\n",
            "Episode 74/100, Total Reward: 23.0\n",
            "Episode 75/100, Total Reward: 11.0\n",
            "Episode 76/100, Total Reward: 10.0\n",
            "Episode 77/100, Total Reward: 12.0\n",
            "Episode 78/100, Total Reward: 27.0\n",
            "Episode 79/100, Total Reward: 14.0\n",
            "Episode 80/100, Total Reward: 23.0\n",
            "Episode 81/100, Total Reward: 18.0\n",
            "Episode 82/100, Total Reward: 13.0\n",
            "Episode 83/100, Total Reward: 11.0\n",
            "Episode 84/100, Total Reward: 14.0\n",
            "Episode 85/100, Total Reward: 12.0\n",
            "Episode 86/100, Total Reward: 24.0\n",
            "Episode 87/100, Total Reward: 18.0\n",
            "Episode 88/100, Total Reward: 15.0\n",
            "Episode 89/100, Total Reward: 18.0\n",
            "Episode 90/100, Total Reward: 15.0\n",
            "Episode 91/100, Total Reward: 15.0\n",
            "Episode 92/100, Total Reward: 37.0\n",
            "Episode 93/100, Total Reward: 9.0\n",
            "Episode 94/100, Total Reward: 37.0\n",
            "Episode 95/100, Total Reward: 12.0\n",
            "Episode 96/100, Total Reward: 12.0\n",
            "Episode 97/100, Total Reward: 18.0\n",
            "Episode 98/100, Total Reward: 12.0\n",
            "Episode 99/100, Total Reward: 15.0\n",
            "Episode 100/100, Total Reward: 16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def simple_lstm_model(input_shape):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(10, return_sequences=True))\n",
        "    model.add(Dense(1))\n",
        "    return model\n",
        "\n",
        "config = {\n",
        "    'batch_size': 10,\n",
        "    'bptt': 6\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the simplified model\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "simple_model = simple_lstm_model(input_shape)\n",
        "\n",
        "# Compile the simplified model with a simple loss function\n",
        "simple_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Example training step (assuming x_y_combined as input and y as target)\n",
        "simple_model.fit(x_y_combined, y, epochs=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyEcDnK1oUkL",
        "outputId": "0e7db83a-7700-4fc3-ef64-36b02c09e8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2331\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2274\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2217\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2162\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2108\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2055\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2002\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1951\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1900\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1851\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1802\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1755\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1708\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1662\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1618\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1574\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1531\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1489\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1449\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1409\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1370\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1333\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1296\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1261\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1226\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1193\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1161\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1130\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1099\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1070\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1042\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1015\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0989\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0964\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0940\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0917\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0895\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0873\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0853\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0833\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0814\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0796\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0779\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0762\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0746\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0731\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0716\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0702\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0688\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0675\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0663\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0651\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0639\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0628\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0618\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0607\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0598\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0589\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0580\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0571\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0563\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0555\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0548\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0541\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0534\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0527\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0521\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0515\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0509\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0504\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0499\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0494\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0489\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0485\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0480\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0476\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0472\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0469\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0465\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0462\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0458\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0455\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0452\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0449\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0446\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0443\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0441\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0438\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0436\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0433\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0431\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0429\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0426\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0424\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0422\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0420\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0418\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0416\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0414\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0412\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0410\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0408\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0406\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0404\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0402\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0400\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0398\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0396\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0394\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0392\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0390\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0388\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0386\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0385\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0383\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0381\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0379\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0377\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0375\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0374\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0372\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0370\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0368\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0366\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0365\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0363\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0361\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0359\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0358\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0356\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0354\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0352\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0351\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0349\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0347\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0346\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0344\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0342\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0341\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0339\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0337\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0336\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0334\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0333\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0331\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0329\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0328\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0326\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0325\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0323\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0321\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0320\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0318\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0317\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0315\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0314\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0312\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0311\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0309\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0308\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0306\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0305\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0303\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0302\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0300\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0299\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0297\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0296\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0295\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0293\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0292\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0290\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0289\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0287\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0286\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0285\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0283\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0282\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0281\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0279\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0278\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0276\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0275\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0274\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0272\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0271\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0270\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0268\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0267\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0266\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0264\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0263\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0262\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0261\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0259\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0258\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0257\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0255\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0254\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0253\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f20eb3beaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "class Model_loss(tf.keras.losses.Loss):\n",
        "    def __init__(self, subtract=None, name='model_loss', **kwargs):\n",
        "        super(Model_loss, self).__init__(name=name, reduction='none')\n",
        "        self.subtract = subtract\n",
        "        self.loss_fn = {\"y\": DV_Loss(\"y\"), \"xy\": DV_Loss(\"xy\")}\n",
        "\n",
        "    def call(self, t_y, t_xy, **kwargs):\n",
        "        loss_y = self.loss_fn[\"y\"](t_y[0], t_y[1])\n",
        "        loss_xy = self.loss_fn[\"xy\"](t_xy[0], t_xy[1])\n",
        "        if self.subtract is None:  # original DV case - to train each statistics network\n",
        "            return tf.stack([loss_y, loss_xy], axis=0)\n",
        "        else:  # encoder case - the difference is the loss\n",
        "            return loss_xy - loss_y\n",
        "\n",
        "class DV_Loss(tf.keras.losses.Loss):\n",
        "    def __init__(self, name='dv_loss'):\n",
        "        super(DV_Loss, self).__init__(name=name, reduction='none')\n",
        "\n",
        "    def call(self, t1, t2, **kwargs):\n",
        "        N = tf.cast(tf.reduce_prod(t1.shape[:-1]), tf.float32)\n",
        "        N_ref = tf.cast(tf.reduce_prod(t2.shape[:-1]), tf.float32)\n",
        "        loss_t = K.sum(t1 / (N + 1e-5))  # Add small epsilon for numerical stability\n",
        "        loss_et = K.sum(t2 / (N_ref + 1e-5))  # Add small epsilon for numerical stability\n",
        "\n",
        "        print(f\"loss_t: {loss_t}, loss_et: {loss_et}\")\n",
        "\n",
        "        loss = -(loss_t - K.log(loss_et + 1e-10))  # Add small epsilon for numerical stability\n",
        "\n",
        "        print(f\"Final loss: {loss}\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.00001,  # Further reduced learning rate\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Initialize the custom loss function\n",
        "loss_fn = Model_loss()\n",
        "\n",
        "# Compile the more complex model with the custom loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "\n",
        "# Example training step with learning rate scheduler\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=200, callbacks=[callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0af-5bdmTASN",
        "outputId": "8d41c043-1b7f-4606-c460-4eb09e79228d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/200\n",
            "loss_t: Tensor(\"model_loss/y/Sum:0\", shape=(), dtype=float32), loss_et: Tensor(\"model_loss/y/Sum_1:0\", shape=(), dtype=float32)\n",
            "Final loss: Tensor(\"model_loss/y/Neg:0\", shape=(), dtype=float32)\n",
            "loss_t: Tensor(\"model_loss/xy/Sum:0\", shape=(), dtype=float32), loss_et: Tensor(\"model_loss/xy/Sum_1:0\", shape=(), dtype=float32)\n",
            "Final loss: Tensor(\"model_loss/xy/Neg:0\", shape=(), dtype=float32)\n",
            "loss_t: Tensor(\"model_loss/y/Sum:0\", shape=(), dtype=float32), loss_et: Tensor(\"model_loss/y/Sum_1:0\", shape=(), dtype=float32)\n",
            "Final loss: Tensor(\"model_loss/y/Neg:0\", shape=(), dtype=float32)\n",
            "loss_t: Tensor(\"model_loss/xy/Sum:0\", shape=(), dtype=float32), loss_et: Tensor(\"model_loss/xy/Sum_1:0\", shape=(), dtype=float32)\n",
            "Final loss: Tensor(\"model_loss/xy/Neg:0\", shape=(), dtype=float32)\n",
            "1/1 [==============================] - 4s 4s/step - loss: -2.7661 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -13.7785 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.7676 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.7683 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.2691 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.7698 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.7706 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.2824 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -2.2721 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.2837 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -14.2843 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.7742 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.2749 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.7756 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.2866 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.7769 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.7776 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -14.2884 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.7789 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.7796 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -14.2902 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.7809 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.7815 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.2918 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.7827 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.7833 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.2933 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -13.7939 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -13.7945 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.2857 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.7863 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.7869 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.2874 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.2880 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.2974 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -13.7979 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -2.7896 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.2902 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.7907 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.7913 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.2919 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.7924 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3012 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.7939 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -13.8025 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.7949 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.2955 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -13.8039 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -2.2965 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904899762754212e-06.\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.2970 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3051 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.7979 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.7983 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.7988 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.2993 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.2998 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8002 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -2.3007 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3083 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314409827406053e-06.\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3087 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.3021 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3025 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8028 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8033 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8037 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8041 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.3112 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8049 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8054 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.782968926519971e-06.\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -14.3122 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8062 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3129 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3070 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3135 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8077 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.3142 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3085 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.8088 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -13.8152 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8095 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3100 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3161 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.3106 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3110 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8112 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3173 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.3120 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.3123 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8126 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.874204867315711e-06.\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8130 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3187 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.3137 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.3140 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3143 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8145 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8148 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3152 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3206 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -14.3209 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867845442931865e-06.\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3211 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.3164 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3167 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8169 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3173 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8175 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -13.8227 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3228 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3184 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3187 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138106171718391e-06.\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8189 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8191 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8194 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -13.8243 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8199 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3246 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3205 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8207 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8209 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3213 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295575010183e-06.\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8214 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8217 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8219 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3222 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8224 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3227 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8229 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.3271 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3273 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.3237 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418659561182724e-06.\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3277 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3241 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3243 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -14.3282 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.3247 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8248 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -2.8250 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -2.8252 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -2.3256 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -14.3293 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876794218973373e-06.\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -2.3260 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -13.8297 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -2.8263 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: -13.8300 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -2.8266 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -14.3303 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -2.8270 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -2.8272 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -2.3275 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: -2.3277 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -2.8277 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -2.8279 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -2.3282 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -13.8316 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3285 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8286 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3319 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8289 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -14.3322 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8293 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-06.\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8295 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8296 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3299 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -14.3329 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8301 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -13.8333 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8304 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8305 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8307 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8308 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.6677181747581927e-06.\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -13.8339 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3312 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8313 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8314 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.8315 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8317 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -13.8346 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -14.3347 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8321 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3349 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009463368187425e-06.\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8324 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.3326 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -14.3352 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3353 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -13.8355 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -14.3355 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.8331 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.3333 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.8334 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8335 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508517440641298e-06.\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -14.3361 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.3338 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -13.8364 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8339 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -13.8366 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.8341 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.8343 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8344 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8345 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8346 - lr: 1.3509e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f21a86bd810>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Initialize the LossHistory callback\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Include the LossHistory callback in the callbacks list\n",
        "callbacks.append(loss_history)\n",
        "\n",
        "# Fit the model with the callbacks\n",
        "history = complex_model_v3.fit(x_y_combined, y, epochs=200, callbacks=callbacks)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1aZ-4ijHW9RU",
        "outputId": "9fe5be0c-6db3-4c24-806b-fbcea2f804af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3370 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.3349 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.8349 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.8350 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -14.3374 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -13.8376 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -13.8377 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.3356 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8356 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3358 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 1.2157666105849786e-06.\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -14.3380 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3381 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3382 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.8361 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8362 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.8363 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8364 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.8365 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.3367 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -14.3388 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 1.0941899290628499e-06.\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8368 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -14.3389 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -14.3390 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -14.3391 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -2.8372 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -2.3374 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8374 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -2.3376 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -2.8375 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8376 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 9.847708952293033e-07.\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -14.3396 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.8378 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.3380 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3399 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -2.3382 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8381 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -14.3401 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8383 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3402 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3386 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 8.862937647791114e-07.\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8385 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8386 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8387 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8388 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3406 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8389 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -14.3407 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3392 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.3392 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.3393 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 7.976643985330156e-07.\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8393 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.3410 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8394 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3396 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8396 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3397 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8397 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -13.8415 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -13.8415 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -14.3415 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8400 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8400 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8401 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.8401 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -2.8402 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -14.3418 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -2.8403 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -2.8404 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -2.8404 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -2.3406 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 6.46108139790158e-07.\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -13.8422 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8406 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.8407 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8407 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -2.3409 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8408 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8409 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -2.3411 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -2.3411 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8411 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 5.81497346274773e-07.\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3425 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8412 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8412 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -2.8413 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.3414 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3415 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3415 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3428 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -14.3429 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3417 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8416 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8417 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3430 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -13.8432 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3419 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3431 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.8419 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8419 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3421 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8420 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 4.710128735041508e-07.\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3433 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8421 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8422 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8422 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.3423 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3435 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3424 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8424 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -14.3436 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3436 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 4.23911581037828e-07.\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3426 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8425 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8425 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -14.3438 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8426 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -2.8426 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3428 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3428 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3439 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3439 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 3.8152042804995293e-07.\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -2.3429 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.3430 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8429 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8429 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8430 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -14.3441 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8430 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8431 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3442 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.3432 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 3.433683929188192e-07.\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.3433 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -14.3443 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8432 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8432 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3443 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -13.8445 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8433 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.8434 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -2.8434 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -13.8446 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 3.090315459530757e-07.\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -2.8434 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -14.3445 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -14.3445 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8435 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.8435 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8436 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8436 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8436 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -2.8436 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8437 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.78128393915722e-07.\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3447 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3438 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8437 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -2.3439 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8438 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: -2.3439 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -14.3448 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8439 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8439 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8439 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 2.5031555708210366e-07.\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8439 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -2.8440 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -14.3449 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8440 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -2.8440 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8440 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8441 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.8441 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -14.3451 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -14.3451 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 2.2528400904775482e-07.\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8442 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.3443 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8442 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8442 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.3443 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8442 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8443 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3452 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8443 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8443 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.027556107009332e-07.\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -14.3453 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -2.8444 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -2.3445 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -2.8444 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.8444 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -2.3445 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.3446 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3454 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8445 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -2.8445 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.8248005346777065e-07.\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -14.3454 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -13.8455 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -2.3447 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -13.8456 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -14.3455 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -2.8446 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -2.3447 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.8446 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -2.3448 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -2.3448 - lr: 1.8248e-07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAHdCAYAAAB7UI9KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOx9d7wkRdX20zM37717N+dlI7DsEgVRRCQLgihBET6VYH4xg4IZMCEqghEFEV/BACKCkvOrIDlKDpsDm/fu3b13b5jp74+Z7qk6dU51Vc/sbKDP7wd7Z6YrdHV11annPOecIAzDEJlkkkkmmWSSSSaZbNOS29IdyCSTTDLJJJNMMsmkesmUukwyySSTTDLJJJPtQDKlLpNMMskkk0wyyWQ7kEypyySTTDLJJJNMMtkOJFPqMskkk0wyySSTTLYDyZS6TDLJJJNMMskkk+1AMqUuk0wyySSTTDLJZDuQTKnLJJNMMskkk0wy2Q4kU+oyySSTTDLJJJNMtgPJlLpMMqmhnHbaaZg6dWqqsueddx6CIKhthzJJJffddx+CIMB99923pbuy2WTq1Kk47bTTtnQ3MskkkxpKptRl8oaQIAic/tueN3GbnHbaaWhvb9/S3djm5Pe//z2CIMBjjz22pbuyTQl974YOHYoDDzwQN998c+o6//SnP+GSSy6pXSczyWQblIYt3YFMMqmHXHXVVdrnP/zhD7jzzjuN73fZZZeq2rn88stRLBZTlf3GN76Br3zlK1W1n0kmrvLSSy8hl9ty5/rDDz8cp5xyCsIwxIIFC3DppZfimGOOwa233oojjjjCu74//elPePbZZ/GFL3yh9p3NJJNtRDKlLpM3hHzoQx/SPj/00EO48847je+p9PT0oK2tzbmdxsbGVP0DgIaGBjQ0ZK9kJv4yODiIYrGIpqYm5zLNzc2bsUfJstNOO2nv3wknnIDZs2fjpz/9aSqlLpNMMsnMr5lkEstBBx2EXXfdFY8//jje8Y53oK2tDV/72tcAADfeeCOOPvpoTJgwAc3NzZgxYwa+853voFAoaHVQTt38+fMRBAF+/OMf47LLLsOMGTPQ3NyMN7/5zXj00Ue1shynLggCfOYzn8ENN9yAXXfdFc3NzZgzZw5uu+02o//33Xcf9tlnH7S0tGDGjBn4zW9+U3Oe3l//+lfsvffeaG1txahRo/ChD30IS5Ys0a55/fXXcfrpp2PSpElobm7G+PHj8d73vhfz58+Pr3nsscdwxBFHYNSoUWhtbcW0adPwkY98JLF91+cQPcvnn38eBx98MNra2jBx4kT88Ic/NOpcvHgxjj32WAwZMgRjxozBF7/4RfT19aUbIEGWLFmCj3zkIxg7dmz8DH/3u99p1/T39+Nb3/oW9t57b3R2dmLIkCE44IADcO+992rXqXPqkksuiefU888/Hz/vV199FaeddhqGDRuGzs5OnH766ejp6dHqoZy6yJT8wAMP4Mwzz8To0aMxZMgQHHfccVi5cqVWtlgs4rzzzsOECRPQ1taGgw8+GM8//3xVPL1ddtkFo0aNwmuvvaZ97/LMDzroINx8881YsGBBbNJV38O+vj6ce+65mDlzJpqbmzF58mScffbZNX/OmWSypSWDBTLJRJHVq1fjXe96F0466SR86EMfwtixYwGUNrz29naceeaZaG9vxz333INvfetbWL9+PX70ox8l1vunP/0J3d3d+OQnP4kgCPDDH/4Qxx9/PObOnZuI7t1///24/vrrccYZZ6CjowM/+9nPcMIJJ2DhwoUYOXIkAODJJ5/EkUceifHjx+P8889HoVDAt7/9bYwePbr6QSnL73//e5x++ul485vfjAsuuADLly/HT3/6UzzwwAN48sknMWzYMAAlxOW5557DZz/7WUydOhUrVqzAnXfeiYULF8af3/nOd2L06NH4yle+gmHDhmH+/Pm4/vrrnfrg+hzWrl2LI488EscffzxOPPFEXHfddTjnnHOw22674V3vehcAoLe3F4ceeigWLlyIz33uc5gwYQKuuuoq3HPPPTUbt+XLl+Otb31rrKCPHj0at956Kz760Y9i/fr1sblw/fr1+O1vf4uTTz4ZH//4x9Hd3Y0rrrgCRxxxBB555BHsueeeWr1XXnklNm3ahE984hNobm7GiBEj4t9OPPFETJs2DRdccAGeeOIJ/Pa3v8WYMWNw4YUXJvb3s5/9LIYPH45zzz0X8+fPxyWXXILPfOYzuOaaa+JrvvrVr+KHP/whjjnmGBxxxBF4+umnccQRR2DTpk2px6mrqwtr167FjBkztO9dnvnXv/51dHV1YfHixbj44osBIOaIFotFvOc978H999+PT3ziE9hll13w3//+FxdffDFefvll3HDDDan7nEkmW52EmWTyBpRPf/rTIZ3+Bx54YAgg/PWvf21c39PTY3z3yU9+Mmxraws3bdoUf3fqqaeGU6ZMiT/PmzcvBBCOHDkyXLNmTfz9jTfeGAII//nPf8bfnXvuuUafAIRNTU3hq6++Gn/39NNPhwDCn//85/F3xxxzTNjW1hYuWbIk/u6VV14JGxoajDo5OfXUU8MhQ4aIv/f394djxowJd91117C3tzf+/qabbgoBhN/61rfCMAzDtWvXhgDCH/3oR2Jdf//730MA4aOPPprYLyquzyF6ln/4wx/i7/r6+sJx48aFJ5xwQvzdJZdcEgIIr7322vi7jRs3hjNnzgwBhPfee6+1P1deeWXivXz0ox8Nx48fH65atUr7/qSTTgo7OzvjexocHAz7+vq0a9auXRuOHTs2/MhHPhJ/F82poUOHhitWrNCuj+aQen0YhuFxxx0Xjhw5UvtuypQp4amnnmrcy2GHHRYWi8X4+y9+8YthPp8P161bF4ZhGL7++uthQ0NDeOyxx2r1nXfeeSEArU5JAIQf/ehHw5UrV4YrVqwIH3vssfDII49k547rMz/66KO1dy+Sq666KszlcuG///1v7ftf//rXIYDwgQceSOxvJplsK5KZXzPJRJHm5macfvrpxvetra3x393d3Vi1ahUOOOAA9PT04MUXX0ys9wMf+ACGDx8efz7ggAMAAHPnzk0se9hhh2noxe67746hQ4fGZQuFAu666y4ce+yxmDBhQnzdzJkzY0SqWnnsscewYsUKnHHGGWhpaYm/P/roozFr1qzYa7G1tRVNTU247777sHbtWrauCNG76aabMDAw4NUPn+fQ3t6ucbaampqw7777amN+yy23YPz48Xjf+94Xf9fW1oZPfOITXv2SJAxD/O1vf8MxxxyDMAyxatWq+L8jjjgCXV1deOKJJwAA+Xw+5sQVi0WsWbMGg4OD2GeffeJrVDnhhBNEJPZTn/qU9vmAAw7A6tWrsX79+sQ+f+ITn9BM9gcccAAKhQIWLFgAALj77rsxODiIM844Qyv32c9+NrFuVa644gqMHj0aY8aMwT777IO7774bZ599Ns4880ztumrfvb/+9a/YZZddMGvWLG38DznkEAAwzNuZZLItS2Z+zSQTRSZOnMiSzZ977jl84xvfwD333GNsjF1dXYn17rDDDtrnSMGTFB9b2ah8VHbFihXo7e3FzJkzjeu479JItKHvvPPOxm+zZs3C/fffD6CkFF944YU466yzMHbsWLz1rW/Fu9/9bpxyyikYN24cAODAAw/ECSecgPPPPx8XX3wxDjroIBx77LH4f//v/yWS932ew6RJkww+4fDhw/HMM89o9zVz5kzjOu4+08jKlSuxbt06XHbZZbjsssvYa1asWBH//b//+7+46KKL8OKLL2oK77Rp04xy3HeR2Obb0KFDrX1OmqvRXKBza8SIEdrBJUne+9734jOf+Qz6+/vx6KOP4vvf/z56enoMj9xq371XXnkFL7zwgqgAq+OfSXXy8NzVuOxfc/HfJV1Y0d2H33x4bxwxZ9xmbfP1rk34wa0v4L6XV6K3v4CpI4fgR+/fHbtPGrZZ291aJVPqMslEERUViGTdunU48MADMXToUHz729/GjBkz0NLSgieeeALnnHOOUwiTfD7Pfh+G4WYtuyXkC1/4Ao455hjccMMNuP322/HNb34TF1xwAe655x7stddeCIIA1113HR566CH885//xO23346PfOQjuOiii/DQQw+J8fJ8n8PWMG5Rnz70oQ/h1FNPZa/ZfffdAQBXX301TjvtNBx77LH48pe/jDFjxiCfz+OCCy4wnAcAfq5Gsi3Mt0mTJuGwww4DABx11FEYNWoUPvOZz+Dggw/G8ccfD6A2716xWMRuu+2Gn/zkJ+zvkydPrt1NvcGlZ6CAXcYPxfv3mYxPXf34Zm+vq2cAJ1z6H+w3YyR+f/q+GDmkCfNWbURna/ooBNu6ZEpdJpkkyH333YfVq1fj+uuvxzve8Y74+3nz5m3BXlVkzJgxaGlpwauvvmr8xn2XRqZMmQKgFNssMltF8tJLL8W/RzJjxgycddZZOOuss/DKK69gzz33xEUXXYSrr746vuatb30r3vrWt+J73/se/vSnP+GDH/wg/vKXv+BjH/sY24fN8RymTJmCZ599FmEYamjdSy+9lLpOVUaPHo2Ojg4UCoVYgZHkuuuuw/Tp03H99ddrfTn33HNr0pdaSfSsX331VQ0tXL16tRPyLMknP/lJXHzxxfjGN76B4447Lg4G7vrMJS/vGTNm4Omnn8ahhx6aZWzZzHLwzmNw8M5jxN/7Bgv48e0v4R9PL8X63kHsNK4DXzlyFvabMTJVe5f+32uYMKwFP37/HvF3k0e4h6DaHiXj1GWSSYJEyIWKVPT39+NXv/rVluqSJvl8HocddhhuuOEGLF26NP7+1Vdfxa233lqTNvbZZx+MGTMGv/71r7UwELfeeiteeOEFHH300QBKcf2oB+SMGTPQ0dERl1u7dq2B+kSenbYQE5vjORx11FFYunQprrvuuvi7np4e0VTqK/l8HieccAL+9re/4dlnnzV+V0OFcPf38MMP48EHH6xJX2olhx56KBoaGnDppZdq3//iF7+oqt6GhgacddZZeOGFF3DjjTcC8HvmQ4YMYc2xJ554IpYsWYLLL7/c+K23txcbN26sqt+ZuMu5Nz6HJxauw89PfhNu+8IBOHq3cTj1ykcwb1W6Z3DXC8ux28RhOOOPj2Pv79yJo376b/z5kYU17vW2JRlSl0kmCfK2t70Nw4cPx6mnnorPfe5zCIIAV1111VZl/jzvvPNwxx13YP/998f//M//oFAo4Be/+AV23XVXPPXUU051DAwM4Lvf/a7x/YgRI3DGGWfgwgsvxOmnn44DDzwQJ598chzSZOrUqfjiF78IAHj55Zdx6KGH4sQTT8Ts2bPR0NCAv//971i+fDlOOukkACXe2K9+9Sscd9xxmDFjBrq7u3H55Zdj6NChOOqoo8T+bY7n8PGPfxy/+MUvcMopp+Dxxx/H+PHjcdVVV3kFnAaA3/3ud2zswM9//vP4wQ9+gHvvvRdvectb8PGPfxyzZ8/GmjVr8MQTT+Cuu+7CmjVrAADvfve7cf311+O4447D0UcfjXnz5uHXv/41Zs+ejQ0bNqS+x1rL2LFj8fnPfx4XXXQR3vOe9+DII4/E008/jVtvvRWjRo2qCg077bTT8K1vfQsXXnghjj32WK9nvvfee+Oaa67BmWeeiTe/+c1ob2/HMcccgw9/+MO49tpr8alPfQr33nsv9t9/fxQKBbz44ou49tprcfvtt2OfffapZkgycZAl63rx18cX4z9fOQRjh5acrT7xjhn4v5dX4q+PLcLZR87yrnPhmh5c/fACfOzt03DGQTPxzOIunPeP59CYz+F9e0+q9S1sE5IpdZlkkiAjR47ETTfdhLPOOgvf+MY3MHz4cHzoQx/CoYceutVEvt97771x66234ktf+hK++c1vYvLkyfj2t7+NF154wclDECghIN/85jeN72fMmIEzzjgDp512Gtra2vCDH/wA55xzThyY9sILL4w9WidPnoyTTz4Zd999N6666io0NDRg1qxZuPbaa3HCCScAKDlKPPLII/jLX/6C5cuXo7OzE/vuuy/++Mc/Wsn/m+M5tLW14e6778ZnP/tZ/PznP0dbWxs++MEP4l3veheOPPJI53ooahXJaaedhkmTJuGRRx7Bt7/9bVx//fX41a9+hZEjR2LOnDla3LjTTjsNr7/+On7zm9/g9ttvx+zZs3H11Vfjr3/961aXk/jCCy9EW1sbLr/8ctx1113Yb7/9cMcdd+Dtb3+75h3tK62trfjMZz6D8847D/fddx8OOugg52d+xhln4KmnnsKVV16Jiy++GFOmTMExxxyDXC6HG264ARdffDH+8Ic/4O9//zva2towffp0fP7zn8dOO+1U7XBk4iAvvb4ehWKIg398n/Z9/2ARw9pKzmmvrtiAw37yf9Z6PnXgDHzlXSUFMAxD7DaxM1YId53YiZeXd+OPDy94wyp1Qbg1wQ2ZZJJJTeXYY4/Fc889h1deeWVLdyWT7VzWrVuH4cOH47vf/S6+/vWvb+nuZLKFZepXbta8X//59FJ84ZqncMcX34E8QXPbmvMY09GC/sEiFq7p4aqLZXhbI0a2l7zk9//BPXj7zFG48H27x79f9dAC/OKeV/Dw1+wc1u1VMqQuk0y2E+nt7dU8Il955RXccsstotdlJpmkFTrXAOCSSy4BUErZlUkmVOZMGIpCMcTqDf3Yd9oI9pqmhhxmjuG93znZe8pwzF2lUxPmrdyIicNkz/DtXTKlLpNMthOZPn06TjvtNEyfPh0LFizApZdeiqamJpx99tlbumuZbGdyzTXX4Pe//z2OOuootLe34/7778ef//xnvPOd78T++++/pbuXyRaSjX2DmL+64vSwaE0PnlvahWFtTZg+uh3H7jkBZ177FL5x9C6YM6ETqzf244FXV2GX8R04ZNZY7/Y++vZpOOHS/+CX976Ko3cbj6cXr8OfH1mIC47frZa3tU1JZn7NJJPtRE4//XTce++9eP3119Hc3Iz99tsP3//+9/GmN71pS3ctk+1MnnjiCZx99tl46qmnsH79eowdOxYnnHACvvvd74pxBjPZ/uXB11bj5MsfMr4/4U2TcNGJe2CgUMTP73kV1z+xGMvXb8LwtibstcMwfPHwnTBrnD0otiR3v7AcP7ztJcxbvRGTh7fiYwdMx8n7mgHb3yiSKXWZZJJJJplkkkkm24FkceoyySSTTDLJJJNMtgPJlLpMMskkk0wyySST7UAyRwkig4ODePLJJzF27FgjsXQmmWSSSSaZZLJtSLFYxPLly7HXXnuhoSFZ3Xl47mpc9q+5+O+SLqzo7tNCsiTJY/PX4AOXPYSdxnbg1s8fUG3XU0um1BF58sknse+++27pbmSSSSaZZJJJJjWQRx55BG9+85sTr+sZKGCX8UPx/n0m41NXP+5cf1fvAM689mm8bcZIrNrQX01Xq5ZMqSMydmzJrfqRRx7B+PHjt3BvMskkk0wyySSTNLJs2TLsu+++8b6eJAfvPAYH7zzGu52v//2/eO+eE5ALAtzx/HLv8rWUTKkjEplcx48fj0mT3phpRjLJJJNMMslke5GNGzdi/fr18efm5mY0NzfXpO5rH1uERWt6cMkH9sTP73m1JnVWIxlpLJNMMskkk0wy2W5l9uzZ6OzsjP+74IILalLvvFUb8cPbXsTFH9gTDfmtQ53abpC6/sVLsOrSX6HnoYcxuGoVGsaMQecxx2DUpz6JoKlpS3cvk0wyySSTTDLZAvL8889j4sSJ8edaoHSFYojP/+VJfOGwnTB99NYTcHv7UermzQWKIcadfz6apuyAvldewbJvfgvF3l6MPSdLk5RJJplkkkkmb0Tp6OjA0KHpMlZIsqFvEM8s7sJzS9fj3H88BwAohiHCEJjxtVtw1Uf2xdtmjqppmy6y3Sh17QccgPYDKm7ETZMno3/ePKz9818ypS6TTDLJJJNMMqmZdDQ34PYvvEP77qqH5uM/r63GpR/cG5NHtG6Rfm03Sh0nhe5u5Ds7rdf09fWhr68v/tzd3b25u5VJJplkkkkmmWxlsrFvEPNXb4w/L1rTg+eWdmFYWxMmDmvFhbe9iOVdm/CTD+yJXC7AzuM6tPIjhzSjuSFvfF9P2W6Vuv4FC7D26j9izNlftl53wQUX4Pzzz69TrzLJJJNMMskkk61RnlnchZMvfyj+/N2bXwAAnPCmSbjoxD2wYn0flqzr3VLdc5IgDMNwS3fCJisuugirL/+t9Zrpt9yM5unT488Dy5djwYdPQdu+b8aE737XWpYidUuWLMHs2bOxaNGiLKRJJplkkkkmmWyjsnjxYkyePPkNtZ9v9UjdiNNPR+dxx1mvaVIe1sDyFVh4yqlo22tPjP/2txPrp/Fq1Fg2mWSSSSaZZJJJJtuKbPVKXcOIEWgYMcLp2oHly7HwlFPRMmcOxn//+wiy3K2ZZJJJJplkkskbRLZ6pc5VBpYvx4JTTkHjhAkYc87ZKKxZE//WMHr0FuxZJplkkkkmmWSSyeaX7Uap2/jAfzCwYCEGFizEqwcepP22y4svbJlOZZJJJplkkkkmmdRJthulbtjxx2HY8XbuXSaZZJJJJplkksn2KhnpLJNMMskkk0wyyWQ7kO0Gqdvapat3AIViKXpMODiIoMF/6MNCAUE+r3xRxLC2JuRq6BAShiGCINhi5TPJJJNMMskkk3SSKXV1ktOufARPLlxX83qPCFbgNxecXpO61l57LVb+5GJMvuw3aN19d//yf/0rVl7yU0z+9aVo3W03hIODWPChDyPXORSTf/3rRGVv3d+ux8pf/AKTf/VLtOyyC8JiEQtPORX54cMx6ec/S2y/68YbsfJnP8ekX/0SLTvv7N3/SPoXLMDCj30chdWrte8bJozHlD/8QfTG7rrxRqz69W8w6Wc/RfOOOyIcHMSiT34KDaNHY8IPLkjdn7QSFgpY/JnPonH8OIz71rcSr++66Was+d3vMPHin6BpyhTtt9VXXIE1V10NFIvItbVh/Pe+i7a993buy+orfoc1f7waUKJiBrkcRpx+OkZ86IPatf0LF2Lp2edgxEc/gqGHH55Y9/ILf4jBlSsx4Uc/FOfY6it/j43//hcm/eIXyLW1OfU5LBSw5EtfQtOUKRjzhS8AAHqefBIrfnwRxn7tq2idM4ct179wIZZ945sY8ZHT0XHQQU5tAcD6227Dql/+EuFgAUFTE8Z86UtoP+Dt2jW9Tz2F17/zXRR7e4FcgJGnn45hJ5zg3AYnKy66CN333gsAaBg1GhN//CM0jKp/zspqZf0dd2Dd3/6GCT/4ARqGD0c4OIilX/0aWmbNwsiPfgQA0PPEk1h16aUY+9WvaLFNt6Qs/9GPgGJopLMMBwex7OtfR8ucORhxyilVtbHmD1dh03PPYvz3vmcACst/9CP0PPwIAKBh7FhM+MEFyHe4Z0RYcdFPgIY8xnz+8/b2X3wR47/zbQT5PArr1mHpV7+GQWWNnXr1VQiamjzvLBMqmfl1G5dH+9w2KBdZf8utKKxbh54nnkhX/uZbUFi9Gt333AMA6J83D71PPYWN//cvFNauTSzf9Y9/YHDZMvQ8+hgAoLBmDXoeewzdd96JQYfy3ffeh4ElS9B9x52p+h9Jz6OPYmDRIhR7erT/+l99DRv/86BYbt11f0P/vHnovusuAEDfa69h4wMPoOuGG1DYsKGqPqWRvldfxYZ778W6v17ndP26v/wFm55/HuvvuMP4bc3v/xeDr7+OwRUr0D9/PrpuuMGrL6t/fyUGly7D4LLKfwNLlmDdtdca12584AH0PvUU1v7xT051r/nDH7D+pptQWLVKbv+3v8XG/zyIjQ897NznTS++iO5bb8Paq66Ov1t/663offxxdP3tb2K5Df/6N3oeeUQr5yJrrvw9+l55Ff3z5qHvpZfQ9fe/G9d03XQzNj33HPrnzkX/q69h9WWXe7VBJSwUsPry36L/1dfQ/+pr6HnoIWx8UJ7jW7Os/fOfsfH//hW//73//S/W//OfWPnznyMsFkvXXH01Nv7731WvEbWSwVWrsOaK32HNlVdiYPkK7bfep59G143/wIpLfopqcgSEYYgVl1yCrhv/gd6nn9Z+G1ixAmuu+B02PfssNj37LDbcfTc2PvSQUJMpxY0bsfryy7H60l+j2N/Pt18sYsXFF6Pr+uvR+8wzAID1d96JDffei03PPBP/t1VnQdiGJEPq6iR/+9TbAAArf/4LrLr0UjRNn4YZN93kXH7eiSdi07PPYcRpp2Hs2V/GM7/5PY5dMAY9+ebkwo7SP3du6Y+Ub1dUvn/uPABAX/nf6LekeIP986Lry2bq8kIc/dYwfLi9A+XrK/Wkk6jdtv3eGgewXnnxJVh/yy3Wuvvml++7fI16bf+8eWjdbbeq+uUr0fNw3RDifs/V77GwYQMGV64EAIz69Kex6pe/jK91kUJ3NworSwrXlD9ejaC5BZue/S9eP+98ICwa14cFz+dYKJTKFc26AKDQ1RWjrqU6D3aqNhoHrd5y36z3XywobblJGIbomz8fANB+2KHYcNfd7P2EhcHSNYceig13343+xYsR9venRziUNppmzED/a68hLI/nNieD+rjHz2/TJgwuW4bGiRPj5xaN45aWvmjNRanfjWPHGL+FPT0YXL4cjePGpWpjcPlyhD09cRsqwh6NUcO4cch3tKPvlVfj98lFtLkilBt8/XWEvb3l9uejba+94nY7Dj8MnccfDwA6tSiT1JIhdXWSXC5ALhcgQBE5hBhctAhBYTD+PvG/Yrnc/HnI5QI0L5oPANiUb8Rggd/MfKSwYSMGV5RPisLm6Fq+n1FqkpQAtXy8mSnKiNMGGTpsuC5S5j7mhgxB0+TJaJo8GS1zZpf7MZctoiou0YJFlbp6SzwODs/TVHwqEn3Ojx6F9oNLChFV/GwSlW8YPRpte++N1l3noGnqNABAWGQUznJ/B5cvR2HDRvN3RTSFVbhPfR7yz89aTm0jjBTO+bZOAQAGli0rmUkdpLBmDYpdXUAQoG2vN5ntkrpbZs0qmZELBfQvWuTUhq2vAJAfOrT8XfrqtqiU7yV6xuq72jd3HsJiEf1lxXlruUd1HvXPp++d8lsV60f/XH0c9DZKv7XsvDPyw8qHZh9UUH3nhPdPO9xHz6bcpyH774+Ogw9Gx8EHZ0pdjSRT6uot0SY2MID+xYudi4VkwWqY91r824a+6k+d+qLhv+JpCsz8+QgLBf27BCVAaz9qXllc1BOtJNEY9c+fL6I2blKqR+VnNU0r8W/6hM2cKnBhGGqLmUv/ay3xmDss0lQBDxmFunnadDRPmwqgpIQU1q1z6kd0703TplW+zAWWviltR5uwJJrCxd9nn7Y5JtSnlSs/M2UuReMy+PrrKG7kFc5YUQ1D9C9Y4NRWNMaNEyYg19ZqtBtLVHc+F49nNRu+phTnc3K724DE73/5GfcRpUhFjLaWe9QVrrnOv/lIn+VwGf3WNH06UHa481k71fkjLTPc4T6yakSHu0xqJ5lSV2/RNsv53uUGFi9B2N+PcN5raCoMAAC6N9VAqVNOiWkUIq18fz8Gli2zLia28vGCq5lf5yd3IvIu7u3F4OuvJ18vSHz/QeX1aCorM/3z5rHjoy66xY0bMbhiJVH05qfuT1pRkaYkE6y6ARa7ujQOpKqU5YYMQcPYseUybspEdO9N0ysLeJzCjzMxErO7VVSFi0P9oG+O/R6bY9RvHQ1UDhqSwunT/6guVfEtz7uQMU1HSGGQy5U2Ypjoi5cofQ3yDVob25yU72Vg8WIU+/sNhFadr+zYbgHpmy+vEbVaP/oJDYb7rWna1MpBS3iPWGFQbKP9eer7Nw/F/n4MLF5Sand6ptTVWjKlrt4Sqgu+x+krWnwLBfQ+8wwK69ahbWATgM2A1Pm81GUxTpmvveZlftTKl8dI3aSdNmNlg6rKBBu1q4SKaZo0CWhoKPFzGIXRXJDnplYmaiFhGBL00/5MjcWe2VAixTZaiF03mqjuZhWpCyxInfJV4juiKYWCUqdsnIW1a52cbnRTHY8GyuizH8IMqGM8TRkbpua4/aBy0Khmbin3E+QjZXIrsU36StTvYrG0/ixcGP/UP2++/ry2knuUFK6wv1+z5FRlflXf5TIHk/7WPH26YpmosflVbX/RolKbhULpgJil8Ky5ZEpdvUU1Kfq8qIoy2H13ybu0bbB2Sl1flQse3eB7HnsMxe7uyu9kMbGVr2wqyga6eDHCgQF7J5w2XAeJ6lGiYwSNjWjaYQcAPDJCN9aNDz+MYpmcDJTCpNSTgD64YoXWfpK5ifJ5+hiFNAoB0Ryb/RwVlsjUooaQCCwKhIdy7sKpM3lE8611AsDgsmUIN20y69UOZXzfQl+EGeoYT1MQE4v5NZeLn0dV5lf1AJfL621sY6Kibxv+9W9gsLIu9s+dW/XBtdZS7OvDwJIl8eeBpUtRLM+5/kWLNMcDHy4oFe0dUjiYxU2bMLB0KQAdIfYyTTvQH7S1eGAAG/71r1KbmiKZSa0kU+rqLBr65AGpq+W677kbADCkjNR1b0pQdhxER3VSmF+jTWn2LqU+lRXPxkmTkBsyJJHQrSlF0b2qi8vgYCIhPHTYcJ0kMnEF+uth4zBFikvzjjMBABui+588GUFTU8kkXV5A6yEGepNkfp2rK16x6bFQiHlh0f1X+IXJYxwWCuifr5cHgMCmuKjPMUk5T1DqwsHBGLGJYu+5zA1NEdRMvKrCKWy0vggzFI7RtGlW03T0XZAL4vGkHEgvUcY6JqpvJaZJb2HWyMZJkwCUDjm9zz5buXYruMf+BQtKcR87OpAbOlTjYMYcy4kTAQCDS92dblQp9vRgcNkyra7YkW3BAiAMkevsRH7ECIVT5z6X1Gu5OVjYsBGDy5eX2p8wAUBlbYyQ5kxqK5lSV29RT/E+ZhPlhRlYUNqk2gb7AFTPqdNMTfDn1Kkbf8fBhwCo3FvTjOmVzUe4X7V8uQOlf0k/kvlVKgqa/mRb4dTpp8jm6TxCpSou7YccWmr/5ZdLZWbMQNPUqeVyVSiankIVLtumryo+HYfqz29g6dI4ZEa0KMfKrQMaOrBkCcKBAQTNzWgcP77yg8X8qjlpJDm9ME4MWvuLFwMDAwhaWjBk/1JYIReEkT6ruG7NNDyfL0z7n6BwFfv7MbCoZGorKcxBuSnW/lr6NwhKSmoQoLh+PQpr1ljbEEVzlMib321LovR709OleGitu++OfDmQ8qZyjDR67ZYS1eTeTA6M0aGi9U1vQn7YsNJvSU5DXBvlMvlhw9C6115a3fFBfOrUEmIWW199OHV282vc/ogRaN1zTwCIY+VtLcGftzfJlLp6i/LCuPJ7ALAvTK3MrwNLlyHs61P66Fl+Wal80NhoRMBvnjotkYMVla+0H5b/0TuSyE9K64Ri1FP+l6Rfizy1qMKkKi6R4hCXmZ6s1G4OMRQui2I0sGRJRfHZb79SeRKWpmnKlBjJiZXbRYsSTeKxA4BSHkAFFeAQE/X039eHgaXLxPo1VIHZjGLvvqlT0TR9Rvm7+dY+l64RkE71UCYpnMo9FXt6KqGCBBlYuDDO1NEwZnRl3jGISTxeQQ65lpZY0U7Nq9McJfy9H7cqYfrdNH06msuHKlV80KjNJdHhonnaNGONqHDdplXl5ax6t1bW4XnGb4BimfBBMRM4dfH6odxH9C5lnq+bRzKlrs5CNzFX5YPb/GJHiSqROgO58FzU4xd36hQ0zZyp/dY0fXrlFCpsPAYqwsSpK103394RZYxsIScSRTFxqRIvikRhUhWXZnr/06Z6OxbUQowNwHL6jvs/dSqaZpT6H3Eg49+UU3XDuHEIWlqcwvJoDgCqBLLiQjcVO7JmN7+q3n2xMuqgABnPKp6TCjJYDmpr9IgizAntqWMcBIHdNB1z6oK4DJDeMUgPadKgt7GNCYeIlt4/BhHaChTXeN2cNs2gPcSWjmmVQ3EaL2dt/pN1uPJb+d20OS9JooU0MctpiivxdM08XzePZEpdvaVIFRXHF5V5z2qF1JmmJk+lLlYKpiHf3q55NDVNm5p40jQ2PSXOl/U6Igayl8JcUa6p/C8xv5bvgwbFrYTsmI788OHIdXZWyjgotZtDDKTJsolF/W+ePg0NY0ZrQW2p5ytQDqcxzU1RjecGXcBtph5Dmbe8I5oTA7OpRFzHaRXE1AVhlDiJJnrM9I10I0nhMhRfq2dwWL6krNTFHrApTfuq92uEEG4FpslUwvS7WUHKk66tt1R4rNP0kElKdpGmadMN06yPVGJMKmhgmRKgooEAqo5TZ0XKlfsAUKEPZFJzyZS6eouxYTlu9Jz5NXaUqE6pM8yCngsehfHVRbS0qFbQBO40Z2x6jKnLVj4WQ2Ge79J9Q+JFjZhf88OGlQjF0PktlVN1iZuiLl5N2mJaH05dsbcXg8RkaRu3aA42TZ2GIAiU+GdzQT1fI2mONyH7/FU3FVVc49RF/RAlIU5dn4JGNIwdi6Ctrex0IyOMWnaVqO54TjoonAZSl6DUqZ6vgFOcuuiaajZ8o6+5FOa3rUk48+uUKZVxVWRLx6nTlKpp0yqezHPnatlFmqbsoKCx/odCzfwacTDL2WP6ybqdKk5dkvlVQQqbFDN448SJyDXXLsVlJhXJcr/WW8qLSb6zE4WuLvQ+9TQ2PvQQmqZOtef2K78w+WHDUFi3DvnOTidHicK6dZrSpLmQl//e9PwLAIBcZ2dpMVFe6kJ3N4JcruTBKkj04kaLZ9O0aeh55BHkOjqQHzkSufb2mNDd+9hjaBg7Ng4PopbPdXSg2N0dL7jRJp0bMgTFnp44KG6UQ7awYQNyra0VrlZ5jHLt7Shu2IDep56K03upkmsbouVYDAcHEQ4OItfSUq5HN3Gp0jRtGnrXrEH/vHlo3XVOqf9KrKf4mqeeQr6zE/nhw+O8nIWVq1Do7ka+o0Mcy8HVq00UiThs5FpakFfQwLBYxKCSzD5SEnJDhlRM0MqCW9iwoRKuAyjle4SulG969ln0vfCCctImphPBA7bQ3Y1QCSWhntT1m7CFNCk/97Y2FHt60P/qayh0dyPX0oKgsVG7VEcKFAWvvx/F/gGN0xPkcmiaOgV9z7+A/vnz4vkahmGcGxMA+l56EQAQtLVVvicBsaPfuI02mr/RNf1zX0OxzDkNlINCWCggHBw0xziQN9dYcY2RuooCroUMyuUQNOjLezyvcrn4ndGcgsp1Gh6NyiFHCkHBoTsBORSFYSiXT4mcafVF497SgnDTJjRMGI9cW5vudV3+bUubmAdXrkRxwwYgl0PjlCkl4DqfR7GnBz0PPwygnF2kpSXmnvXPK3E46bhKojrANU2dhlxrKxrHj8fA0qWVkEv5fCkGJ5AuTp0FqVPbb54+vcQZHT8eg8uWZabXzSiZUldniRa/ppkz0fv44+h57DEsPO10BE1N2PHf/9I2a61cRC6dMQO9jz+Ophkz0LYmMr/ypqSwvx+vHf3uOKdnkjRPn47eJ5+MF8ewvx+vHXUU8m1DMP22W8UFOV44yotnrNxNLyE/QUsLGidOxMDixVjw4VMAAOPOOw/DT/qAVr55+vSSZxSJUxe0taKxsxMDS5eif948NIwYgcGVK/Hq4e9E+zvegUk/+2k0SKV6ZsxA79NPY+3VV2Pt1VezfR7//e9j2PHHAQAWnHYa+hcswMw77ywpdqG+cepjNA29jz+u55VUFk51HJqmle4/MkkPrixlmWjdfXe2T6t/+1us+PFF7G+a5HKY+OMfYehRRwEAFp7+kXgjUKVpxoyKx1/5ntbffgeWnHkmm3w7MgFFz2/Vry5VfqNKnckvXH3F77DiRz9iu2yGL0g2MTZNn45Nzz6Lnscew8tv3hf5kSMx/aZ/omH4cONa9e/e/z6LhaeeqsXpi8jyzVOnlZS6uXOBQ0qevos+/glsvP9+oxvN06Zh03PPkXZC7TcWDQ71azb+50G8tMeeaBg/HtNvvAH5oUMxsGIF5h1/AgqKMh4paIEthVr0XcSpKz+HgUWL8OLue1Sua2zE+PPOw7ATSsnSX//Od7H2j38sFW1rw6Rf/RJD3vpWzSmItlvs78f8E06Ilf7GyZMx7e9/R769csALwxCLPvUpbPy/f2ndDBobMf6730Hne99bav+738PGf/8bU//2N6fyTpLLYfTnPodRn/pkXBdQWnf6nn8BzeX3sXHiRASNjQgHBuLfVHP6ok99Chv/9e/E5pqmT8e06/6KXGsrBpYvx/yTTo7Dddhk+EkfwLhvfUv7Lpo3jZMmIVc+9DVNmoT+BQuw5Kwvxe0BQNPkcuDz3l68uNvuyA8dism/vhSte+xR6f8D/wEANIwZjal//CMax4+vpEVraCjVUa5zYOlSLP3Sl8t1T44PnTFCXN6jips2Yf4HToqR8uYdZ2LqX/4S91e9tvS3Pl9jB7zGxjicSvO0qRhctsxA7jOpnWTm13pLed63vXkfdBx+GJp33BHI5RD292Nw5UpLuVLBYccfj7Y3vxnDTz4pkVNX2LAhVugaJ01C4+TJlf8mTdL+az/kELTsuqvWVpSkPoqnJEmEBkUKacdhh6Fl110x/OST42tGfPhDaBgzpmT+AtD3yiuV8hs2lMqXETgapy5AELv1R231L1iAcNMmbCqjKqVul8p1HH4YmqZMQW7oUOO/COnZ9MILcblNzz2PwspVFZObEKcOQJz0ulDuM4A4yHLDiOHl+z8UjTvsgM7jjquUi9BFJSAzlZ6nnir9kcsBjY38f0EAFIvofea/cbneJ56olMvngXweQXMzOt/7nsrYlMey96mnWIWuZddd0bLjjgCA9oMP1g4XHYcfjnx7u3Z9w6iR5XtfX+n/o4+y99V+2KFGeZszQIR0tewyK477BwCF1au1eUPLx/f49NOaQtd+yCEx0twwuhTeotBV6Ten0CGXw9B3HWm0E21cEW+00NVlli1f0zJnDhqnVBDpwWXL4v73vfCCptA17zgzNmnDKU5d6ZqGMaPjUBWaDAxg4wMPxB83/N//Varo6UHPI4+gfEOVNon348DixbFCB5QUx/5XyfgXCqxCFg4MYMO/K+O64Z570L9gAfpfe1W/cHAwnUIHAMUiuu+9R/lcGvf2Aw8seeKXlfYgny/N6REj0LbXm7R7DPv7S+2HYeJ//a+9hr7XSgpO79NPl5xkisXE/9bffofR9Shvsso/bj/44HLfKvcBoBxV4IBywQIKa9di44MPlS7t6Sn1f3AQGBzE4NJlcciQuI3hw+N1L6qTtgHA8Lrue+019L30EjAwAAwMlA5DNgcsYtKO2x85MkaN2w88EMjnMeTtepSETGonGVJXb4lMhM3NmPTznwMAXt7/7SisXu0Uj6tll1kYdsIfMPD66xgycCUAi/erUt/Mu+5M7NryH5ZQlpAoVfHfakgKVWL0oLQoNE6ciGnX/VW7ZMSpp2LEqadi5c9+jlW/+pXuNRX9kdc3FY3bRkncTNywqL+NU6Zgxu23sV1dccklWP3r3/Bmg+j0LnDqtO/Udsn9N0+fjpl33J5cjkr5t3HnnovhHziR7/9FP8Hqyy9nx2/mvfegsZyXtdStEMu/8129j+V/R378Yxhz1llsGy2zZmGnhx+K62ARWi4jRPnvcd/5NoYdf3zlUm7eBLJSF20qQUsrpv3jH8DAAOYedzz6X3vNGD/tnSEONh1HHIEJP7xQ5+7EinoFqYlk5t13VQ4W+TwQhjFyGl8WtddgielWnr+5tjbMuOUWFHs3Yd4Jx5fiS5I51jJ7Nnb4w/8i19ammNUsceqi78rjFwQBpvzpj1r2lnXXXlvut1I+am/OHGx67jkl7l5YaZE6aESUj85O5NrbS6F76P0q4z/jrjuRGzIE6665FisvuUSfo/S9pd8DmHHnHVaahyob778fS88+h30P2/ffH6P/538qCBSAiT+9BBgYwKrLL9fbVft/5x3Itbay7c074X0lVI5wK1v32AOTfvFztkzfvHlYeMqp1jmimlLHfuUcjPzYRxEWigiaGjVEetKvfonBlSux4oc/wvqbbgI3f5tn76KjkNH7oLx/Iz78IQx999Gl2JP5PBrKMfxKnYn6pt9jw+jRCIvFEkBgef7Gu8zc44hTT8WwD3ygQnXJpOaSKXV1lpAQnUt/R4upQ7noBQlyyZw6ixmRE2p+SfJsqvwUteMA/HLxySL0IU4oThQ2RamLNkNW8Yw2KAvnhCXoF4kSGbXLDRuDMMX3b2s3fsbJijvH5au0L48ffc463ygaU2b+WUQyuQcMqTrmkuUbeEVOleg+uN/i+VRuv6lJ8cykGwfzIepHQ4NJxqYefqr3Z1ubtqkXVY5aqF8f5HQeJ9//AEE+j3z7kHhuG+02Nhgopo2wXuHUVZ5fEATIDx1a+Vy+By7afxCNB31/crm43ahc3NeGhgo/z6KU5YcNR759SEUxY+ao4cyijF/DiBHOSl0uul9OqQgCTaErfVWaRwZfUW1/1ChRqavcf1H7N2huFvOXFtavN/vI9FUVTcki/W8cM6bkmQ7l2Sh151pa9d9CoQ2VvqC1Qd6x6B4bGyvovqG4WfYI4R4zhW7zSmZ+rbcwipbThh8rGpFSVwlp0i2YX+MF1JFYa6AnCTGIYomUMhfdkduwYqWOpKmJFyWYp0gm60QoLGKaMJ6FBopATFxace5ZxX1IVsas8bEs7VbqsYyfDVmkm6pNcXQRDmnzqduG1HHmb2n8WMXBgrRGXWM2dTp+mkIb1R21lxeUTAhjTJ9bkblH2g+bMmAZY9vBhToVqQcSo5zK35P6pI1foPUtZOaoMV6c962DBMz8cTlc0nvU1jVb+6Q9KesMV4ZbO73XZqMflvlrzDHHd50eeBKcaOhn8zfLe5jJZpNstOst7ILvs+GXzS65XHLwYYruJQlVeBLc1Y3fHNrhNpzKxkLQD2XjC2iyaW5RLpoKs9kBWSkyNm5ucyBkYq2fNmUmXhTlcQytEGFUDUOityGydDF2URxdhItpFqFBDpsIex+kHm0+SRskg9TahtGIxabWR/uttk9MUjHyZum/OsbUszB0eGa2sbGOsW2OxAgquf9AOznpbSGQ+8QoZdZ3nJa3jb9NYqSXmX/W91A3vzu3T721YyuC53Pw6SvbD4s1RXq2vof6uLhSXnLeUZV0CUWv9gCZiZdkSl29hTMRWk50sdCTYS4XI3W9AwUMFmQzkPMrldNfaiu0rjYTl3eZTmTjUOoOaO5JdcMhiyq7SbiYm7nFyeDpWeqhY6Re74KwWZ+xQz3ERJKINFCzZbzw1gapY0OKuMwDa5w6ZvwFkySLFFhQMK/xU9o3OGgRUseFxuCQW+NQYnnWHF8x7oeD+ZxFo3VlnqIxgfqOUaSGMc1W6lXbDfR/mXeMHmqckTIqXEYSH/SMMV/aFGXjEGJxpqp00XJY96RBVPpB3+fK/RsorCcaaDgvKUitmELMtkc4jFEmtZdstOst3KbqEPTR4G0FAdoGKvlSWQ9YX/jbMDHI0DrbjstJm4taHv0dxc4KmUXJMF+Z5gcXFIrlZhk8PdmMaDXfWDcFBtmi4oL45fw2JboZufD/XIQ1fzF8L1GscerMcZDzUjJKpU25FJDL0k8Be612XfxOyZw6g/+q/E2pBawi4ZQmzNdEX/47cvCgvDnmHVPfP3lTZ8aPC55MlVn6PexKFRXOe5odd7Eco2Rax5S3FHiVUcTJfGupk3v/4/WTo6+4CH3G6uFIuBc9pIlgWve9x0yqkkypq7NwpyenRMoEPQqCAI1hAU2FUow6zlnCdwOXiLKJffPgbnAEe8qpA7PxBXFcM71vLDfOBcXglDJKELaZMzkTtYv5xmbGdtqUeN6MWI4qX7Xi1Fl4W26biIP5lXEmEjcOpRyL9MX9puMhP79A4RLFdUexExv0A4jef9KWWrcDGuxkmraCUYxSKDl4hHEhBo1S2vIwv9p4n6CuMWnNrywaGP/oV86lfelw5IIKcr+lNU1Spzq1HwH5LjbV+x3qDSuIyqkznr+M1NXqAJmJn2SjXW/huBQ+nDrF/ApUUoVZkTrXxVJ6qZP65vPyUjRQM78km19NUynTD6fFmZRh27WZ78wx8nZwIFIZC49NKWlTpIhYrTh1kXLMcppcuJUyGsU6vHAcPlLe8CzlkFbL87Mje1QpjuaqWYQ75FAHG5ewOazC6PL8OFSYoOFxx9UDjOT9qCA1hvnUl1PnUN5JbGigC6fO+1BGEd7kwxGrXJO++pom6XtjQ1O9HRWsSK0Dp844cDF7XSabXTKlrt7CKVo+nDrF/ArAHoDYg7heqpuaOM2TvtmEJyfGQlSucOqYRckIacIsyg7mS0OZYJQCKxfFNkY2hI0ijZy4oGhkM9PNv2b7pvm1KF7rJZaQJtWbX81xkDYV1lHGxuXJWcbPykkkSnHeFtKEGQfDbGZ51hxfLKraZYwZpTAOaUJNdJZ3jOPUGX3iDhUWhcugcaR2lLAg/g6HK+P+VaSSETHch8NzsM8RX6ROsKawz8/hkKvVLfAGbd7PDpw6d/tvJrWQTKmrs3CLstXcEpWL/oiVutK/QywesL4nNYMvxsS5MsSG4HEiLaqAwgkhpqGcYlogAWZ1xdPhfm0ndVo3a321II0O5lc3D2cPxE/lJHEKgsEF8lzoBWFRiDQhTayegaZSZN1UIs9S27yn88iTkxj/a1HqWNMcNZvblAJqRtMqjztm/hb9ZFN4GoSQJpr5Lupi5Xm6EOUrnDrONKrfN+1XklJFhUUDkTy3jUOOqzOBwTd2UMosh/XU4T4kb3atj4xS5lS1tDYq5lcrpy7kf8vMr3WVbLTrLdyinML8GhWPAhCv38Tkf/XlNATGqm60L/ULcDW7CYRj9bfYNFq5Z2nBURdMJ/MlIayznDqbcmUJ+2LdlGzIVNS8w+ndUKaSlEq6GHPm/zRiCWnipDDaTFPcCV/k9DBz1KaU+4Q0YfppeJFy9ldOuY3/ZKgFUh9tZjvfUBrxWiBQHHJM2KCIP+gS0kTlCLMoLjPe6mdvxIrpj4ujjnCPie0bIU0c1labc5R6YPUR6kWv9kP6zRWVp9YQtm5Shls/4896vZnUR7LRrrdwvA8HpM4w20acOhfzq2vfaAw2G7TOfe8T0iQmnivSwMepg+p9RYnK3KJu3fBIv5l7tJq4DMXT7f5Z9IRKrJO6bxTa6djDfFi1+ZULu+HB17MpLuwJXwxpwiAFMZfHxokkiAttj3xncKmIF6kmzDhQhcmKEFFnHKZuO0LEoGqx2Zg/lOhOIZz5VeLUMfdhcaJxKu8i1vnncrhi7t8mgve9F9VDlZThPkTve5ZT53uoj/pW/tfJ+znZ/OqDwGZSvWRKXb0lZDY+IQaUVoyeDKmjBBeAuGqirLph8khdEqfLbMOCdMUBXeWTorG5Mrw/rzRhLNE+uphDUQSisnC9UjBqRL7GhehNx48LKaE2K3HqqnaUKP/LkeFd5oHSVwN9YwBXeVNR/yYIM2va5JFL2ifzO/0QYE0Txt2AyFezcOpYgMdhjJn1JB7jKBWfQTUIlLlF3n8Horw293xCmqTc+FmFyclRKrqW9CvhfRAjA6Tk1KUOaSJYCtg4g568PTOjiFm36QxhseakvcdMqpJMqauzcCZCv5AmEaeuVD4yv3JInXfwSZtnpQOnzundtTkaxKmXiOKmogh0weIWFQflyoiFp7Vr23AJmqE+M6sphuekaOKAdBmIXxLSRMetRh5ptlRUTtCw2lfBpMcF6DY5dUXjb+uGaeMk2pRiqoxRxEvrEqMoUK9r1bRJ23SKU+dhoi91tPRbXn9umoejFAsygDz+3FjHCj+jVFJNNbVyYyqZTjmYDaSL1JfQnmGadPG0V6+vfJHYV2ud1FKgIa36b84KM1UYmbrpfVjThKW9x0yqkmy06y1VpgmLFszoRW0b6AXAx6nz9rCyRCt34dS5vLw2TlgF/dARF41TB30z1oEaBxRD2Fy1vlhJ7AK3BgmLp0tIExd+j03xZpUYaj6s0enZwqnzDpdCTXI271ELp451sCEicuqkPgtm/whV5kOamIqzV0gTK9/QYY5wzyZujw9pwh6cIsVTDWnioJwYY6z+bSjlKTd+xsPXDamjz98RuTZoDMnKtdYPY96mPFwZlgIFTbX85iSGE4lqfhfWL1ss01rFxMzESzKlrt5iQSFcQprE5WJOXQmp45U6z5MaXbg50wbfhFbeKkQ5U++ZeubpJGCBxMuaX12UKxnps57C04Y0ccoo4bMpkb5K7cdjQZCSqjl15pz1Me1q89+BPC9xEkOL4uCUJiwJzZbMtQTxSuq/6IVs4/GxThjJaC5n/jRDmuj3o8WpIwcn26bOojGGMwJMRcNW3kUsacJc8uL6cuoMK4ZtjsVdVH4TEWZPs7N08M7lzEO5r6c7fcZx3VWmCctCmtRVMqWu3sIu+HYUh924Y6QucpQwvV/9T2rQ+uGUJkx9yV0WD1tIE4IiaGY06q5vSRNm9R7N0YVPRXocTuGGN2QCUhYJbZcTlw3bMn68+VAyt1VpfuXQJBfvw0iUexSj1GvORML4ceZzm3JJQ0IkcboERxMrp84ap460a51j5jvnhEbbMjpQBw9GcQvp+28jynNKUVQPhxTSe3J1VCDCmqhd1juJN+yK1FH6hwPlwuinT7tCnUbuXu03+h44cupsacKcQprU6B4zqUqy0a6z8HHqEjZ8TnGIOXW2jBJ+p2CJKGvtW4JSkdiGWj5PNz7lpBi71Ot980aKAr0N35AmcSiLzZAmzCWkicktTDiNS5tAtQutzcTmsofYTFOcGTeBqA/ACWmtzCMyx4TxkxxNYlSZQV5ZxTkGTKnZ3MLj41BdhzFmy1MHD2JO1jlZdGwgjz+zcVvzI0tpwmrBqYv+cOHUxfdI6ktoL+TGTRL14EJ/i75IHdIkqke1ZvDPzzdNGDs3uPcdIAcH4dlmSl1dJRvtegu74FsWcYBVnKIQBLGjBGd+RfIGoIkl24PYtyTzn9GGsHAAFc88blGS0jtpfaT3wbVP+s3eo2XBpp6JysJnN/uU/60ypAndlBJPw/EGS07vVWeUYDhWHgqjNlYupinJQ1xFCgjfiUfBhENFgvm1okRH/Ylyv8qKl54mjJp9Le3aOLZOaK5s/qw4I1HznWJiI4c6e5ow5l2RnEuYe0qN5ljmn33Bo8/TESlME9LENscdzLdsnVRhtqCp/mnCyKFaq1vaoywKe9F8DzLZ/JIpdfUWjueWhOJIvK0giDNKsJw634WDwveWxTiStGnCDA8rgPHMU5Aryqmzml9tzctIoZGCjI1TJ5CREzk57uZXnzRhSafhyjwjJrWqF1rT/JUmTRitA9A3qrg1jqcFuqmTOWELacKFzbH004jgb+PUce0bIU0sZnAuBltZ3NBoAVUCKmGD6P1ozhCmUiDHWWTWM5oXWEXTBDTHe+Nnzf8Wk3YkEtKesHZVFdKE9lMr73vf9P1X1gxpjjm2YaLYisKbJqRJ2nvMpCrJlLp6C7MoJ6UJ077N6RtFZH7tZkOa+J7UqMJiWYwj8TS/Wh0NjBhMyoZLkS4LCuBDItcUaSOUg8U0Rs2fjpwcL2cYth5+/MSxF/tbJaeO5TR51K2FeyC/cQ4vxHuULUxMpD6OLmKPqaNJjHg16J/1TpXLcuZjva/sc7OaX+OLpB7LzxwwHTw086veN/09EMafW2N8ckg7Hoqo2EzMdvpCdG35H1fFx5f2QH8j950+6LJgYtWyfsStlIs4jq3tHgVnPluasMz8umUkG+06C0t0Tgppon2vmnQCe/BhT76KuVCqC2ZC33zb4JQiYeMrrVfU/Gqa3aoOCWIEmLWgKPRaX/MNK8n9F2MJJhD968mpc1PulfYt+UDp9dY0YTF6EZVhlHKDU5WAdBJEMnruMf+TKVNRFJQvqRJsQXrsceqS0VzjHtWDF+XUaXHqiKleVQoEThV3cLRy6iSlPKX5lTW/u3Dq4nLpDmVODkc2Z6C0hyubo4fk2e/sKCcjtXJIE/nZ1sopKxM/yZS6egu34AunoEoZdVHW0YsIqesdKGCwwC+YqYNP2k7Y8deei7LBCVPKCxufahpiQ3kYyIIH0sVxclzShHHegxaRzIeqhC7990k3BRjEai8TqU0saZq84hWq5crCx6lL3lScFFdf3pFk0spbvF+Z9r1SOFETYULdhtjyEzfk9d9UL1wpoTvjGRsLp5xY2q9HmjD7oY6/x8SQJhLCa1MgHXij/l6/lD6iKOXSHPNF6qIhVZSyLE3YtiOZUldv4RaDpJAm6vfU/DrQF3/c2Fdg2/I3v5JTIMzFuPKD78IhcEKCwAw3wqB4BokXME6m9nyMLpw6yz3FZmDPhVMyH6qShhOUsHCaYQpqdHom41Dqk4NSWulY5W9jMyj/qwXv5TcVPSMI9GusacIckdZ4Tup9DWxKHfdOiIipzfzKdchhvtH3mHNGMg41polNTxNm51RpscgM5YAx0ce3k1a5YdBMl0Os5R4TGtT6Wy2nzsrbtXekVN7oB5S5TX5zfddth2qOw6i2Rf7Wrq32AJmJlzRs6Q684YTZ+JJJ9LJS1xgW0JwP0FcI8Y4f3au9v+HgIIrvOh/I55D/9h3JXetrQ/Fd5yNobETT9+7C52c2Ym/abyqOJ91IxBOvwtsxTBxBYC7iTCgLN54LNTFwSoGs+JiKp+OmQAn3nLhsMLEy5Wh+FTwRqz09W7MGuFRtM01xiIvEM+PShNnGhJLBk9CdmINF0StLSBNuwxf4TuxgCRtoqRvJirMt3V9AUvFZTWxqF4nDTaVDJtJmZDYImevp57SOEqoziJP5VbpH10MZUZQdOXW1M78Kh4xAeX7cbw4iBjZWHdWMdzXk/1avzTh1dZVMqauzsIuBZRGn32tWW5Te393GtOKxZT3o6jUDEKN5SOnfHuY3Q4LK9d19uHFRIVmp831xpQ2H3VQY0xDnUYfyWLj0RdxcK+25mO9omjBn843FUcKFEyjypVy9N2u10Cr9CMOwdP8+fD0X0xQ5wJR+EtAA9W8LGmnGYrSPhxG8mcSpYykTTPs0zqINIWLz6sZ1K8iMJBY0uqKMcua7ZPqDk/nUGGNT8a589LQmkDa4dH3WuqS+JSlXRtBvB6XMhkbHIVH87tuWCswMd+I5tgaKqcwNOl8i4TjJkWScui0imVJXb+GIzkmekdqibC6e//vuqVjWMcoo1vPU01j2ta+jacoUTL70l4ldW3/nXVh58SV4db934kdD9sSGAcbEScSbE2NsksrCIW24zKYScpu5w+nZQPxY84EFRZE8+xJP+klorFKnBycoafypMlk7Th3ZsIIATuE24uLyhld5DxilSEID1L+tyqVuvkrmJBIlOiTfW8yvbJgPB8XT7v3qoAxY0OhKmrAYzin/AGVuMQeGhNyf7L06cOpSb/xGTD0LAq4X1K+PkWv7nDXMzw7loliiCEPx4OIGa6uVShSVgBl3TxRUWttyAVCUOHXMOkx+25bShD08dzUu+9dc/HdJF1Z09+E3H94bR8wZJ15/27PLcPVDC/H8svXoHyxix7Ht+MJhO+HAnUbXsde6ZEpdvYVZ8OUYUFER4RRarqMhB8wc02GU2zAkQOOGFWgeHI7pzO9U1rUFaN2wAsXB9QCAbkWpS0wT5rlwGBuwWgc1DanhFlw4dVa+kQXFYNIjUaFohrNSKyFNqrggXRQxSOQk6QhR6kTitFaKtOVyyibiyuHMAcWi40ZP7oNeq/wd2jZM6uiicpI4Mbic5fF2cJTgza8EWWJ5m/Ihzy1OXdQPorgBZkgTVTnJCcpgoATWdghpQtcz7fnSW0q58VeswUQBgeP7w60xLg3G9++oMEVKnYPXsJNQp7poP9FCmlBU3pUaw6OYAQKEwkHDyqnbBs2vPQMF7DJ+KN6/z2R86urHE69/eN4avH3HUfjyETtjaGsj/vrYInzsfx/F38/YH7tO7KxDj03JlLo6C7sop0kTptYhInx+J7VoMR5S6AcArFeRuoSQJlXHQsrl5JNmTnWiIJsxzA3XvoiUF0UajFetm0NTIzHG3M386pZRwgFprFFIk5qZX9m+ONYhIVKsM5Ew1znTnmUzkdKESYgLDd4cj1+k1AEV83P8mRljiVrAOnNAb0uVeP6kMNFDUUY5Th2dozEqqNAfpE3dxn8MLetI2o2fmhodza9imjDXQ5mvg0V8cKHzNvrdl1MnoWkW+opvmrBobVSfDcdBVtuif6MKxXULysE7j8HBO49xvv7cY+Zon88+chbufH457n5hxRZT6rad0faQYn8/5h57HF6YtQs2vfDClu6OLpyiZTO3APqirCJ8SeXiGEyuKFppOrQXS0rdhoEQRWquMJrwW5Staa6EcCN6mjDO3BIq/0/oi4GKMhuOjSdHURTHhctwsGDELVm7J2+GEKutKJaPcI4OPpw6rW90w2PekaSQGurfNjTSd/woMhvHqasodWb/o7JqNdRsLrfLOqGQtlw8pFk0Ok9DmsQdlA9OFk4dq5xINAqm/Gbh1Lk4Lxi8QTdOnU+aMK1eAeGsNqSJU5ow38gEBkXA4v3skCZsa7C+dnd3Y/369fF/fX19yYVSSLEYYmPfIIa1NW6W+l1ku1TqVvzox2gYs+Vs2lbx2bCiItLC5+hg4Z5fsFRfe6EU+64IoLehydqGfywkgsYpCpSJQqnm12iMmBOjsXk5oBgWTp2Vd0ZQFHfzTQKqqvYlVZowvoyxqaRFCMyaK38y/EinGqQwCcz4i2nCOPMPZ/4k/ebQYFYMpJO5R8F5w+roYWvXxrF1UYIo4V2pJzBCmijKhUXxFCkiHBpETYQMxaFS3hHppiJ4dSfWJfH9kg5laUKaqPVKnDpfbqsQEiqwpQlzPmQJSF9ONe0K5nf6t1p+KwhpMnv2bHR2dsb/XXDBBZulncv+PRcb+ws4evfxm6V+F9nuzK8b/vUvbHzgAUz62U8x91//3tLdMYVZ8BMD00omAurZSIv5noLLL3VTsYCmfA79hSJ6GlswZLAvkVPnvCjbHA1y8qZiTT1E+UEecd5Yvk8NvScr7epKKSsuSJdkIpMUWSmkSZUmEW2MDbTEzxTvZJpKCqkBmJw6a0iTqHx5PKQ+0+tjTp2ydEomYVtIEysaLKPjTh7SEsUBMEKaaIdMg68VFYr/Z/aJ5dQJaBJX3oFywIktbIsTUh8Xc2zfl/YglQNpNyWnzgi/ZEsT5sqpE8c0EA8atlSSW1NIk+effx4TJ06MPzc3N9e8jRufWoKf3vUKLj9lH4xqr339rrJdKXWDq1Zh2Te/hUm/+AWCllanMn19fRoU293dvbm6B0BdRLgFX1LqhE2K5qU0ypH6EyRajIMwxNDWBqza0I8Nja0Y3dtlaSMlOmOQeRVOHY0hpUU0N82mhgnGgVMHsxrlFG5ZsKPFzTNNmJmCyZTNG9LED5lIFA6pclGq2Tp4RUEbU8n8p3025w0V/5AmFOmMzK+6+VltiVMUzNhtMlIjIZil7zxM9BxSZjM/izEkc6AHrkjYVFAC4Z4rn3o+KvcYhqGuUPgovK7et2T+OafAklDXtA5L1pAmwm/OnDrLodolpIlwj1tDSJOOjg4MHTp0s9X/j6eX4py/PYNfffBNePuOZiSKesqWV6FrJGEYYulXv4bhJ30Arbvt6lzuggsu0GDZ2bNnb8ZeglcYbOYWQORf0LyUZlueKJqy4HW0lDgBGxtbrW34o4EyJ8RIKK7234qwETOT1fuV59Ro39nQrIDf+JIV5wTFXa3Ti1OXoMhKyES1RBfNMcBRwTSqEOavi6MBbRum4mp/fszGxXaSjHesBCqcOkPRZDZsMbMH065kslO+syoDthyeLs5I9N1QFD6J06ivMeVrqXMJYCjlqfODUkcd9b2yInX8PSaGNEmRJqxUrzDHfflucT8ofcQ8FBtzzNmKQvYhdW6IacKSFfbtPU3YjU8twZf/+jR+dtJeOGTW2C3dna0fqVtx0UVYfflvrddMv+VmbLz/ARQ3bsTIT3zCq/6vfvWrOPPMM+PPS5Ys2byKHbcoJ4Q0EdEECb2IivkqXIoTwNCW0tTYUFbqap8mTFfcEHBmG+WkaShTqtmNoFAuSBfLqSPmO4do/5snpIltw6YmMvvCGVBl0oW35yBcXkuvNGGlSsp9ExQ1l6wrnGnP+vzo/AvFSwEwG115vBtsSh3z3gmhKNh2o2u5/ri8b/RdiZFL5eBEHIVK80RH/lW+aKICbsvTq6E59H5qsPGHodZGAmZe7oZ5j3bhEdvEw5E4xz1RNNKPkJoaAshzzPVdp3NDeTZRSBPR0YX5rdK3bQc72tg3iPmrN8afF63pwXNLuzCsrQkTh7XiwttexPKuTfjJB/YEUFLozrr2aZx7zGzsucMwrOgu8dFbGvMY2rJlnCW2eqVuxOmno/O446zXNE2ahBUPP4zep57Ci7vvof02733vR+e7340JF/6ALdvc3KzZ19evX199p23CKGhJacJEBIp4Nhri7cRQ6ePQ1gipa9HrMtrwRQP1cpWTvnrSNM2pZigKZjFxMYUGdFHnlALE7RrFDQ9BVzMM5bsw4rVhO5iKAVOZjL0na2h+dVWQkvoWCec1J/HMNKSVILYsCsab/0WkxlCQGKRO4ompN+AV0kRG6lx4SuK7wnm4MuZXjv5Q2ZiJcuLCqdN4j1QpTLfxa/O3WORNzJxIacIcD2UVq4DjgdnHa9hFKI1DM5F7zDFG7MHfGQVdbYv+jRSgwlYgzyzuwsmXPxR//u7NpegZJ7xpEi46cQ+sWN+HJet649//9PBCDBZDfPPG5/DNG5+Lv4+u3xKy1St1DSNGoGHEiMTrxn39ayh8/nPx58EVK7HoYx/DxJ/8BK177L45u+glLArkGNLEUFZiJSwBRUsRfDI6ZURInaiN+HLq6OKomYbISVPd3G0hTcJyGZe+BGRR1Oqh5jsXpMfRfJPkDKPWad2w03HqjM2o2tOz0p6T2dOhb7Fw9UiOJuzzk+e9iNQ6cupomrDSdwLSqKUJs/CVjD7aOHUOyJJwj5qHK4M0i8FnbSFNLJw6LqOEyclLufGr86/Mq+N+oyKbmN0OZV5pwqDOH36O+5tfbZw6ydLhZ0UBPfDmHNOESQrfNmR93W/GSMz/wdHi71RRu+aT+23uLnnLVq/UuUrjhAlQwc7+tlIO06YdJqNxnJzmo+5iWwSlDV9Y+JK9Zv1OaupiPLS1NDV6GiKkTjLxpjO/shuwwXdTUBSDqEw2CudFXebUhfQ7m2eih8lX+93KqXOoS0oBlRTSxHMzShS1j5TT6Krgk/K0Ps38KjiacNxKF06d6/iZTgcMUieiTyanrmZpwpzmiLk5GxldVHSVtGt1ooj7w6wxEu9U7Uskaeej2l6RvP8uSDedK5shTRgAmR+ZNtwHdVhRDxAiX9KPDmFkT8kFCF3ShAm/bQ0hTd5Iko12vYUxfzmnCRM4dRLC538KrpgIOwhSl5gmzNnjkZp4yi8+kuLUlctLnDoJ5TTap0qlqRTYuGHmSdlx4YyVUks/XZAuumFqnCjL9RSFrJK8zOZu9eVXChseTzcQlGImpIITJzIevoTxoFwixvvVCWkUvL7ZdgkKxdVtR6PJtapXtfCOqfQHIwZiwLyblQ5W6o6aN5RDC5qTNH8F0YYtDLU55BOnzj+kCTOmTuUkNDclp47OI0uaMHdvdIoQR31m6o6usHHqUt9jJtXIdoPUUWmaNBG7vLiVZZMABDQmAcWRFh56sjLK6dclivJSR44SsferpDQlcZKIiDG0cgoaZ6AoimmB4dQZi7p1EdEXRZ3v44BmxXUTpSoxpInFpBaJwwZj8KUcza8GClmLhTaX0/lMvgqjpOhyzhyShzjnvRxd4hPSRJq/0niracIMpZQxcQt8Jz7AtdLvYtFISWbtL2QTfRCYHq4c/YHNmiDwftmDo6GsMyZy9f5oeRchnDrXA6zpxep5KDNQzCSzrTTHUyKUUl5dDk31pFqYyrhSN12TIwmFv9Vrt4KQJm8kyVToOgu7KCcgbmJIE8f4ds7BJ1VOXSvh1Elt+C7KDpw6e+5JcsKO/nY0v9o986jZ18Kp8w1p4pBRwun0btuU2et1ZMrbQ9UmgrnG19xj7gbM+IvmP2ZXcTC/uo4fjY8YjV/1acLkZ82ioPSzbbrZeIMGGhc3anGwUMy2Ahqj9VlKpceUrxWnzvkAKyKVScqZpPAmmW0lhDkdYm4LaWLyNj2Rc1u4G4nqY+FLpuUNZlKdZEpdvYVblBPShIkwtqMy6BtiIkQYO0pE3q9y2JQqFw4LpweqGc1QIFSEragjOKlDmjCboFEBtGu8EntDuW9OXBZ6YeGVFHfDszpt0FNO6Cbiy6kTwmRwnoVymjDV/Eqen00pN5xx/MyvBqdLFYv51ewj0yb17Eyq2+x0uasEjc7lYNIYFMTJRrQ3zP6kfyydhNTDlXdRUjmhiq+nN6rv+ysFoU5vfvVcm6X6tPHjTbO+1BgT6VPNr1Spt5lfFdN+JnWTbLTrLcyinOTwICpOQuygxHKSKJ6hkaNEJfiwpHB6njjppqKYb62mIckMFv3tzKkRTAyAE5plmoHLPyQtnPS+OXHZKIx6GFhIu54oTmmREbZqYYNx3aGTPCo19EdA9RiFoZKZg7lHOo+SzOfUQUMhjyd577ImybhZC9Kj9EX0rPUx0avcOIHGUFqDIqXANGObGV2i4sy9ShQLprwvfaPSBDFRuyJf1MPeWTmjiK2jUibN8bR8M5v3PZ2robnX2OsWOHmqo5rx/NXDtTBXM05dXSUb7ToLG99I2rDiQgJ/wzlosav5tbIYdxCkTu6bJzoj8H1005CpMJmKb0rzq9SGWrcNPaCIm3NEervirvXJJSSDL6fO2IxqiNRRTp1zsFPdNBwLt9GKHuKMwlDDkCZmlhOlbwJfKmQUbZ80Ydp3kvnVw0SvKTz04KTdD3keRVNhMJBmTo+X5ihgID01Mb8Wi87KmXEQceV9UfOzZzkT4UyJmKdJE+Z4yHI6VG/nIU22B8mUunpLPO9dNqyyFHnFIXBUBp1PwcqCZ8SpE9FATyXBWDiUxVEIN6BtoDTOV/l659yPtjRhRpw6btwot8bx/qnZlBMXc7k4fgmcOhpstRZKnYR6OPMrE/hGrElPQIrUelw4dQ7x4kqXW0zMIl+K2fBtoXxom+p3kvnV9vxEUj9zcHKIU+cf0oQenJQDmITKVpkmzBkVEu7R/VBGEdsksy157pGk5JvJnLrAMsdc1//ycwOdG1WmCcuQurpKNtr1Fs5rKm1Ik0SzrecpWFE8VPNrCGYxjsR3URbNB4GocJXCLZD2jJAmSv9SoBhqn2zR4tOHNOG5NZo4IV2S+Ui6migeNVxoVdTDldPI9s3g1DHmU4F/p4c0IcqIC6cuidMloU5BzkR94j4xY+xj9nNylEieI4Y3cBCAckIrZmDzUKWieIlBdK2cOhXNIV2N2vcOaULGyObcpBWk5mdH82uN04TBRhFwqI+mCQsU3lv6NGH0AGjWLZrfyd9q32rilJWJs2SjXW9hOXXCiT8uIyw8As8hFucFK6qvYn6JkLpCLo++fJMIBlYWFVfFsfwvRzy3EO9Fs2P0nTIGqdOEUTSLW7ANTpLbwikFz9UkFV8qAWmgKHANOXWagqw+D1/U1kVxEdJU6UhBVFzeTAzEL4nTRR104uthHhBs/ZdSOHHPgXp2alUnHyJEL9aczKkDKkgP5/0ohzRh5r+E+KnfVSpIvB9RVEXfGTHXFR/vOJMOBz+2nOTg4x10WbIUMGiqp6XGShGQvJ9tnLparjWZOEs22nWWCombM80kmVHJAiB5pEXiuXCo3ohtTXnky33d2NhiUTj9XlxrmjCKQqmcDGNTURGa0F2p8EgTxkf7F5BG5xO7gKq6cgJ9vffoeFsUHm9RHXVURxVn8yvPSWMRS8lDXB03YpLi07zJnCROKgoSoxRTZCTukmlGl1M4MYondQJQJYWJXqNvGKFVLCZWhoQveziq61l0cGLuoVacOqVMWAzdvVgla4AvN86RE5eI5lZpfrWleUtNjbGa5i3vX8ap2yokU+rqLUVmU5VOQXEZfsFyjlPnmSYMxSKCIEBHvtTXDY2tFhOvLxoooAEqUZvjrRBPX92kU3RWipzShNkWXE+lQGlYv56Kp1LKoins5dLJ3t5dJ1E2AWelVOtc9IewUeRkpSi+VPtM7tGCgrHzj+2joBTncpBCsvAbfqQAOrTrZH7lu6uW50OaUOSxUkYMPquZbaX+yKZy3URXw41f5RSH9LuEMow53V6MrhuO656k1G3GkCYVyLr80VlhpnNUVXiFvcbGqctCmmwRyUa73sKgEEmmOTGMgWS+isp5c+p002R7voLU1SxNGHU0UDgh5satmmYD7SsjpIkrp0tCCpW6YzTVxqnzdQ6g/afiaT52ThMmcIFqzalzHn+tvKCosWm+JMRDRWwd+E7U4zZlmjAg8DMfx9fq17BID/XsVMWFEyl5eAZMgGF1PTLMppUDg2G2pf2zKeBqEYFblmbj1xQt5yDCulLvniaMmP89Q5qIvFHf99AhpAmXu9VJDG63OdfNkCYWhT3tPWZSlWSjXW9hFxFhw6Jl6MtJNxyjnH5dohCFoT2nIHUJffPmbdCTsuZNaCIFYnonlBca1fznwqljPPMMjzI2zhlBehwJ2okhTdTvffhSjuZXby6QiwicOv80YQJPh00TZkEKojh1Fp6jOI9cvYcZJUhSvLQ6JYTYMse0/oFsqNY5wnPauJAmWj/ou6FmTRC9OOVnFSO4Nk5dDcyv2vxLRMx5M6p7ui9q9nQz29Y+TZjNfO4wxxixUmNE72f1b6rwpbzHTKqSTKmrs7AnNGnDikTlxKiS5FHpeVKjm0FHLkLqWs3FvCzVhzRRlTp6Co3KBMamEpLN3N0MKphRlLqtJkqRqOx40q87p07YxGoZ0oRyGj2RYdEjklWKBDRA/duGZvly6iRvSeYQUumGiRTWJE1YCjRaO/Bo7xiDVBmmPUUpEDmNzNpE+6+iOS6OFq4Sr5vuiJsZMNvNRCjRGKoNabJ1pQkjayMX0kRSypV26W++95hJdZIpdfUWF884qYzBqbObX715G2TB68iVym9saLFwwTwhdktICdE0pLrrcyFNwqIzKmlNE0b6VAulgJYTzdipkcboe+lyulC7bUZOEm/EoT4FXc2vCXHq1HrElGJ0HgjllUajHpevrcw/vpOVPtKwLSIJnjOtSghxUruUZhD/7GCiL7ejK25RXSZSZSXaSwqs7VlF7dtCmvgeClVROcXONAgBqXXlxtWKU1dlSJO4PMOpSx/ShF+btZAm5AGqSrqYNSPj1NVVstGutzCnF5FwXZbUacJcF564Pv2l7siXlbrGVnMxrrRSbsK1jfK/ZHEMFPMPZz4QzY7Rd65mRcnECyjmO1kZTpsmzHDQoOKKwvgiDUZA0io2UaMrygbpGieQ65vEN2IC2hoTkeH0OKUJMzidCeZrYmIGZ8qkfbIhjUnKNecZ7Gqip0iZjRunxYKk1IJK30WkxmJ5iK+3mV9rxalzRYXIGufr6BT1t9o0YelDmpB5oXHq0qGJlbqjznFIbQJVgv4NZYwyTl1dJRvtegu3iEgbViSS232Cg4U3b4MoHu1B6V+b92tNQ5pIJGaV00OdKKBvuL6LOp8mLLqWqYsShp1DmthRVW3z9uFL+XLqaH+qEfVQkYZTR9GrSDgUS9pUfNOECchlovk6hH6PnCep0f9Av15pL1EpYJCRkP2d6zNRqlT6hg2pouZwppxBEeE8fVVHD+pEs1lCmhTZMWeFKi5puXGe5cw0YekOV2IqsBwT0oR1OLLVTZFa1bTrQX+IJAtpskUkU+rqLJVN1VwEE8NdSGnCEsyvzk4MpL72yPxqiVNXLadO53jRTUVZFGIFgCxmUX9dOTW2kCasK79RA+m/46aUxJtMmREj6cQvc4FqsNIqhwrtebhu0NKhhEEYnNKEuZiY6cEhafw4E1/pB0Xhc0Ea9fmbxG1k0XsNKbSMsVKnplTlcqAmOn7jpkg5Y7aNGzDXJhpnz5p1oBqOp6KEugYRlp1IHBF+w8KQsN7QMCORpKVBGEi98r30m+f7SNdBLYWjgdQW+b+Va7M0YfWVbLTrLYyCJp6CyiKnCRM4SVE531Mweak7gor5tXZpwnjeR6BuktzmbIQ00c1S3rkfJTOu+h1HYidmYPd27c9YQ4GsFVnGz3K9YX6twUIr5h525dQJ85c120gHGDWkCU3hZOHUGaFxpD4r8QWpM4vIaeUUZ9HhQmrXrtRZh1hVUIpFnb4hek+bG7c1o0tZ2DXGQApVNIf0leMfOoqucCv3YRMDzXI8DNLnJxy0k9qLxEoRcKiPPYAaMSwdxyQWssZqnDrempSlCdv6JBvtegu74CcgbtJpNgnhs5kROSHZFtqDAoAIqZMK+XFiJO8zznygLgq2kCYqUpdsfiVIhVqPwcmSza8UaXSOLO/CqbOaX4XxS+CEeSuhLsKFlAA85psw7ytwtnJtdB82pCCqTt5MTG5jwvxVx4+amKX3z8UZypYmTGlXGxrfORKVUegb0jvGbtzq3E4KaaI+coPTJ6CNan1pNn71XqL33zGzSzySro5eBjXEE6GXEMpq04QxHspp04QZ4VKcvJ+Fv6Eq/Jn9tZ7SsKU78IYTbsFPCHdReTnJy0E5MFR8XyrCN+nIlZS6DZaQJt7cEFtIjnjBJaahgNlUNK+r0L0flJvHek/akB6KlDnyVugpmsjmDmlCA5Im9tdFOE6d6hWaJOKGx8xbrzRhFhOzr/eyanak5le6wcZdMusU+UqJyqRKD/CcI1F7KqpkmJ8tGzdXTlBgNcWBcOo0NGdzcOpUhTvJ/Cp6gychfJTG4HmYk9Bcb06djfcmrA3O3ugUjawonkHII44iPUAtXwOnrEzcJUPq6ix8nDphw6oUMstARW2SlEFHFI0sCkMQIXWy+dU5IXYk1NFA480RjhVjGoo9HIkyVm3ux3KntN/4kCaeSlUkSRklXJEuQ6mMvrdfb3CBasKpUzhNvp7W6rWi+ZLhaVEzlmY+J2YnG9JqzD++36rZjTqziOZntk5ybUJIk/hriYju4iGNslKlPRteOSl5uEpITWB0v9IAo8ASTt1mI9Mr8yc1/cLxULbZ0oRVzalT1086x8ofvakx3D0m3Af9W7k249TVV7LRrrdwG06CaU48cSV5VPputGTB69DMr3aF011JkM1fpsKloAC2kCbForKAORKeqfctFEXRMm6m+TNqN2FTELg1lcYr42uPQUaRRrvibgQ/rSmnTqk7hVlXQjFY87fIX6t8riBZFhRM4nQmcdvCYqXe6HvpmXJUgBjpcjg4KNfLnDp5jhghTThnCEMpCBiFJ+oLZ7aFfj+C96uh1AlIa/VpwhyVQwtv0F6OmKarDWlioQi49INNE0bDnfg6KtBDtUoREBy91IMOBSWcw75kUlPJzK/1FmbBTw4iLPAvVPMXJ968DX3D60Cp3rUtQ3HUi0XkLrjbbKIXKLzz6wiam9HA/E4lLBbRcOiX8Zln/o5dAF3JoAqXghQkpgmLQ4skCEUK1SE3yNPMYmQgjSnNvkS8kUaGk8gK6W/qzYTtjLJBpjEnJfGNGJOemSbMVBhsHq2S92OSGZRmzdADYkvmY9X8auErJbWLqKtF43db2bg9hzRhbJw6VSlIzIwgm1+tJrpqYpmp8yfhcBMLVYrqlCbM9PBOiVBaQ5pYkFYHMZzANPN7NCd4pdz4W702M7/WVTKlro5ihheA9nfqNGEJHpWuJzW6KIzM9WP4pvVY2zIUrw/kgK5NXCmgbXjpT/Z3RjrG4r4Je+ADUBZHlXjOLri6aYCmCXNGoAROTalSimYlc7J8QyLIIU08zUeenLrNGdIk9Bl/VUTTFIOeSSFNOBK+1Xzux6nTNjqqVAlp+mwhTZx4m9r3wrvtan5VUSyVt8o5ztAmVdMkoT8oDRhtmhklFDRcQnrSbPwqp9jZHFrpV7kD5WJJ72/5X4LmO4c0qVG4D9PRLP7BYpp1Rero2qiY5ouCNcnKqavhWpOJs2RKXT1FIjqnDGmShPB5w99kUWhEiMvu/iGWDhmFEaeeis5j3m0U6b7nPqz61S/RutdeGPf1ryU2cdMj83DZI0uxoamNKLmBuaionAyJCwUAoXtIEymifukrhwXbQBNdlTFHBdzTezdtmrBanJ5VhSdUNxdX8QjMKhPO1c/J5vNYEaXlxW5XNmUzTZjw/nGmQCk9XlJ8PGnTtI2zOhdVpYrb+BWlygxeazHbxtUL8z8IKorwZgpposYJTB+nzk0ZNJ0IHA8xtFwkaRFzCgBovGP6m6elxsgoUlkHQymkCRfns/KFVm8m9ZFMqaunCMpXYhDhhDRhsqOE5ymYQcraBzZhp3WLMaZlECMnDTOKrBtSxLJ1i9FenIHJzO9UXpk/BADQHWWpUE7KYriTIDBj+WkIW+h+r4RczYY0sZiE5ITanpsClbTE6ySkQVmMnb0nXUXj1PkjdVKyc1ZRSDD/lX5KNm1KhHenNGF0/CROHYfCpE4Txih1CR7GTmnCOO9P29yW6APS/M/lgEKh3H/1HRPMr6k4dUqfpKw7VMh76OzoReZf1WnCEpT6xH5wYUuqTRNGnbm0kCbEJBuJZn6lP1VhWs8ktWSjXU9ROTkuG1YkUkgTiZMUt5fupMaaJkWCvx/yM6ytEQDQ3dSmowjMJqmZsYwNtLKCeKUJIygGDWJc+jcZ6Yn7Jz0bKgnPOC3SkGx+FZSSWvBcVE5ZGk5dgvlV66PoIc5sKrZwE4L5PNF8HUJ/fzVOnQPSaMztBKUgIBss1PfBYYzV9lT6hvgeKRQHMEqByGmUqCGK8sRRHOKPVWz8ahuheh8WIZ7BVqqF1hZ51s6HOXc02kU2a5owg5rAILUSN1ApZ/yWWV/rKplSV08Rza8Jyplk4kgKk+Eb0kTgmxh/a034LcqdbU0AgA2NbbppxpdTp5l0QnmMiJjhFtT7cjDfkfIamdgmiWFrHMeRhnFI2uhVLpB0qEgr8aYKf1RYKS8pRdqzEjzEbWnCrEo5RWqSuG2qUlz+TjRJ0ra0+qnZXGiXC1fkaupX6g2LJNwH5dRphyp949aUAsopi7okvP+qgqA5e4hk+uRbMkS9R8d1SHr/E7lxIsKb1HHy3NW2keI9FDl1lt+ckTrhUM/VHUkW0mSrk2y06yiUk1P5u/yvxKkTNikpzZLSIFtOFAkpA7MYxz9EZR2RutYIqWvVlJJAUdwob0VLIRajMfpm7ky4tpG4HYj2smnLcTNJUNwTR1FAGiWzk2bidOVkOYo6/7zjFUJVigSTquY9KpivueDRtmcicNtcxs+4x0SPUPUdJwpsAok84MydPmhofO8KGq2abZmDk8g3y8lpwlj+YLmt+Hfq1MSUT7Pxa+ufZ2aIUl8UnqSj12xqTh09jFSdJoxBUw3PXkeTdCSRkgz6buTEuW5NE5aFNNkiko12PYWab6K/k/hWEtSv5KXkpGaBgenfeiOlrji+uJ1lpa6nsRWDgwXtxZfi1CEhTZhqBnXO/RiXM+/RauYim4Iz0iDxr9S6aP2MmEplwsKpzK3ac+pUFCuF+VUIaBp/4pQiS0gTl7AtctL6BPO1Nsdy+m+SRyBjPjZQEOk5UIeY0gezXkEC6dkI75FqTqYKn0uaMEMp4zyj1Xbje6pi49fuxfE9pO+Pb0iTmFPn+CwkhD4tQklNpBrvTZrbfkqdgdSmThOWAr3PpGrJlLp6iojUuXLqLLwVTnxPagJSZuubbyqaziFN8d/re/tZz7zK5mz+ZvJFADWFU3LuR0EpK91M+V/LKZpycpxDIpQ3BcFW7qyAU6QhkVOnLMbKPPFNT2Tri5YmzEdZTFSKVIqCwOnhUCDbvDd4Q0nKlVI3RVMDqU/msxQ9S6X5Gl+vKK0+hzTObMyYXzWlSkB6tHdTDGkimF+J17CYJizNfFTvpej3HhrlEmkP5X8dApRzfXRypnEQ05lMRmF9Y1Ja04Ql3If1tyykSV0lU+rqKDTNUOXvJL6VsJgnmG19T8FSsvNSVRLC5IcGNuTzaB0oxbNb1zMAzXxrWVQMpYgqY65Il5DsvPTRRSkg5k9XnlNSSBNnhwuqVEbfS5crz1R9hjXh1FVM4qnShCWQyNXxF7NPsI4uFkWBIrUJiImmjJE5JqUJ4zdT3rQlbnhx1czBysP8quVeDVTErbzxq+9vvJ6Q95/L6BJ3SXjvtHFT31XST/X99xVl/ngH7476lphnLyrH882SlLKKkpms+DuJzUOZOrN4O8pJlhJz3sTiENIk49TVV7LRrqeE/KaaxLeSYGwpJERcLi2nji74yndMI6UmXBeOXA4dAz0AgK6efv2ELZGRGRK3jiJ65H6UHB3Uui3jRjcF18jyrpy65JM/5dQlIBSW3KXVSrVpwmTyNTMWkvla+1yet7D0ReBEihsPFxKGmF9NkyKjKFLkLUEpYGPgOZPziRKs8eakjdtEakKtnDT+wvuveV0noznp0oSp8y/+MqlQ5e/QXRkEUc5qFtKkWk4dkxEkdUgTKQWZxfuZpQfEH6swrWeSWrLRrqeo5i/1+6Q0YRKMnZaLJ4nk7q/WRSWF23x7fy8AoKt3oFI+Z4lTh4Q0YZpnYkIHDE6d8hs1jXGLoVpe4Qu5hlKRMkqkRhoSQ3Io7apt18L8Gpvkiu7joBXnDyW2OHVWTh0NN8Ep5ZL3c0JoEX2OBeZvqjCbqZjCKem5ceYtl01afV+0WGYWxMn2W+L4k7GO32XhHuLiKcz2kajrnyvSbby/jmtkypAmyQG27cWpmGFHlPWzyjRhFI2tgAnMoToSG+86C2myRSRT6uopkvkrYcOPNA/jNCvxXEh77ic1YcMrNcL3zJdLpSF1AzoKSUj9umko4s+QBQsANOUqyRxC7pEgfvH3AL/Rayd9B6WAlvM1sdvaL6reewlmPBrSpIacOs0M7VNvglKk806j3wQ0QC1nUzDV8aWmSU6YOHVxvVJIIVYppQeW+Ae+3cCs2wt555RR5T2K6tPRFIWjVipc6aPIH+Tff9YzFTA5pdWQ6ZX1L1VIE+X9dU3z5xvSRM6E4rk2037QecQ5usS/OdJv6D0qimfSfRh/K9dm5tf6SjbadRTR+1DYsOJywsYjxclSSpIG7BLQDY/xLBSb8EADO/pLSt3a3gHlxQ+MDVfjHdFNjnLq0ihFBqeOLthccWK+cWzXPaOEtRqZEyaFxtAQm1qbX1VOUwrzazwm5Htmw3QLaULM50lIq8v4KaFFqOLAIY1y2CLKdxLQ97ioohRVKjfuQRRlbLWDk2B+RhAY64lTmjBp/KR5J4Y0SaHUqSFxfB0XorYdy6VOEyZSZGpkflX5p55zTK6bob+IqDqzfkZiOxxnstkkG+16irDgu4c0oY+LWfjV5nxRNAPFsizG6nVwOOkqbbQPlMyv6zcNykiXxhezm181vpiX+YXk86R8vQSlYHOENPFCGjWzkwcnTO1PNaIqHq4hZbSuCfPXYn4V+WtQUVx5wzTNrwIKXilQ6WNIvrOZSGlbKdOEcUiIH6euqG3ugTR/k9KEJXAarSFNbJy6KnhXWiw/z9AkUTnfNGGGpSAtpy4tQknfAzakCZljrm3Eilv5n2pDmviafzOpiWRKXT1FWvBdQ5rYyMhse44LHakPiFAMy2JM+ub64gZBEJtf1/UOaCgk3XC0RUUyDUDfOJxzPwLQSORKnVb0zfA+dTWjENMWkc0f0qQoz7+0os6/VIR3E/0RFc+cMH5pQ5qUr3PmtnG8Lc4kKVAsxJAmSVw+jojuYX5VPTw1Z6ToNw2NIc9DUwp0+kOlT4qJVms/vkBfnzZXSBOJokJFWOMS1w36rF2NIJIVxrVdqT6KpgZMSBNfNDDuK1XqmfUXMD8LTjRZSJP6SqbU1VFk93/hFBQXFF5O1zRhzqgMQYE0Qo+EBvqb3drLIU1KjhLlL4n5VXNiYEKa6AhbUR4jImLw3nLt8felq80KJBOxY5qwROXYdXMB3BxE1M2omg2UE3X+peHUJSBdmgicHl1hIEirA6cukdOlbsrkHlmekWh+pXynhHYZYrrXu6YgZZripL5jUJU01XwXKldAR4EMNIbvE4uigby3an2pzK9RG+5zW8wIk2h+5Q+VziFNjPv2Xze19lzQVM+1WbSGBBZrko13nXHqtohko11PoeYbkM/ChiaeZpPK2ZQTRsxwHQJXSG+k9K/HotwxWPZ+3TSoL450wdU2I960UL7Y78SvjJue5iYZ6aHmu4qi7sjJEZW68gKY9KzoAilF9KftUseTGog1hZaLcB51KppoQboq1zNlfTh1CZwutV3jUJar3L9WZ6Ww8bdrCifWM9jHxB1fE2qbu+kopPxmJIuvvNuJ428NaRKa16t9QLqNP3WaOvX99zSjenPqmDlSqial2VlEGnPec0zuK0MRELyfrbzrLKTJFpFstOspkqeYM6dOfzmT4tT5ntREd3+1LiquoQQU6Sgjdes3kTRhFtNQYkiTlCiGvuHQE6qEoqhmR0eESgpCStv28d4rFpMXTm0xrq1Spx0qUsyDRKSL4dRZQ5pQFJfj1KkfPMYPUOZK1C/Oe1czcSv1SCmcpGdhGZtExR8EKVOpCZRTpyq1kvlVJcpLnDrJirAZOXW897VDOfU+XU2EBqfO8b3fXGnCAEMplVPguTaim/z5FGTCfTC/ZWnCtoxkSl09RSKuShtWJBIZnnpCSe2liFNXOuEnm8UqCJn7VOoYLGeU2DQomoZETp0U0iTm1LigGIoyTLwnnZwJ1E3BNSRCgok9PdKQZD40za814dMBhG+WYgH38h4t/yuF1FB/i+9T7nO5sWSEVwmbYSgOnElSmD9iCqeENGHqfPFyfFIVTlXJ1cz3FA3nkR7Va5auNRInkUVxSwX08jUJaVJ0fw+VvmpxJhMdJcr/kgDl9Q5pYjUfS3MsbUYhFalNuA/jb+XaVJ7NmaSWTKmrp0gbH0e4diqHdOUEMVAgm2sTbcPjxW0fjJC6Qei8OWXDCaGjYIZpQd0oil58sYBRykofi/rClIDUaUqgK8ImmV9dE5IrbbkET9UWah+lwEVSpGnSy5uKi+TMIaHZbFlX86uG8CZx24qgqBQb0kTtj+boQQ5uru1ySqsHGq09G3pwAolTR+ZoyHLqHBEnDQ2z0DhSrB+xpJx/eriYBOU6+jWt+VWypqTk1Ine97VME0Z4n4E6b8j65RTSJOPU1VWy0a6jiKTihHhzEoqTxNPy5m1I7v6AiDAlcbo46SiUkbq+gr5RaiiKbhoKKPxPzFJpUAwN6YrqFpQKvbi60buaYezPyst7NL7HMLmcmiYsDZpmkdgMGDooR3wFcd9ikZA6afyYsq7eyyrS4ZKuy3gPuT5JWTvowS0BqamMLXOwchhiLS8th7hEfYh1GgaNceHUSeOnceosaI7PvCeSKk2Yeo3PukHMzzVLE+ZrfzU4oZyJnCLWfpw6A6m1cOr094/+FF2bIXX1lEypq6dIm6rrhk83zESeVsqTGqCRcK19S/HiDi0jdf2FEL2KUiRme+Bc6jUHB89FXV28KNLjYX7VzTeunBxJcU+BNKgbplROPb1vLvOrr/mrLF5IlzR+GgpE5gZzn6nThHEBbtV5UOkE25YZ0sTxuTHvoJfir/LmuJAm6vw1vCeV+aKOgyrC+KkKouGprhavJpYZhwY6OZEo9+nMqSPmZ9f1RrKm+PSXrRBkbAPzkOSLBhJPXc18K96H/GyzkCZbRjKlrp6SllMnxRviiNpceykcJTS+RqkRvmcpIPbW4gByxQIAYH0hqJQP6IKlKIw5YcEBNDK2f7JzFWVx5NSpSJljLKjE7B8+C6AXp06pP63JRxKWqO6xgHOKizrPNKWu/K/F/OOMUHAeweK1CsJG5xj3TItS/6lpK/6Bb5ehZKTx8NaQMmJ+VZEeg2+n/qa+mxSNkd5/TnEC5DRhVYQ00eJU+nDqVKTW0eHBUHhdvd4Fs7M3p47mfta8l+nBwW1tiuum75jCIZUzulgO/invMZPqJBvtOoq4ACZw48TFXPJIqpQkDdjFCNchEdi5JrwyCeTQEWWVKJT5SYlx6shJmSpjKc2vBqdOu89k86tzu0lobApHDxVpTAzJ4TtGDhJonKYUCiOnKKhIl9aWtKkwKFmS8sp5PzuMH+UIpUsTRs2vCcqkFitS779VFCcOLodyuTP6oUD8jfE+j0Saf6L5tTbKjdZm6HC4UcspbbuaUWvNqUtEaiXROKHEUiCaT/3Mr6biqpp26fplU9hru95k4ibZaNdTBMi++pAmkjJYzUZLTZNS3/xNekEQoL2c/zVG6mymoSApTRhjGrOJsuFYOXXihsugEEnNSuaruG1Hjg4EpDGRU6ea4WplDqlsql4x1CLhAjKLSBe/OVKUzM97WZ1jydcaigOHlIucQIE+kMTlY1BMNzRaGS9l41dNqdT8KKUQY02z6nWlBkkHoj6T8THQHPd5b4i6/qVyIim6lxNDmiQd5gRrSryeer6LBu+YQVo587lH3VHPNMVTyOgSWvaI1LzBTKqShi3dgTeUSIuyeAoi5QyEL9B+NyQNbyOXAwoFOYab0DevRTmXi1OFrS+Wy1FOHUVG6IJFeVg+ZpwcsxmUP4ucLlVYTp3jib3GIU0q5l874mOEr6iFcGYsjwWcS1ovKmUcf40rKyKherthqUAypysw7zGeY9xhTBljjVNHw00kPTdOYUxhftXnSOVdi5FbDY3hD1Wl7/lN3ag7bl5VKhk0NfpYzZxkTMxO4TNUFNGZE1v+lzpqOR7mDNqza7tCN6I+OKUJcz7UU6WQQXElpd722zbEqXt47mpc9q+5+O+SLqzo7sNvPrw3jpgzzlrmwddW47s3P49Xlm/A+GEt+MzBM/H+fSbXqcembHdIXfd992HeiR/Ai3vsiZf2fQsWffozW7pLFRHNr9KCWRbpxEPhdqGcFzKTUxZjLoWW0UQ6NLC9v2x+jZQ6slGGxaIeUoGmCTMIutG9pkS6SpVCu88kTlYaTp2oHKdEGpOU2TSmYlepNqQJ5/wgIF0SJ9FwUlDNt0mcSBeivEpxIKie4ZGt9k9yhqLhJqR5E1+vVu2PRhlpwoy6lf6qpj3tXipIjTj+gvmVOh/VNk2YMv4+qJCqaDm+d5L51TlNmMA32xwhTVilzEHM4MWKwujCqdsO0oT1DBSwy/ih+PZ7d3W6ftGaHnzk949iv+kjccvn346P7D8NX7n+v/i/l1du5p7Ksl0hdetvvwPLvvUtjPniF9D2lrcAhQL6XnllS3crFpH3kRjShN8w2U1Fa88fRQtQWdDZwKdUEjhdrKhIXcypU1AElDuhmjZtIU3UQMlpUQwQNAuyMqxz6hwXziQTu09GBnVTTthctMU43kBrxKljzXg+iC0zf6Xxl8x/FCWTzLdauwzCKJpBlXs0zK8Mp04ahyCn/56A1HAopg8arSnBpFwFqVTnr5nRpaJE2tKECfOPcWLwKu8geoBj90OFll7MN02Yo/mclhPTa/kilJR3zPDe2ODRPnUzims0T4z7UNdPqvBX49m8heTgncfg4J3HOF9/9cMLMHlEK77x7tkAgJljOvDo/DW44v55OHCn0Zurm1bZbpS6cHAQy7//fYz98pcw7H3vi79vnjlzC/aKiHA6S8wLKi3mEiSeVM4mGorBbChGG/4vbhAEaC87SnSHkTIXIXYl86/OBcrpm6v6Lyhi5YtipFAKVLOPq4lhc4Q0oZwaa7uKiapWi6zG10tRN/UIVf+WlCIpwGn5NzH3qloVyvpt0X38tEMOOYBw3rt0HIy8qmnShPk403BcypzyjkV9UeevzfwqUT0SQ5ro+ZVFTl0a3pU6Rj6IH0e/SCynW1NC8n1iH6WQJr7vIqWoqM5wgfo9zOfuUXdIHGUQFMr9pvcR8n+rn7eC3K/d3d1Yv359/Lm5uRnNzc1V1/vkgnXYf+Yo7bt37DQa3/nn81XXnVa2/GjXSDY9/zwGly8HghzmHnc8Xj7gACz8+Cew6eWXt3TXKiIRVxPThAmmRcd8ol6n4NgUDH1DERTHVImpgwAdZUeJrmJea5dFRnI54xRphLKIFzCXRT1e/Yj5gIQ0STK/KmOUaPaNOTlJCrgfp84rpEnNza8M38xLubcgXRLx3iBjq88PBOmz9zvmldkuVh1c4rke1cPwpaRxoEpaCP460keeU+c+R3Tv04D8prw3xPyqUhNYFCi6THxeDFJY+oIvn2ZOctw4D6Teq1zqkCaCFSYlQmmgqTUMaWIo9b7mVwFF3xrShM2ePRudnZ3xfxdccEFN6l25oQ+j2nXlcHR7M7r7BrFpoFCTNnxlu0Hq+hctAgCs/OUvMPacr6Bx4kSsufJKLDzlVMy47Vbkhw1jy/X19aGvry/+3N3dvfk6KS745X8Tzaj8wilme0gD8SvcH13JlNqIyvm1UUHq8np5ZTPQA2tS0wJBdzxO/IFKCLaFNBHNd4z5Jolbk4TGbrY0YQzSVDOkrvxvWk4dp7gI4+kU0qTo+vyUdpPmL8PbMtKEcRubZI50CJBstFuWNGi05n1KkTqaJoyY9lROq0j1oM4jpH0a0sR0dKli42diCDopMJqi5ab4bDVpwqIyEUdWRVopx9rTUUFTMDWlPkAYCuuXxIfV2t/y2NHzzz+PiRMnxp9rgdJtrbLVK3UrLroIqy//rfWa6bfcHC82oz75KQw94p0AgPEXfB+vHngQ1t92O4af9AG27AUXXIDzzz+/tp0WJDHdl8S3khbzBPJ9Kk5dxLdReVKwKI5pzAi5ClK3vozUBYG+4VBvQ5HEW+qcn1KhOhpoaKSO3MmcOtV85aiMJTm1EBK+vS4TaRRP/Gpf04QdsQjr4eiVJkxGuoyxd+TU+XgvG2gUdymH6hn8T/VgkIBcGZy6BC4fmE3T4V3TTPQSp46g4Vqt1DTpzakzlWFb+TQmukCxVPjFqVMOjp4hTaJn7ey0wh1cYJknLlJW6tTDLBtLzge9pH3R1otcPBdM3lzI/l36XIVpvcbS0dGBoUOH1rze0e3NWLWhT/tu5YY+dDQ3oKUxX/P2XGSrV+pGnH46Oo87znpN06RJGFxR8jZpnjkj/j7X1ITGyZMxsGyZWParX/0qzjzzzPjzkiVLMHv27Cp7LYi0qSZy6nioPylOXXUbbcJiHEnK9FCRUvdasQWXz3k3WtePRNvNz2PNzkciHBjAsH8vwYYRe2NwzhR0vNSP/JKVWDfn3ci1NGP4zc9j3cS3o9C5AQDQuqYT+b4cNsx5N0a1jcEX+gfR1mSZ2vF4E9OQqxlRRUhdzSgsR0pp2otTp86XBKRBRYhcTcWuoh1GynX7hDSxxakzxl/nNBnXAyVkSUVEkhxdnBBeRjkiXqSc967BqTPMr0lmc2ZN8OEtMjSG+LlzDi4B9LlHTZOqGVoR6eCoOzHIaE4t0oSFmqOOC/1C4BQ6tUWeXyKnrvwvfe19FS6mL9SaUTkHRN95ooEqUgvlXjVOnaCUs7+l2H+2MdlryjDc96Lu6Xr/K6uw15ThW6hH24BS1zBiBBpGjEi8rmXXOQiamtA/bx7a9t4bABAODGBgyRI0TpgglqOESZVMWXMJpY1P2LAqBbXrKsX4hTaWNAuHZtrT+WZsz9KYEYIAIzd1AQBWoQnX73gQsAHAv+cBU/cvXfP0KmD4rsBwAPMGAKwFdjyo9Nu/5wHj96nU113+r/z79KeW4qR9d7A0byJdAAyOiiiMMuNsvhGV46huP05QMies/O9m4dSZym2akCYs0iUhPyIaAAMVSkwT5vK81fcB+ibFmiQTzK/OfCetXZT/TotGkzmiKqPqoUTd1CmnlUNVAXnjZvhupTYp0hpdnxKxivqQJk0Y5RRaxDiAOHPqEhDmVF6/jDWFQVM1pcyt5sqfGqfORn9w4dRtefOrq2zsG8T81Rvjz4vW9OC5pV0Y1taEicNaceFtL2J51yb85AN7AgA+9JYp+MN/FuCCW17A+/eZjAdfW4Wb/7sMvzvtzVvoDrYBpc5V8u3tGHbSB7Dy579Aw7jxaJwwAat/dwUAYOiRR2zh3pVFXPBTojiuacI8XirW3R82xTHFaSyXw4yuxThv70688uSL6HvpRbTuvTfa9twTa666CmF/Pzrf9z5suPdeFFavRscRRyLX0Y6u665D0NSMER/+ENb++S8o9pRevtY990KufQjuf2k5Xhs2Ccu6NiXdZLnvTCo0B+SA9exLUpyTPJWjTckF6VIdNRJCymxeTp0yjmkI7/GhJNnEKG+O6t9ESXdR1JI4XVpoEKI4sI4ewnzwTRNmoC4Qx8bebxj0DR01VNEYvV63NGHCwZFFQ2GuVSkdBkplTDTSaWyUsfUOaVIjTl3V5lcwlgKJU+dqfTXyylbqriCU5D5c0oRtQyFNnlnchZMvfyj+/N2bXwAAnPCmSbjoxD2wYn0flqzrjX+fPKINvzvtzfjOTc/jygfmY1xnC35w/G5bLJwJsB0pdQAw9stfRpBvwNJzzkG4aRNa99gdU35/JfKdnVu6awBkFCJtSJMkLp7/SQ36YmxzV4+/90cDg6Ckupw4ow1dzyzAuuduxujDd8Soo3bBS+ffg2JXF6b/6Aws+cvD6HvpJexw1vFonDAOr51/M3Lt7dj5qO/hlR/ch8EVKwAAI98xGY0TmtD3rxfx2rBJWNfTb++ARuImKIvLyZ0zXyUptY6cOu+QJkmcpGrDjlj7wdSdKk2YiXRJnDpbSBPNG1gpY3YclX4njJ8Wk5BuxGxIE6HttGnCNO9e9wOU/myI4sohlQHJ6KJt6hZOnYA4VsaNCRukla9m468g7j6HilRcUGIVCcn3ieXEkCYpUCzV0qDNSd7E76wwE0cJzQksIOhfJJY9wtv7diuQ/WaMxPwfHC3+ftGJe7Blbvn8AZuzW16yXSl1QWMjxp5zNsaec/aW7govCpytieQhRcqlTRPmGxi4VCWj8LBdS7E4WTbKuKcq6qKGWyhfb5jdiiGG9peQuzU9A/b2ORSDtulgfnUJXhuJEWePyGZLE8bw/zZrSBMvTp2pKMgmRgGVpqY9H0cXDamxc9tCTQEol2dDmvBKqZnCKf6Bb5cj2Ps403AhTQinjk2TFQSV90BDWsplaEgSyfs7ZyqV5QJ6+WpimXEm3rScOmeknaJgSYc5wQqTZm2Ou1Ixv6rrr3csRLPi+M/SOx3/kBiaxfhbuXZrCGnyRpJtR4XeHkRalBNDk0Qvi2DSEU16KSB+VXnS6pX6lsLspi3G5KSsbfTKgm+YFijCVoyVuiSkLtDI77pSUNFNLGOmLnBpzTdUJIXfUpdLmjB1MU7Ff7SJwtdLl4JMQRxA/jTMrxKnjpR1mfO2+WdcqyhuRGFjEXZps6dIYyLCat6vl8mO89olnDp2vLT3TH3/JKVa2LhFTh0p74E+GqL1yQFhj0Q1+7seygTza93ThKllJE5d9K570i2qQmrp3+q12xCnbnuQbLTrKSJfSDgFRcWSQpqIekIaFK3SV81dXTS/eigjkWhIGVkcFb6IqrAYSJc2VqXFOfKoXbPRzfyqKY7RvTicbtWF2jdNmJyn1wOFsY2f0K66AdTq5BxIm4urMM4AoonYZVMpOoa2UVGXpE2d8SKtPGsTKRcV53jOUKUgQZnkzFs+JnomlqE1TRbHwXRIE2ZSSipzVEfV+fLVpQlTFVcf+kIKTh1df5L6zdAGnAKcu9QpcOri/vlSY4TyJfMrT38Q70v9bRvi1G0Pkil1dRRZOUvi1PGmhSSTXpqNVjtZOphf0yzKHBcr3iAZz1Q1pILBSUKEWBXR2RchdUnmV0ZxBNwXQpv5Si5k9FuVVCFNVNOWR5owPw3c1pGoTcX86oUKM2MijQPnVMGVdeiH5v2csPFY49RxirqEPAXk94R+srlfaUYLm6jlqeJq4YTGVatz2yWkieDRr/HWSgUcyztIwLThbX51LVeZf15KGX3uUbuu5dk6VYRbmEcqJSKN+VWjxuQ0VF4TG1+yGtN6JqklG+16ikQmTwpNEpP3hdN/Evl+M4Y00Uw0rsJx6qhnnrpBq6fQmFNHETY4I3V6snN/pYA3XyWZbxIU8Oh2PEKa6JwaoVzVJlKLaPxLD6Qx6pqPiZG5tvRRUe4V5dKqlLOOAg5KsUEV4NC08jgQJUVM4SQihLLC6Be2g1HmOS6kYZolSkGgzHlVpHnL8dbArHE1MEOqXsxu3q8qfcLRbKu+vw68zfj3eBx4xTYdQqm8/8r81eqiSpmLUKROGdNtPU3YG0kypa6eIpHJ40VGKubI0xHaS5P7VTNNWNpI4nSxoimO5MVXUDDtvoWQEFFfUSyis8yp6x0oJOTdU1EMwqlzMHFVlEIHpSqSJE6djwKubsqJnDql3TRhR2xSrcLImXSETd4ppImrMwjnDCSGFmF4W4jMmEyfJCXF4IQmPG9GGfCLU6eYPyUHDy54topiW0j4sUhIvRrDkFIctPJVbPxaSBN/+kLoSLco9U99j5QxSHoWnBOcT3lOGL6ixntDtDb4Heo1BVW1Wrhy6raDkCbbg2RKXR1FWpTThjRJzhnrj6Kx6YUsbXjzNgDd0YByYVQUTA23kJAmDGERbYObkC8vnmttzhKqo4FBtHe5H9l8ldRmqevMWHpsSoFtU5baVfiDmyWkSRrlnnoUAvJ8SuJ0lf928iJWTWIJ48eiusSMqR1+pPYF+oDM5VP6GFdO6rIIa6KPOXWV34w1gnn/rZu6wGXTeacWNKeKjV81o6elLzh736rP2sv8qlA1ot5Wy6lTQQAVoaRKWRqkjLMC5HJQzc+q2HjXNXfMysRJstGup6Tl1AmIW3LO2OilTPFSq/C7tW/8om5vQj29UvOPwAWi5reivpGGYYgAQCcGAQBrN1p4dZziGNXp4z3p4z1HPcuI+CFdKt9KQH/JtSGnlFQr2vxLoTByDkIJ5lcrpy5UkBcrp07hySVxujhTLUG1+P7TNlUEPHlT5+PUCfQNvoK434bXPev8YfZTU7hE87egzMdzLIRkeix99F8/YlG9/z0UXjD3mDimiqOL/vwS+s05s3mYb+11kpAmZI3xDmmiXKtaURAE/Ltabof9W702Q+rqKplSV1fhF3zpFFQpJm1Ugf67US7NRmtC+2pdZhMpTmOqidUgagubCnHX1zl1FVRhKErKnBWpiw/4RWNRclKuVNOY66aUoNR5bUoq0ugckoMJbVGtxM/Rz/swLp4zFRcJ6eL4d6WPof63J6cu2STNIDSRAsRx6iTEVW1TvYcEhJVFuTxTYTmnCZP6qRyqxJAkkhJucOpo+ai/1ZhfPZQzgDe/J3LjmHXJoT3WCuPy/G11Btz81c2v2m8+CrOqjHOcugSknPttW0oTtj1INtr1FHpijsQ1TZiwUUjhRtKd1HhEITFNmM+azPBTuE0lVJ0wBNNC5XOpnmERUmdR6nQuFK8UOHlPhv4hTeJ2qPigMBrSmGQ+5DbpGplfNfJ4GlMLoygkIT82To+qQFjNryqnKsFExcapi+pmDlWS4swoUqXLhHYZnq1fnDpVCaHmVwaNN0zKyvvvkiZM4NShqHNza7nx65aKJMRaLVgZ21QhTark1Gnr9WYKaaJz6tyrji/V+Ho5Zf7qz297SxO2PUim1NVRas6pS1AG05zUNKRM2zDtJl6/kCZqGwKKQOJrSYExS9VUFJbOIDK/OnLqqGnIRfHhUAhX803UDpF0cbZUpEHiZimLsXSoSCuq97VgdrQK6xlY7qPgTJRkfnVRslnUJSm0iIriGnOVQaKM90F4r8RQKorCHIkHb1ELsE0pApz3eez8wY2NXkYVSSnSOX1aAb2jVW386uHKh1OnjI3rmGrKrvm9S7lYVMUoDYrFKeVWTl0KpE5V6hVOnT2kiYCiZyFN6irZaNdTJBOba0gTySQlKoP+JzXxRCopjrUKaRLzfZR6VdJ8TleKaEiTaDPvjM2vNk6dgoJQ84GL4pMzlZnkiPQJ5lcfpMsrpImKmKRB0yyint7ThDTxilMn8Eeph7aLo4vmKJCgTGtIJ/mOTRPGm3/Ve3XLT2vh1KUNacKFLaGHEgbZ1ZAa2o544BRoHFQpTLN+sG14oNAceu2onKmetqWvHc22UkiTahxEiKOLyalL8b6rh2pF4c/ShG07kil19RRpw5FiQJFyhnYmRPmulEt/UtPc/QFRcawupIm5GLPBj22mhdIX8efOoBTKxBarzpomzMWcqpmohWdjNJqg1PkgXR6bWWAxw1UtUTWpQ5qYG4VkYpRCauhIK/Q5I4mm8ETfSUpxpMyYClC6NGFk7iakCWNN0x68S51LqSujuvmZoHjq3M7l5ANkUVrTGDSe3g9Q3ZxUFSYf/rA6to6WhqpDmkjKT5oDFnfwpiFN1N98FMfAXBuzNGHblmSjXUeRza92xG2LpQkrMpstlTQLh1OaMPspVF9MiogGYVjZ/GrN/6q2QfOOOigFsVLowyVz5dRtzjRhkmkzpVSdJswap45XipI4dd5pwpLGT1FczfFTNkCj/wLSSJArnzRhXiZGTeHR62QzutjoD4HDpi6uaSRrSy05dSyNw+P9Keq8wYTGymXI2uNsfhUU2ypCmhiOQbQuH0U3rpoxv1scZQxHJe63jFNXV8mUunqKNMmTOHUSjJ1ofvXfaNn4VtY2/Bdlvo0g+rH8m9KmyukBjNNyqGzmMVJnNb+qp25yjy7mOxV1cTQx1DKkCceXkhdOZVOp9cmZSROWKqQJG6eOKkWVeg3PZ/VvH0cXFX0TuW2Vd9MwZ6nzIKoxKaakM6eOMb96vc8c4sJw6gjvNuCQGkVhkDduyVxup3FUlR+UizfnxKlj+uYYZ9LwvE88zDEHbw2prQKhJGiqYQ2oBj2n813wPncxv2acuvpKNtr1FHHB5xfMSjl+4Ut0sEi10QpcGKFvqTgxHCes3K6arYHj9ABAWKCn/Ypy1plLRur0ZOdkUXJBHlWCv+vCSTiBhsS6rbtpTc+6ISF1lU3FZ+NzEtVhJFW8QmajkJQyqtTHf5I56jLnOUUtiVOnma8Jp44NaSK/q25KAbeJerzPHKfOkiaMZnTRlM9cTlGg+E3dONRo7VsQf595T4Xjfznpu+Y9JnLjOATLpRy3RitzPB2njkHII2uGpJS5isipE/Yam1InzY1MNqtkSl1dpbyAiGnCBMVJ2jBVvg8nVfGcqMkgAQ1MpThWNsrKpsLxRXSlDkWSAkxZnIflSmWs+V8571GQU7jN/KoRlcmGKQnlu1DxWQAZRUMqx4U0qdkiy5nYvOaaiUaJceq0569ukMqf1GQktqsqo0nol2nqMgL1shs2pUrw/Rc3dc6zlnLjbOKZJsw0vxL6Q0KaMKv5dbOFNDEVLad6uEOR66HMFwFj53gV6KTSrpEmTPtNVT5TmF9VRzVHTl0W0qQ6sae2dJdMqauniAtgAuKWgPDVMk2YntGB6YPRN//TmDWkhBY6QDkpKuXDAlXqKmhEZH5d52B+1Rb1qD+Jm7zSVx8umYA0Vb5z37A1pDFJCWU4dbUyh2jkcR+khPQt5JAuaa4DMjpQ9HV0qZSXlSsV1SGmYYYTKJrRVfOxOn9Fr+Xyv1zICIdNUlM4iTKvmu8NpYZDsVX6A1mj5EON+o4zSGx8T9WYXxnE3/f98U4TpvLwHPpsc3hJi5irFBXaF1UpS3OISzC/2jh1YkiTzFFClGIxxM/ufgVv+f5dmHPu7Vi4ugcAcNEdL+GaRxemqjMb7TqKc15Io6BihlSLJcapUxZlRwk4pMzWRqoXV1EcqflWNW2qi5JaP1HqojRhANCZL/V5Q98g+geF8dQ2dXVRUjZA26Cx5iv7/Sdz6jzGkeE9yQ9Z2YxqfXJWlZpYGfNB6sr/sh50vDkP0M8axhyNlRT5HvXcp3bURTObUoWNe/8ExUt7/ur8TWqXVQZclAmGN0bQuNJ4xQVIP8nclhx9oj8lxxYma4sqVcUy0+afv6Kl3mPiGil55SeJJaRJ2hzMKkWFKrOBpJS5Cmc2V83EqTh1GVInyc/veRXXPb4YX33XLmjMV8Zpp7Ed+Muji1LVmSl19RRpAYleJLGcsBk7O1j4m1+N0AtCG6k8bFWkjCJd8XpLNiONU8eYX8v1dATFuCqJV8eRwQG4m1Zs5iubMCY17R4ANwWcM5FtkZAmqvk1BaeOmb+ih7igFMtpwmzPT9244gaETkbvg3ltoB5AKr0w+0vuJ3RQ6njPYIIU2kQj9pNn42C+M94FCWmWzJ5K2BQjC0FaRZWK9h561MPco3OcSdXU64KYcmt0GlqMXmmlHnrf3PNLkyZMQbG19ddifpX5lpmaIcn1Ty7GBcfvhmP3moi8Mp92GT8Ur63YkKrObLTrKcKinBREmHqoKSVLvwt8t2oSOtPE1bITRxqzG2P+ihwltGTrJvwPwEDq1AUsnw8wrK0JALBGcpbgTt3l7rggZlLwz0RRF0wqPkhXtSFNamZ+TWGG1ipg5q8Yvkfi1BEFw4NT5xbSxNzkTKcChw1bQJqT04Qxm6aTMqGa6KM+EDSO4yAqfEM2TRjgpKCw6eks5atOE5bi/dHz4rqZX7X7cUKgzDnunFowoS9sruP4Nyj99Kk77qT+bBzMr855gTOJ5fWuTZgyss34PgxDDEqUpwTJlLo6isi3SeTUCSalhDh1qRI6qy81cyKX+pYqpAm3QLLwvx6njiJdITHjDm9rBACs3Sjw6jQUgze/WhdCLj2WS+omTgmI7sHjVM2nCXNBmmrMcWHThPkodZySK4y/9vyFeRk6pgnjlBrhek1xpQpAUJlHlb5J9THz14X3p8Wp83l+JhrNhjQBff+YA0NA+sohpYa3smp+FTb76HeuvJMwhysHDUZ//o7vL+fo5OGUwd5z2vdQRYgNSoBp9k69NqvtJXg/07+9wr68gWXHse14dP4a4/tb/vs65kwYmqrOhmo7lYmHSKYe4RRUKcebdFxDmqTi1FHzaxKnLk1IEy5NE7Phxredy5W+GxzU6yvqfLHhbU0ANmKthNRx5lPAHc1iPMycFk4bIuvFCVJ4XklIQ1DZAFJlfbD2Q1UYU6CAljRhRj1an1V0gJZ14CspG18i0spxlKgCRLNaqL9F1aifo/lrRYOVzTkSihTaRDscEcVJ5YQaceqUdtVDAOE0xj2QTJESjUMpE/+utO8lmhnZQ+Fl7jHRlBqYz8/N/MrNEcc2xa7IloIgCEpT0MXEz0k0pmrYqCBAovez5e+09/lGkM8dsiPO+uvTeL2rD8UQuO25ZZi7ciOuf2IJrjhtn1R1ZkpdPUVC3KRTEKKvhY07ycEijWlD9AyVTLwpEBp2MWZMQxRZKit1Nk4dcgGGDymZXyWljg3eW74XPxTFIfeqVk5RBqmk4ASFDkgDy6mr1RqrhTTxVxg58rVE7hYdTbS9kkEu2H4zaHBCmjDAHGs+pEmyUuqV9UJbE9zRKDakCUkTZjgjkXbVZyGPv2QuV+YGw6mrKIWkfR9RUUWfA6zN/CwVqRap4xSetMqOAydSs2Z4oeflawuDylcBQl9OXdr232DyzjnjcEVbE3529ytoa8rjJ3e+jF0ndOK3p+6DA3YcnarOTKmrp0icuoQ0YeIpNCFOXSrvJ81dXqkrIaSJX+5XzsRjLkpG/6PTPxvSJNocVPOrhNRJiqvKP7KgKJppy0OpVU0jVNKkCeNyd0ptbhZOnWp+jb70N7+ynDoB+SldI6ADrkp5TDGAOf+oaHlSyfhxaJpojlQ+l+evdaSYA4CXMsFxwJiQJpJnrB58PLCYX/kDJxsgt1LIrCvFxq8p1T4HWI1T54gUcpxeD06dhi5XGwScO/gSTp0Tb5OtOhobYn4l6Gp8ncCpy8yv7rLvtBG4+mNvqVl92WjXUURUy9mLlW4U5X+TFK40wScT0vuYfUuD0DA8L4bEHvVfcihRN1xARersnDoNvYrqdQiJkSakidZ/ZixTpwlL2hSVxbf25leOv+OP2LpkZBBDalAFzwHxZHOfCmPCxXtjzZhx9/n6NE5otOHaDg6sadodzeVSYdGDk2ZSjhyVGGqCEVJIG3+hT/HYFM35zimFaeakcijwi1OnHnQcET51/jk8v0o55VAQV5BwkHCsE2FojF+sbFVpfgWNpZjg/Wz8rV6TpQkT5YAf3sOCD129Azjgh/ekqjND6uopSXHqoJ+CKuX4jds5TViqjbYov7BaE+6LaSzRYmzjKWkKE9lEB03zq3r6HV72fr3/lVX4/i0vGM2vb94ZA3NaMWRRI/pGvAmDc6bEZTue70X3nHejYeRIdJKyEzpbcMp+U3misg9Sx3Lq4F0P9VBkRTvVR+VrZA4JlA0r1TxApW8gf9uQLgkRCCvwsgsnEkUz96l4bWhmzWD5UpKJW1UKBh2Ugiq9X51CmrAOLgqyJHHqmE1dCmlicHNBFZyo2TTmV+U99KknUO7REeHjlPLUIU2qdFiS0oSpdaZW6jilkPN+Zh1AeGUvSxMmy+K1vSgwh/z+wSKWd/WlqjNT6uopLtHyw9BYmETFiXuxVEmDzKjIjrZ5JpiGfd5bDSnTF1U+2ba+YBlpwoiJaXxnCwDgpeXdeGl5t9l+03Rgx+nASgDDdwOGK7/NGwB2PKj097/mGkV3GT8UE7Xgn47mm9LNlYsxzysFCV4fP75cwCjptTK/atzCFCYl7zh1QWAqCWTuO6EomjKacPBRnUFiBV7/TVdaBKVS2xQdlIKq49SpiJsDGkfRR6IUyHEChQOngriboS7Mw2Lt0oT5Hooc10iq1LiUAdg5UnUQcNX0SZFGdk76HOpNpS7IBQiL5vPX2o8+k2u0PmUSy53PL4///tfLK9HR0hh/LhRD/Oe1VZg0vDVV3ZlSV08R3O7FU1D8nWR2MXkNenMeCkckDF9L6wOVFItywLVBOCEc0TdAacuknLqQmJiOmDMOXztqFlZv4Dl13Xffg/7589D2treh76WXUFi9Om6n47DD0H3nnciPHo1h73lPXOaWZ5dh0ZpeLO3qxUQ1BVIS0V69b9XsTMUH6VLN7knojWY+rHIzoVVrnLoUyr2NU8eNZ1mp0+aG5I3n4uiiKoiJ46eggDFVIHpWzGZmQ+NdOFlsSBMPEz1jNq4oPIz53jg4kXFNclQR8lIbNA6AR3TSzEl2bqdUeD04dWHkveyECpbnuO7RU+5HysMVYykIyPMLlQgBXikco7lBkT4VqUV5BlnN6kx/M4nlE1c9BqA0jmf99Wntt8ZcDpOGt+LrR++Squ5MqaujuOSFtIW7MHlG3KnMLJcupIkfp87vxVWRLt40xJ70OL4HAM3DLsihpTGPT7xjhtj64jsvQ/dzt2HscXth3b8eRt9LL8XtTPqfI7H4kpvRssfumHbUOXGZZV2bsGhNb0lRZL3PXDYT2fzq49TCcsISQpqEjPmwejFRrDTZS7g4dWyatoiwrV5PTXsxUidP+lRpwkImawbDl5Li5LFpwrzNr9FvcjGl4+XiDO9SvSdyffxqakiNi/mVrk3mO0LLlG4pxcGT9DkMGRqHrRjraJBQSH1WDnOsUo4x0UvruaOwIU0Ip676kCY6p45Fai3PVT24ZiFNTJl3wdEAgLdfeA/+8Zm3Y0SZB14LyZS6eork2cedgrRygknK0fyabqMlZi6RU+ez05RFW/B1ZCbaHFTenHkKZUKapEHM6Iaj8vjIJjOyvfTSrdrQT9BMf04di6z6mLFznKImmV/NDaxmHBcubIVXmjDmUGJBo+IYXGp0fnpRzHdK5tT5pAnT+UvRXJX5UuwYl5XSOAaYzVHCGqfO4wDBcuoUZZSYlON2qVKQRJQ31iZlbpCnxCaBrzakiU89rIOPD6fO3QxuTROW2lHCpFQYzjskzlyquuPiSkgT9TfDrJ6ZX33l/nMOqXmdmVJXTxEW/MRk75IZVeX7sM2lQGbiDU9fiuU0YdGi7s/b4ENKRJsB8b5S/+U4dT6hRbQNk3Ky+E1qZPkktWZjn35S9snaoSpYVLw2bNN87RPSpFbeaGxIk7ROOWWxookcX4gidYMOpk3m4CKn61LMZ/TgwJnTbWNM5q91pBgaQuU9d5nj5X+ZNGFgDjU024R2cJKQGtjWJpX3mbz5p0Fz0oc0UTl1jmukdv8eIU0YxLVWIU1sacLUNdJrbBmk1ghpUu4/tydEjn5GSJRMROnpH8TDc9dgybpeDBT09ez0/ad515cpdfWUJIcHwGp+FYMWJ4U08TqpCShWgok3VUgTzcGBoHGM+aDirk82cjWjgc+iriJdkQgL9sj2ZgAomV+Z9Fgu6FdsUmQVd3eFi0UaE5Am58DKPqJ54aWpu9w3jm/EVcMh04YJyCdciIJUiUqxicrSOHVuacLKbRQKbt6vXArAtCZ6mzOS8P6xSkFs/uY4cUYHjPaNMlDmfZqNnzucOSlaUeNqXxLKqdYUl+cXt6UoYHEFKQ7CWl8s85exdHg5L3FpwoKA1BGa10RSLAL5POlvptRJ8uySLpz++0exqb+AnoEChrU2Yk1PP1ob8xjZ3pRKqctGu44i50lUoH2bZyTl6diQH+V7r+CT6ornxKlLgf5wnCYa7Z4LnhkrfCRNWGhBDNj2y//SNGGoLIZ0zCKkbtVGlVMX+ikzqtmPSpIZUOu/ZfzEaxXEpNYhTapOE2ZueGw9jPnaSDBe4N8Vvd/q+NnnjapAV5MmTK0rnr9WxZMz23k8P8ZD2jDRqR7ukUmZOzjRAxfHD6P3ogX4Je+Yi6OFi6hWBQ/EnItTl3goY5C6akOapPVCDyzzt3JvVXLqiFLIIrXcnhCaCl/GqZPlOzc9j8N2GYOnz30nWhpy+PsZ++OBcw7BrhM78fWj0jlKZEpdPSUhUGdJOEhbOM2y7utqeylOwZxpQu0D7ZuP2ZO2oSgaNE0RywmRHA08za8sUhHXxZ/CI07dmo19GhfMC2lQvdao+JixbeNHhEtInyZ8BN8PhTeVZq7Zwj0InDp6vfH8HBQmzbSZxMXUlCMd1WL7U0xWSp2edTyPGQXK6QChKlVE4bGFNImJ9srBid4vw/MT+b7qu0nuQy1fXZqwMNX7w3r/ChKH1AGcOJFGW7Xk1NkcPWzrp0/dJE0YOKVOQurUfzOFzirPL1uPjx0wHblcgFwuQH+hgAnDWvHVd83CD29/KVWdmVJXT5HShCV5v4qpk6J6eBStqjRh3iFN0ph41UUpQgosJ02O7xH1wccJgCORI6qbX4xGDlHMr1qAVrDXcxJwG3XcsAfSpSKNXiFNPNBMB+HThKUsH4ltPF04dcLz08TK6TQ6We5iaM51LmezzXEm3nAjTl0ymqijWilN9ERxZTO6uBDtOSU8kVPHHJxqFNKEDdviwXPTkUoPU2rBI6QJQzGomlPHWAoMZzKqlDnXLSiujPezxKmL+0bKZWJKYz6HXPn5jGpvxpJ1mwAAHS2NWFb+21cyTl09xcH8auXU0XJcChquXIrgk4b3aw1DmrCpyBKI2qV/ytcYcep8zaDKuJGxq5jGiFJXRup6+gvYFDSUy5t8JXu7AtIIeCng1gDNQpt6mrDaml99vAj18qY51Yq4cN7DIqdOvkfV/JaItMYKtMLbAlGAQkbJsXnvuoQ0YePUebxrtjRhijJq9DduV6Y/OCFtuYriZA99UcXmnzZNGHuodGgv4hRWG9IkDlCd8j3ULAUCeuyTykwR41BNFXqANbHGEn+XKXUuMmfCUDyzeB2mjRqCt0wbgZ/c+TLWbuzH9U8uwU7jOlLVmY14HUVclJlTkCbChinlQjXLuS8eYpw6oQ0pory9EcbEa5hYLZw6Lk2YV/BeZdzofQnhCtqbG9CUL323NleOKeTLqWM8GmNJE9Kk6JkmLI2p3Cbxc0wX0oRNE2ZJ80Vz57JIQcyJtClMKooUVS5w6lRUlyjQ1jRhNqXUJfcr4zXprYAgQqN41EWLIRdxsiJkiSPa25Rq6aDKcuoYTmSaOakirl71mAdXn9zNoUvYnKjMZjC/smu0lCbMtw16qFaVRbrfOHDqMuOrXb58xM4Y3VGyAn3piJ3R2dqIb9zwLNZs7MP3j9s1VZ0ZUldPkVAI7hQE9Sth4+ZOzmqZKsyvVPGQQ5qk4dQxi2qExlH4HzBQPD5NGKnbIjZOXSh4vwZBgJHtTVjWtQlrg0a0lct7mW9qHdJE2cyc0oSlcWawCBcDzwuxZTY8q/eow6YiPT+uHh3hFa7luGFcaJC4AxYUhl5vm6rVxqnTTPSkfdZ8X/4uVvgYpBzlqtTnBb1cpfsWTh2TgSMVaqUdzizKNBVFqfeiqBjPz/0gp87VVPxTpk49pInQR982yPPXnksQaIcb7nAaK+zV3uMbRHafNCz+e1R7M/7wkX2rrjMb8boKv+CzpyCtmLBgcWmWaJlSA+5djF5CEjYkGQ2skrcXl2cUN5tnHsr377M5cN5/kVjCFUQm2C40RQ3Lz4YRNlwAoqqqRBqTOHUM0lS1cBu3z97MmC+pMwJ7vY2o7RBugs19Kl7PbaDEjKk5M1ieI0Ga3QIkq6iWj4lRfTb6PdrCnbDvv4P5VeL7hhTxV8uof6eYk7Z7tAobfNmdPuEX0sQ2x9OaX6P7Ds3xIyFNfJXl+Hou3mP8/MufWaSuqP+UKXWp5NklXfjI7x9NVTZD6uooRpohVcgpSBNJYVFP3EZj6ZS6ClLGZG3gJBWnTj0pS+YDBqmLNxwS0kTL7OCJYlBEMkZ6zGIjys4Sa4Om8rXplEmr2cLJ4YIZvwROHYDqNxOzJ6VupOXUxWYw5SubiZFuKixSUN7MrJ6l7kiNjkbSuaooB3H7spJd4Tu5eOhGFaoKY1yRXK7S8XJxRvGnyrHal/jdqGzqBv2BUcqkkCaGw5VSRr2lajl1cU2+6BlFumxCqCFOsSmtnLp0Ck9lTnKcOkJf8R3X2FJjljcyutjWsdBjXXyDyv+9vBL3v7ISjfkcTnrzDthhZBteXbEBF972Iu5+YTnesdPoVPVmSl09JYlvo5oRVRE2bmuaMGXhTLXRciZOrmupnDFUTg8Zk1ipZLy3OIWv1Ak/RwPNJEnGzpICaFQ5Vt1aVDh1fiFNTCUglhTmIzWkibQr6emNBsvf1QqpY3hTqeLUqeZLefxpSA32mFFw6IdKMUhSppW5QjmxfIiVqJzwjkOZvzZnDhsXy4egz3l4xrEgTTQuGncOjWI5jcL4qdcasQQ1DmIVm79CQ0gVp84jpEnUxxDKgdcD3attSBNl3Re9l1Ny6ghSa5hfgUr/bY4S1d7jdi7XPLoQX7n+vxjW2oiu3gFc8+gifOPdu+DcG5/Du/eYgDu++A7MHJPOUSJT6uoplg2Ey2sZF5MWLIvJVltIfZQ6QXHabGnCiEmrgmYwiwJFEdQ++Jj/FLOZGdIk2fy6LnpttFAebptCqZwFjfXmS1k4XIB+Hy4ptDyED2nigwpbOHXcODhsKk6bmVdIE9P8SvlnrDeoU5qwZDRRm59eYW84igOhMdickThuoo3TSJ8Xl22kciOVP6vY/Pk0YR6HIsZ7NKHB0r8+ChPLqfO3bnB1spYC0kdvZZk4g2h9JJQA7T4inl0c0iTj1Nnkygfm4ytHzsInD5yBW/+7DGf86Qlc9eAC3P7Fd2B8Z2tVdWcjXk+xLcounDr6fnIhIWgZtW4XiU/xNGuD3fyaOk0Yffkt5gMDRYi74MKNUoRDCiOxxKCKza9oLLfruZlYOHUV81E6vpQckkNF6lKaZMSOpNxUjb45mhip9yWLFDiENPEaP0Vxo3PMonjx/df5Tnbzq2ma9vEUrSjc3MbP8OaoMxKH1FAlVlkTDOVB5UvaOHXVhDRR79HH+1U1bftYGlJx6pRDQSQePFy+H8ozEkLSePVRkcrabOHURZMymutqWrBY4adlMlFlweoeHLXbeADAkbuOQ0MuwNeO2qVqhQ7IlLq6SmJeSMBqShV5K0nmVx/0RHBG2BwhTVjvUdvCGaOInMLprhRZOXUW01icVSJsNMv7OGgw5levzBxafK6E+1a/9+ACOYl6qKgiXRxrjmPNl4SfxHm/uoSbUOdfXLfAqYvnisJfjOPUmXwpe5w6D74TZ5r2MdFzz4ZwU7X3KNDviU1lRucvx8mLm1dN89T8qiCzPt7jVJR7TOdEEnodRqjCkz5NWLnNlAE/NPNxJBKnLqX5lTsAGnSD6ECvtkM5dX6tv2Fk02ABrU0lZTgIAjTlcxjT0VKTujPzaz3FdnqhKIRaTOLU2dA9y4JrFS6jg9Cv0nUpFmWNExYtxtD+jQnvWt8YLhCg8508HQ1MEresFIyKzK9hQ6VdH6TBKaSJu3KoEb2T0oRBUVhrzanz5DQafWM2PK6PQWVylJslaHQYupnGVPSkSBQ1KsxYWzl1trRt9MBk7SJjqk8TSoNLExYVV52hSJw6dhxjhIsZf5v5lc539SN9/31EO5z5K7za+++DurlkLSFldPNrlaZJ6eDN/ZbSUYI130r0h1yu9F+hYHqmZ0idKNc8ughtZcVusBjiuscXYXiZtx3J6ftP8643U+rqKZaNO+bUsebX+CL9e9XEQYtUGdLECPCbGNLEB6mLyqpKCTlpMotS7JlLOXUa4dlPKTJQBAvvLDa/RkodZKI4J1Qp0Rv2ULg4pDGBEwYI6EsVwsYi89mcuQ3PNp4U9VDnZD4PDA66bWZsSBO7Uqc5pcROPQy6TtE8ri4XhxWWWuFOddAUZqJoBnE/iub1hjOHSX+I71dbE8j9qqZ1unakjb1HhHV48lC0WA97m1CE00kRZNboWqUJU53JBBTWm1MnpQlT61YdZaLvy0oduN8yMWRCZyv+/MjC+PPojmZc/+QS7ZogyJS6bUAs/A0H1M0MaRItslxTllO0TWKFYTOGNLFxmmwLp5QmjFEO7R2IlENmw7GYxkZG3q9hQ8nHI2VIEzZoZ8qQJoknYvV7B4TIS2LEq5huc+YOJS4ZGRilIsjnEQ4OunHqtDRhSfNXeS9pmAYrX4ozvxIUzFXxjKqOFXh3ZULPOhDovzGxII2wHQynKu6HyqmT0oQxGSUoqV5r10dsfEebMKnQnCSq28F72WyLUc5TOizFY80opYajmTenTjbfGllOlDUrQPmu6G81C5+0fckDXzlks9WdqdF1FCvsbjG/iht3QH7nysBv8YhP8Y5IXao0PywnTN8oWe9XyveodMLkO1mbVzdqgtRFBHELp64fOfQ2NOtImcdJn40rmCoifnJCcjakSc0cJSr3kyqkCZgNzymkCUEDgJis7RTYV1VGk8bPFhqEOYiFLkqpi1LHoJheHsbKemKmCSvfP5cKLGqW5bSS52Xl1DEobnQbHCcyjYKj5Jf14eZxDldeacIsFA2jDMepq1FIEz3rBzkUp+XUBWRu5Mz1lyLlQRDIv2WsurpLhtTVUywLPpvrEdFX/IJli1PHBhZ1EsHEWe6HoSCmWaAsIU2Qowsnw+ngnDi8uDHmCb9SV3Tf5v20NTWgtTGP3oEC1jW1Y1IYegVPrV1IEwVpjMdPuFatLzYt18r8qsxZH4WDKx+J7ZBgCakR5HJl+oJLSBPm+SeNn6qcRKgI9/7Z3gfjwCJ30aYMuHlaR2WYZ0M9HFGZm1akxsZplDh1nPcrh7SmUXDU+SBFCLCWY5Ral3I+oYE2I6cOqlIaCL/5ImUGUqtaSqJ1p6j9G5tfUVHYt+WQJn94cD5+839zsXJDH3YZPxTnv2cO9pw8TLz+ivvn4Y8PLcCSdb0YMaQJ79p1PM4+cme0NObFMptTtr0Rt0jfvHlYdMan8fJb98NLe++D+f/vg9j40MNbulsVoQqMKjbzq7TRcQs/Jyk4dYbipPaD+S5dmjDTfBgvIpbgpxSpK5n/PBZ1xewncuqE+4lThTW3axtW1RklvEKayONnXqwgdT68Qxdhn2OKucYiXTKazXK6CFJn20y80oSpz9Vw6mHMx7ZsASRbixunTqm72jRhRHELmeDDlFNnDWliU8rUQNuGowTDiayWU+dlfrXcv1O5NGnCGMS1ypAm2jpIUViXOWatW7aUGGnCcjnzwBqSMtuI/PPppfjuTS/g84ftiJs/+3bMHt+BU654GKs29LHX3/jUElx424v4/GE74q4zD8SFJ+yOm55Zih/d/lKde16RbWvEE2Txp/4HYWEQO/zv7zHtb9ehZdbOWPQ//4PBlSu3dNdK4pAX0s8zkuH0kDKly/xRNA6ps5p5vcKmVE7xBqeJnAbZRcUIaQK/RV1FMWhIkwROVsSr62oeQnJHup/arYmwneqxjB8VjVMXhTSprfk1NacuGg89GFvpX0tIE8N8l8spjpl+acIqdbsoxWT8bLw3llNHUDAn82vlKy+qg5qXNom3qv4WH5xsIU0Ypczg+zJm60gipEf9rgpOXagGEXcam3LXuKw1NiFcPLeQJsxhvdqQJgRNK/WNHIpTml+jPnHP31TcygcYtR0S0mRbs77+9v55OGnfyThxn8nYcWwHvnfsbmhtyuPaxxax1z++YC32mTIc791zIiaPaMM7dhqN9+wxAU8vWlffjiuSanUfWLYMA6+/Hn/ufeYZvP7972PtNdfWrGO+Mrh2LfoXLMCoj38cLTvvjKapUzH6zLMQ9vai75VXtli/VHFBIdgYZmKaMNlkqyobaeLUsUidjeCfiiCvKlW6+dXmUs/H0PNBupQTPh07DqFQZGR7yQN2XXO7I9FeEZY0jUpf1Gus9Sjjl7DR65y62maU0NI0+cQJjDtX4eTFYskZSeNzaYqwgTDblDpmHknjZzFf20KasM3Tdi3PgVUGvMJ2VBRg49lw73iE4lESvvb+lf/lOI1WTh09ODFIa5rdnzUxe7z/nt6vFYXH/yDHmuhTH64s85fOMd82yNh4hTRhfqtZSsI6SP9gEc8u6cL+M0fF3+VyAfafOQpPLFjHltl7ynD8d0kXniorcQtX9+Del1bg4Flj6tBjXlJx6pZ86csYfuL70fne92Jw5Uos/MhH0TxzJtb/8yYMrlqJ0Z/+dK37mSj5YcPQNG0aum68ES2zZyNoasK6a65BfuRItMyZI5br6+tDX18FWu3u7t58nbTwPux8K2HDtJhfvZAfrSPMKT6qMwzNrvuYH+M2orIKJyxHFiUWqWO4MOU+pEK6wIQ0iTNKCObXMlJ39+S9saqvHZtmHQkUQwz79xLkh6y1Nru+cy8MzBmP9lcH0XzLC9pv4/Pj8FakRxqt4x8EJcQk4d58hQ9p4nGAYBQXq4enwaljOD0u4SaYrClJacL0vummSo4TyD5HgjRbn1lOV2ABpPTwLBrKIBsaKFYKcvpvGlJD7tfm6MCguNE8jDUw1XybwhTJe9G7v/+hL6eOWgq8nKMcKQYuwlgsaJo3pzlmqduK1EZKvXofFJTYykKadHd3Y/369fHn5uZmNDc3a9es7elHoRhiVLv+/ej2Zry2ciNb73v3nIg1G/vx/l//B2FYijf3wbfsgE8fPNOtX5sG2O+jgMRNDf7jl0qp63vlFbTstjsAYP2tt6F5xx0x9c9/wob7H8Dr5523RZS6IAiww5W/w+JPfwYv7b0PkMuhYcQI7HD5Zch3dorlLrjgApx//vn16aRtUXbi1PFl+MDAKV+q6Hrq/ar2g/vOox1bSJNKnLq0acLczSghgyKwCIUiE4aV0rg8O2oGnh0EMGNs6YfHX2ev16RjVum/xQAWz9V/a98bV7fcjPFO3rvy+LGSy5XG0ycUg4swnLpUacJcHSXIpqIptBR9ckgTxnp/Cm2W6iamXRvvjXmOsTLllMKJe7dD7TebeKUJU9F8Mo4sp44iNZw1gMsoUY4lyDm6pNr8VaXaxlemYkEqXdqzZZ2R2uLC3qTO7EJ5b0rfAvqb77hGXWI5ddTSUHlXlaNP6f8+qHIdZPbs2drnc889F+edd17V9T742mr88t7X8J337oo9dxiG+at68O1/Poef3f0KPnfojonldz//DuvbPL6zFSfsPQlfOHRH5BzHMpVSFw4OImgqIRYbH3wQ7YccDABonj6t5vy1FRddhNWX/9Z6zfRbbkbTtGl4/dvfQX7kCEz549UImpux7rrrsOh/zsDUv16LxjE8HPrVr34VZ555Zvx5yZIlxgSolVjDPtANSxVJGaQnZ66MN1JXrjIhTEoktQtpQvk+toTSTAw9L+9XZXHy5NSd9rap6H30Eax+/Gk0z9oZfS+WCLHDTz4ZuTZ73r71t96KgaXL0H7QQWieMT3+/i+PLMT6TYNY0TrMk3ztaD6KlDrKCatWbKmoXISb89aQIGRTYYjabuEmGKRK6Ddvvo7MmKTP6r2wBzcZBTOE5ev5zPHK2JohTQgaw2zcPFJTMemW/rXwBzmFqxxLMPaerFGcOu/5R+8RbuukmSbMk+oRiUf4Jb4fUZ1cSBrymy+nzpijgfEbdXQJggAhvc8qeYO1lueffx4TJ06MP1OUDgCGtzUhnwsMp4iVG/owut28HgB+cudLOP5NE3HSvjsAAGaNG4regUF89fr/4jMHz0xUxH78vj3w4ztewvv2noQ9Jg0DADy9eB3+9vhifOaQHbFmYx8u+9dcNDfknNG/VEpd88yZWHfNX9B+4IHY+J//YPTnPwcAGFyxAvlhw9JUKcqI009H53HHWa9pmjQJPQ89hA333YedHnkY+fZ2AEDrnDl49T//QdcNN2LUJz7O3wuBYVWItuZiRSHMRbxSjF/M42psCpjnYmkgZWo/bFywFGnCNGUsupf4FF3Qv9d+Mzl1fnHqmPYjGbQrPsOHNOHjw9Zj1XM3YdjsVqx77iYAwI6HfBUNI0ZY21143Y+w8bkHMeG0d6DzqF3i7x+ZtwZPLVqHtS0djuEqhHEQLy9lKwk3Y0iTygadAqnjSOQ+acJUpM4l3ATHqZL6rdZDOIl8SBOLUkqfm81izikDXiZGpT+Ubxb9xnqYmyhe5TdCEXENPxP1O0r8HvVHNb8m3hAjyvoXShQVrhi9R8DrMGjLOiOV2RwhTbQ4e5RTlzakiYHU5szfrCFNGL7dViAdHR0YOnSo9Zqmhhx2ndiJ/7y6CkfMGQcAKBZD/OfV1TjlbVPYMr0DBWMa5GIHsGT52xOL8fWjd8G7d58Qf3fY7LHYeVwH/vTwQvzp42/FhGGt+MW9r25epW7MWWdh8Wc/i9VX/A6dxx6LllmzAADd99yL1t13S1Ol3MERIxI3SwAo9m4CYJ64giDHKz1bQmxx6qwppITF08apixfytJyK8qLQ0FAymZS+FfuWOk0YQSED1TQKfVGphDQp9yefL+UbVEOapOXURHXFyqyD+Y7jJDm0S5/XmI5y+rHmoemRBgdPypo7Smgbt7+5hYvN6JQmjDO/0k3FAQXTx0/ot1KPERLGonixyA9ByFwCJLN8PSevS8ZEH+i/hVxfCeKpPU+BU8eHaFLQ5KidfL6cdYBs/ECqzZ9PE+ZSkEFqvcyv/pw6ZzTaRTyQVv+QJmRtY8zvFfqDyqnT5+u2mibsY2+fhrP++jR2mzQMe07uxBX3z0dP/yDev/dkAMCZ1zyFsZ0tOOfIks5z6KyxuOL+eZgzoRN7TR6G+as34id3voxDdxmLvMPzfXzBWnzvOFNnmjOhE08sLHG03zx1BJau63W+h1RK3ZC37IudHvwPihs2aHy1YSeeiFxrS5oqq5bWvfZEfuhQLP3KVzHq02eUzK9/vQ79S5ag/aADt0ifDLF49jmFNBGUOvZEkMYcVmqk3GYFsYrrr1VIE24xpuYDC1FXRdPCQgFaEGMf8yuJKB8qJkp7uAm9H6UqPTYFgniOjpS6lg54IY2uSEN8vUO4Dx/JMRt3CvMr7+FpoShQTpa6qRSSEQovpMaC1PGcVhkx8krhxMQ388raYUuhRdF4jjfHZebwQGPUWIAhfTdrbH4FmHu0Sc58/92UOvr8fEy2Khqd0oktqtPohxvS6lW3JU5oZY+qKNIVUIIofFuH9dVZjtljAtZs7MfFd76Mld192GXCUPzvR/aN1+gl63q1tf6zh8xEEAAX3fESXu/ahJFDmnDoLmPxpSN2dmpvwrBWXPPoInzlXbO07695dBEmdJboPGt7+tHZ2uh8D6mUuuKmTUAYxgrdwJIl6L7rLjRNn4H2A96epsqqpWH4cEy+/HKsvOQSLDz1NISDg2ieOROTf/mLGEnc0mJNZUMXTFXExZNZMEgZX06dQbTNK1GxKf8s7aIcMPcqueSzKEL5t4YGYGCAoBEuShGpR6nLiQRN+wF4IWx0HGOlrrkjPdJo2ehj8yvlhFUrau5h29xOKK+jGLLDhZEmTCXqx2EePNKEOSA1GqeOosrMhm1FCmm7Vo9lGHV7eRjHCid3cCLIrdrXaIg5hU/loiKB48chhQ0Nejmb96yLxOPJ8AZtxag1gnP0YJvTn58TX4xFXGWKgZtY5pGBtPq2Qd6jHPf8KacuJ3PqtqGQJpGc+rapOPVtU9nfrvnkftrnhnwOXzhsJ3zhsJ1StfW1o3bBp//4BO57aUXMqXtmSRdeW7kBl37wTQCApxd3aebZJEml1C0+49PoeOfhGH7SSSisX495HzgJQUMDCmvXYuxXzsHwk09OU23V0rrbrtjhCrtTxRYVyyLolCaMcuoEJQHQNzwvISFNYpMJyOZL2/VylCCoCpT7t8Wpo79FfSsyDhfW9k3eYFRX6BAKIKCoEOC2majIgiIqUpcaabQNPx3vGplE1PmXzmGm/K+rhyfdVDSkzoI+UWGQGvF5q2M1SELC2Dh1XHUG0pxs4mc9gz0TyRvPxkA1FTSGjiOL1NCNWza/ao4SgvlcrCNB9BzO8bcOBVO+D5ZsN6IwaHTVnDoDTbUgrWnThHEHQPL8bGnCtraQJlurHD57LO4+60D88eGFmLdqAwDgoJ1H47IP743JI9oAAB9+K8/nkySVUrfp+ecx9qtfAQCsv/12NIwciWl/vx7dd9yBlT/7+RZT6rZ6IdwWTTiYPhKJhG4z2YbkGlehJiIVqaPtKJ+9Ahxb0twYp2jGtBD/FqWG0rxffbgxhFMHKGYLB9OY5kzigZ5QpK7sWbWmucMPaXRVKg2+WY1sIhwZ3odT57vhGZweG6cuWWFyGj8GqbOmCbPGqSPPzTbHckzdHiZGpzRh0fd6Qf03TmGgShmr1KFST3R9GakzHC2qVW58QxpRS4Hr2uXD26Rtacp5VF/K95BaGjSKCvktbZowbmyMjC7K9+SAVnUsvjeQTB7RZphfq5HU5tfckCEAgI0P/Acdhx+OIJdD6x57YGDp0pp1brsTl8Ck1pAmZBFQN5ww1Bdg2ynaJgbRVilPFc60RGebS77NtJDTywXcou5kmoLRvpF6x4WjppV3Vyaph7PGqfNBGl2Dp8an75QBSRPq1eME+syDyEToSCK3hDSpxNcaTO4H4Y3GdXCifk/TrBFzZKlP8mbqlSYMZt0+Ht4c34yGNGF5q/GhziFNmEUpMxA/5btKQvgqN34uwLEPDcL3faCWAhdOnS1NWGpOnQ1N9UCsubotz98IaaKGLRF+29Y4dVtCunoH8PSidVi9sc/YYk/Ye5J3famUuqYddkD3XXej4/DDsPH++zHi1FMAAIOr1yBXDieSiSn2OHXkFKSVExY/TYkL9c9pIX6OzJ3LlcMG1IhTFyMlan2B9htLRqZ8u4YyuqaGNPHi1Kicurz+ndWcCbO8U7vEfFUWlVMXuiyCdByU7/jLy9fXOKSJyhcKlUCkzmIxMbJpwmhIE4VjZiapt/TDltCeXqoenAjCxqXps2Y2MfiichepN2Hp7+g3dxN9KU0YKUfnL4f0uKQJc3Fq4dDw2Hs2JUWE9qfoN/8C+hwc1y7K2/Qy9XIhTarl1Fl4jyxf0qlq/d14I6UJ2xJy1/PL8YVrnsLG/kG0NzeQCF5B/ZS6UWecgSVf/jKW/+AHGPLWt6Btr70AABsfeAAtu+ySUPoNLLEVldmwKF9FK8fzxTQ0oljUXuBUHCeophllUSgrdYabbUrzK5tQOw4ToS9KuvcdQRFzFaXOJ/cj5Q2qdbmEAqgohUxCdJd2iXIcpaUZyDdiQzGHTqMgEd/gqQZ5ujbHZ81RIE2aMNYz0HbwIUpgqCj+9JlYkcsU4xeGJnrMmI+tNADSR5c5xoZL8UWIqPmVjpVy7wF9N9jgs/r485w6MucABFSpS+nMFdenmZir4NT6ml/TpAkrx3IMgsDu4Z2iH5yJ3IUbbO2vxTOaTxOmgxLbakiTesv3bnkB799nEs4+YhZam/LJBRwklVI39Mgj0Lb3mzC4ciWaFc/SIfu9FR2HH1aTjm2XYluUHbJDSGnCtGsiSftSEaItAqUdqnCmdJQIaBtKuxX431xU4k0lKpcvLzJqXzyQLq39PEUIbeY7s/9Ody+Y2Fsa82gv9GFDvhmr+oGJTFG9edLXpP6S62uWUYLjbaUwv2qcOtu8Fcx/QZBjEGYLcmmgwQl9zuX4NGs2792qQ5qUN0n1JOVzUGOeTVyOhL1g0Rgu+Cwdf2tIE3OOBgqyrt1PDTl1XnHqfNEsmxUhoa24n+UDAuCmnPP9kOeREe7E21Gu3FU2o49AfwgUFD3O65sOVHijyetdm3D626bVTKEDUip1ANAwejQaRo/GwOulnJeN48ahdffda9ax7VJc0oTZwpPQxUdF5kDWs7Sn4Fh/qyzqUUgMM6VWtSFN5DQ3rEt+Tv8tyJenr0LG9olTpaMIDfp3PsgX7adYrvwvY2IfUeiNlbrkeqIN25VTZzHXVCPRswLSbdA5pXwkFu/RgGwqKlGcJql3SRPmxm1DrNSFlK8XP09VKbU5D5B2rXMsesYMp87JpKUohVJIE1uAWUu4DCOkidXUrKDZ8TtWNp9XGa8tvkfOw9YmxlxxbD9+3u7lAqrUlRomFfoJTVemj5/n3KZ10+evIrU0QL4StkQOaZIpdTZ5x06j8MySddhhZFvN6kyX+7VYxKpLL8WaK3+PYk8PACA3ZAhGnH4aRn3qU7VDArYzsUfLJ6cgWgYwXlCbE0Nat3mWhBu/6NT7Na2jBDlNQlne6G86yUD7LTbnFIte/BwWRYjqcgkFQE/DgBunjpKJFRkx2IuFTcOweiCxmsqG6Rj8OF6MaUiOKoUNaeKVJsxmYuT6SDYVVamg6KltHkTz2THdU4Cy4knQD++wI7RdK5rImKZ9MhGwIU1y+m9cgFmn4LNRnyz94dDseLyi+6ly4+fmnwen1hmpjcoFdN54mF/L/UQ+X4M0YXo/WPNr6jRh+nPjkFp7SJMaobBvEDlk1hhccMuLeGX5Bswa14GGvD5eh88e611nKqVu5cWXYN3f/oYxZ52J1je9CQDQ8/jjWPWLXyLs68eYL34hTbXbv6RJE2YL0Gk1vwplkoRz94/rsIQ08WnDFpLDgrgYoTyUkCY+uR/ZkCRRXQ5hDtiQGB4mMQ6NHTFYSgPjhNT5Im+03a0kpIl3nDqBUxcoc9Rlw6TzKFGpMNCrnPa9c4BgG1/U6GS0Hrg5kRjFWfOr/hs/H+g4mgqDyYnjLA/MOx5z6mqz8fM5nJ3sr+VupOTU+aBghOccAKhdSBPZROqGWDNC3yMWxSWHqlzOsEJUrbi+QeQr1/8XAPCze14xfgsAzL3gaO86Uyl1XTfcgPHf/Q46Djkk/q5l553ROHYsXj//25lSJ4kNhRD4VtYAnWo9Rgy5lBs44bQFQSCaX9OGNOHCHcScOsq3U+slBGduUXeLUwWjfSOgsEOcOjZ4sk0ENBYAhg+WEO9VfQyn0mieQVOt7UZj6hDuw0dU4nQKTp1/nLpow2FCmuTo3Eg2n/uPH61bMf9VbqB8jVmnEW7CgbfJxanzJegnpQnTMiPQcbRw6mzPig1pktc5dbUKwqunqXM/XLHBe63liKXAJ00YwHiGpjS/WpDGatOEWQNTGwcNhVNHA6tvo2nC6i3zUihtSZLqbSp0daFp2jTj+6Zp01Ho6qq6U9uv2E7xAopjU5zIKZAr55/QmZyw1Q2zViFNbGnCKFLAuetHvzUonDqPQKIGUhEEQOz96mC2iEHVdOYbzhlmRKTU9ScrddYxYtul19dIqdPup4qQJlDmks3ESBwrdDS5XI8LeukbfFZAL9iQJrbMJjYUhApzAPDKmkLnCGBy6ixkeD5cBvQ+WZ8V8443KMHCS3+YbXiJMkYp4tT5OkpUFdIEMDl1ad9D+vy4NTJlSBMa/cAlpEkQMHvENpwmbFuXVEhd86xZWPvHP2HcN76ufb/2j39E885uiWzfiGI1EbKmKGLwpJw69YPk/eq5YFaQMsVtX0VkuDZ824m9T5mQEgYKpaIIejkV6fGJU1fhjSghHWifHMyv2hi5iORFDGBE/0YAbkidMQ6uSkmNHSXiaopFP/O3UQFgeAYyfTTQAIW/ZgZdtfTDc/xipJrW7W1+pYipZY5ZzK9O6AeXyo4qozY0xhbYFrpywuZAZRwlKiGIqPk2LWJVUTLiUfJxXkgZ0sTrvaecOij7QJWcOnb+0jnmTb/R0UjW/JqlCatKrnxgHk7edwe0NOZx5QPzrNeevr8JniVJKqVuzJfOwqJP/Q82PvggWvfcAwDQ+9TTGFy2DJMv+02aKt8YYuEdiSiOpqy5m1/TLxwUTYCijHiYhm0tWE7KJt/J3FQop67UFw8lljvNkvQ4dr4T6Yc3J4dD6tyVOpMT5Wg+9IiE7yQMb8unbsM0lcslBOimnB4TKfBKE+Y5fkbd3GHHRgPwSeHEKozuJm7jHqGMt4FUagW131iFwYEMbzhcAJWwQZsxTZjb++/5/El7XtxUDo32SWnI1knmEcupS2napnxhpu5KSJPy9wpSbgamzuyvVK64fx6O3XMiWhrzuOJ+WakLgjoqdUP23Rczbr0Va//0J/TPnQsA6Dj8MAw/8USsuvTXaNtnnzTVbv9iIzo7mF+tacIMpC7lKZjh1LBBYlH9wsG63dtO0aRcoCp1rqR3QFmcVN6gD9/JLO8knEdjWYYPlJS61X3mb2b7Hn1V2k0dZV6stzxngXQbNINiWAOzWtOECSguJ76cOnFOMs/TorDFiJaPiVgz7fqg0QxSR8yvFTSHef84xDo2HzuQ4alygApSZ6QJS4scR/3x5XT6It1xe+V/PQ5zrDWl2jRhljUyNQoZV1D+d5AJPi2GNAkq8537LRNN7j/nEPbvWknqOHWNY8cYDhGbXnwR6/72N4z/zrer7dd2KS5pwoyQJrZYcDZHidQhTTgUS1A4U5+0ozY43pzlFB3o5VSlzkdhMdKEqfcYL4aWCmgqJV9OnZGao2J+XdMXYrBQNFzbSUWkrwnmQ0OZqJFSpyj71vhsSeWBSpxFi4mRhtTQ04QRhMIpTZjj+JHxjuYPz6mzjIOBgtj6GFdY+S6kP9o6bSpV8TxNi/TQQ4ntkMplbYiRteh+UjpzxW0o/fGhm9C54vn+OnkvR8Ks0VVzW+mzzTHrp8sc46o2kFr1+evWJKeQJhmnru6SWqnLJIVYTqZiSBNVASDl2MCW8ceUp+B4wVMW43gzpV1L2QZN96WhcfIpOiDlVPOrEW7CJjQVknKPMUHYstDb0ixZRVKOAQwd6EWuWEAxl8eajf0YM7TFUo9l/CztVm32IVJtmjDtWVGTKjf+UpoqJU2YE/rmO34S+sGZSG3hKsi8SZsmzOX5Ge9K6Vu9bg7psXBaTQ9HiwIbL2fqxi8phek2ftX7PV2cupScOh/EWzW/GmbrtOZX05pS+S2Qf0tRN8upY0Oa6KBEFtLETQrFENc9vggPvLoaqzf2GUacP3/ird51ZkpdPcUhMKk3by0ilxtm25QLB00hlAsqdQhpwnwhdrtLPjlFMyheJfiwsmD4uPBTMnBOMTEXHE7RtjRL1nbL/zKculxYwLC+DVjT2okV3X1WpS5Vmiu1fK1MIgynyS+kidKPyCTnw6lT0QCDJynfo1e6Lq7dmJummP/IfbAhTSzpnZhOlutmOHVOFAMyR9T2DcRJrY+gktWGNFGcCmjw7VqFNOHy21olLZploJgeaw1Qma9Vmp0DC5rKevZ7Vc5Yaki7bJqwuJ0spImPnP/P53Dd44tx8Kwx2GlsB+905CmZUldPsW18Dpw6kbtSKDCeqQ6Ef04M056yGBucupTmV5oKjFXcZL5dXC5fmb4V05gHiqFy4nxO77QfruYbDn2JpBhieF831rR24sHXVqOnv2BeU5aN6wOsGjkN+baRKIxsRNA2BF3z1ojXtzQ0o1H9osacOiDB7CgJt+GFzG/x9eV/KRoQKAcPF26lbf5xQhSUSrw30/xaOfhwdTIoeEIftdSv8HnfSFtqORun0PYeBHRTj8okm5oD9bsaKTeaUp3C/OqNZsVrozsXz5YmLHW4D9IPsEq5p2d+VNrwjDbrNnlztjRhGVJnk38+vRS//H9vwsGzxtSsTi+lbvFnP2v9vbC+u6rObP9iWXgEFCcxFlxZqTODD1dnGmXThBnx1dIqdZGJldmAbbwj4lGnKcdpTCJqmigfpMeSSskqXEDZSIpFDN9Uen++d8sLCRXlgAM+rX/1mwfFqydNPx6Xv/S80o/NcHz2SZ0UCecZaPGiNTzElUOF4Rnt4lnqmkqJmhIDYsZUlHSrGdCnXVuaMCcuF5mjavu2WHQOnulOygk9CDImupo5DBR904TJ92hvj64bjnM9l9PQxFqlCbOtn85zW6i7oowzdWdpwmomjfkcptQw7yvgqdTl2jsSf+9873ur6tD2LLZYXmJe0IRYcAHAZntIi6IZKbBUTh01G0YbsFcLsG4cNEm6uqgYfdM4dT5IEdM+DWli5WQxY+Qikom9/N3R8x/E+lm7Y7CxyVpNccNGDK5YUbr/QgHI59A0ZQpTJzB31UYsbh6GnoZmtA32lbpbo4VWrSdVCjJ13MgJ32Z+5b3vZJOU2W/yrBM2ZzEGHuF0BUFgpz14tFttnDo2pIn0m8abo+8Bg6LHuXdt5lfSyVxOUQprtPEz5v9UjhJpObGu/S4rdaELwulUn2Wue85tQ2zvkZHRRSlDrK8Zp85NPn7AdFz5wHx8+71zakaL8VLqJlzw/Zo0+oYVWyyvtJw6qVxqzzLTjGUm8iZ9S6k4sgFOaV2awqeX40KaOC3QjKnO2LitO6eHqU8tZUkTFoYh3vr68zjp6Alo3W1Xaz3rb7sNS77wQ+SHD0dh7VrkR47ETj+7n712t3NvR3ffIFa3DEXbhpWlLzeD+dVI3eYgnGnK6uCzpdOEkX4Y5uMgsHK7TOXQhtQxqK4Pb5Heo1KnOX/ld0x7D8iGbw1Jwjl1Ec/K1Lwv2h9v8yuZK86cWDKmrt2m62dKLrLcD1MpTx3SxBKYunK4J4eqXOXZVu4x49S5yKPz1+DBuatx38srsNOYDjTk9QH7zYf9w8NlnLp6is+GFRVJUpzi06OAoqVNE8ZA67Xj1FlOyrS/LKeuXK7BDGmSKjCraj7w8Z70VmoF5Rjw8mw0kEbLwj1maDO6Vw5iVUsnJkdKXa1WWuVZpcpWwSF9FqSLxktU549hUnPh1Ln2mVNQQDZlIx8mZ5J0N/FXzJdcuBQXpY7cI6CYXy33b3sPxDiBlsOm+pmij9V6gaom3hRx6rzNr5bA6NZyQaDHcqwyTZhhsbCGNElpqWEACMOapIZmyTh1qWRoayOOmDOupnVmSl0dxboo01NQXIj8LpUjikLakCasuz/n5ad2LqWHFRv8k9alfqThTnJpkbqId8KkCXM4hRuefWnNN6rEmQh8+FLJhO1xnS14beVGrG7tNMtXKVqz8Vh4LOJcv23z1pImjKJPdk6d+/ixvxPlCEDpvc3n7eiV5HDBNlr+l4tT50LQJ/eolrOlCTMC7LKbugunjr7HgakUpj14RlVyvEMf5wXfg4hv0O9IiMLjw/9z6QcbSy519hiK8DIKv5E1oqKwx4GpM05dogwWithv+kgcsNMojOmwhLDylGzE6ylWFIJsWJEkRJFnuTdaW+lQNG3DZIKsltpIZ0awpmkiY8OmCYvKqSFNqkl2rvF9HJQrCyfJKlbzq7spyifN1dhyaJQ1LUON8lULg7R5bSIWTp2Th7ga54zSEKyOLp7cKPp7NMeU/lNHD/Ydpwhvyjh1TmPMceqi/tKxUs135Dc++Gwy4Z+jURhITy05dfQ7n3LO72/a915Xhqo2TVpDmpDffBuh884FqQ1grJ9Veza/AaQhn8PXb/gv+geZQ34Vkil19RSr+VVAcZIUJ8E0mtqzjGw0gTWkSUoyLIcGxu0xJ3z6d8ypY4Bml9vlwl/QDdaqHNLyruYbZhOKxMez0QNpGFdW6lapSF2tTCIMp85nEVcdHIxk5yz6U/7XFtJErVtu2K/PEnqs9pGYFHnF2aNdqggAfhxWK2/QMlbGe2C+f/EzsjqF0HUkMJSpWqUJM9pJLGeucW7tlf/1TC8WX2V4eKdEKImlg10jB9OFNDGeJeNEw4U0kZxoapZnejuVPSYNw3NL19e0zsz8Wk+xvczx5iaEJpFeTrrQ0nJpibLxZwYFidtQrvGScp8tnBCtffK3jZPkxanjPHzji2wbLu2/6/2TRVEVn0XQI3hqhNStbqm9+VVDqtLmlQ0CaBkBbGnCcnTjMM0/ysWWNt3Hj/vdSBMGmMGTuRtwmL9KKyhXGH8T+tAdbNwq7h2Py8m/iSFNLDH5tHroWhVWufE7OGjw5chnV06dT9gcrn6XANtOHbHMo6rThMmWkori5hDSxMYtzSSWD+83Bd+7+QW83rUJu07sRFtTXvt9l/FDhZKyZEpdHSW0mAgNd3+jDP9yGpG8o09pPVM55UZUHKPFyasJBcZnODWSpyGUMVKV47JSIJbnhIuhZTmhmsVJeW9OHR/SxLku2/gR4ZS6WrnOa/Wk9WTM5fTcndaDDzlcKGi0MQYOji6unC6xbsqpA+y0B492Wb6YB7JllOdMrPEXzDtG+1z6sfSvg/nUqEdxZqFpwqp1GND7636oU/vmJDbTpEO5Cm0g+j7le0j6waYJSx3SxDI2Av2hpLCXr8lCmnjJZ//8JADgvH8+F38XAHEu7LkXHO1dZ6bU1VNscabohhVJWvNr2jRhjNlEUjjTLhz2sCXkWjCbivo5l9PDNjid1M2Ni96DncTuYeoj7QBgM0qkyl0Z1yuXGdcZKXXKiW8zcOoi8TUpxZ6BLigG5QuFFqTOppRb0CihAP3C+J4ijWzwZI/nxr7XaUKaxB8ZE13clvyOceVc0oSxhzMpTVgNza9OCqLl4OjVnmu3KU+56vu29MvH4sDWbUNxy/9S83ug7AH0cJNZX63y77MPrnmdmVJXT7EtygmcumTzq8Spq/KkllP4EjUOacJ9tit8zGZElDqn1D2cM4ZxD5Z6fFAh2g5gNb+mUkodOHVrWjpQQIA8wtqZRGw0AlehG57V+zVSijlOnUUZoeKL1NC6y/OHDWlifY4eG270XqvfeaG5tveIjpXlHWNRIH1Tt8bPVNuI7onJCJJKuEOF0/SzmBhtpQQzfGI5Y45X6/UrP1svxJoT4x6VtdlAaiv3EacJ4/h2mYgyaXhts0kAmVJXV7F6ONJTUFwmYSGPXyajMXs5SbhTIF2Mq27DhgZYFiXOpANy6z7eb0o9XkgP0w8n4cjvkfiENLGNH5FR7U3IhUUUc3l0NbdjRF93zcjLLpt5olCTtIuHuKEUBMwz8UBaE8aDy46g/QsoBx6LSVFQDoVGSb12+oZZ3jJHbfPXwrczHH0snvksGmp4T6Z05pLaEPpiXpPy/fVypmL65IJwpugHmyYsvtRvbM31h6mb49RRcCELaeIlryzvxpJ1vRgo6HvD4bPHeteVKXX1lDjOFLcICubXREeJ6LraoGjmKVBBQQROnX9IExvEL5s4aN9YhM2pL5YNR2jLuF777LoplP/lOHUeSJ11/Ig05HMYXuzD6nwrVrV2YkRfd20XWsJp9N6gDecHBzQ71BWo0rvjo5T7bs6CEqDUY2RZYD1C3RXPeBgZ86vbHJE3fh803JYmzGo+5SgOBppTe6Su1vQF63XeoVAiZTbqiFtxsz7L+2/0ybeR5LrZNGExRQf6NTXi726vsnB1Dz5x1WN4aXm3BlBEo5aGU5ep0fUUW3wjuuCRMtJmKSuDKT3LGO+nWqcJsylirGm08smsx3uDhqnAcUR762KU1nzDm7EBP06dL29mVLEXgBKrrpYLbVrSeXR59IeRkSHZ/AqL+dXFtOl0LSDPMa6cNU2YR7sUFVP+dvOQdj84WRU+S5owK+GfKpWlYGblcoz5PI24KJMO5dzThKVoSytX45AmTD+8+aJULIorzeiieuyL2SaykCZWOf+fz2HyiDY8/o3D0dqYx51ffAeu/eR+2G3SMPzlE/ulqjNT6uopNgUtXjA9vVglLl6Y8jjImT+5DQaeiojWhgVVsZ2imY3bcMF3WERY7zcbl4iKB1LG1RlaOHVp4mwlLZyji5sAAKsiD9ha8lxqtYk4xKmj3pMaGu2DtPryjgT0mPX+tb0TPs+NMdWHFnNncls2NJxB47hyBI2xZ5Rg6hFNdCk3fhezLydpObGGadOxHDGlVx3SxIYYeq4NVKy8QRogX70PYx9SUfRMJHli4VqcefhOGDGkCbnyfvbmqSNwzhE747x/PJdcASPZiNdVHEIApE0T5qsMSsLxTURnjJQeTgwaqHySr+VIvGm8vTjF0cO0Un1IhBqFNImbtz/jUWWlLkoVVsuAoCZqkE7BD4sUxeAOPmRTUdAAr374BCrmrucOGk7euz5KQaRAqUhd3GF7f8GMn7P5lVTEEeWL/7+9L4+zq6jy/97Xe3d6SaezdfYECAmEgGBiAEUBWVRAYASREXAZBAEX1GFwA2acCTOO+lHHAR1B8KeDiAIqiA6LoOxrgJAFEgIEsi+ddKf3fvf3x3v3vqq6VedW1b19X3dT388n6ffere1uVafO+Z5zRG0MMZ+xfSgyElg7DFhr6izqANF7asipS41vRjm6WAqeTGPiD5G2Q6qBzPtcxrdzUGIo72NcTYEFN76hGlv3FubqaePr8OqOLqs2HacuQ9DR8oUFq1Sp8FexEKvi1NmGNImq71m+hCrcitmLSy4qOt5XpYO0Zk89AqFOlGhv4j2pKyRFgrcyGK6QJgDQ5vcBYGLVpTnRJiRml+preL9S2gADDYWpiYr0KIwIpeqNjokzhzxOnb2HtG5IE4qLF56rL2pKNcyvXtRENyzmV6v3R1eos9hAsuU0nhG99ohxRdpMwVIjNiULaaLwjHYhTWjMn9KIVZv3YkZrPQ6d0YIfP/Qqqity+N8n38DMVjvPWCdGZwlKs6Uyo8YJTiqelq1LucQZIfU0YRQnhOLIST3qzLVmUt6ekUnGUjslclJYaOQDjbSj+i5gol/U1I1ETp1wTUhNl7CoZBbSREN7IQqlZJownX5llAcTLhapjaMEN+L9EzXNRo4SjIluGEOa6Am8hKaL7E+94SS7EzfeSTl1xL21dgIJy2sI/EZpwpyIQeHSY/cP34fL338ANu7uxkd+/BgeXLsdV59ykFWbTlOXJcho+UEZw5AmsaZR050aYX5VpQkz7oPQ7lACS0TTEV28tTg1Opw6YotpHdKE4tQZkeDNNA0TBfNrqkJdUk6dYLahnqlISA0uTZhQ2IhTF2d+VT+vYvBkUtAx0RAx9X3fLzzXJu+0UWigmI1TWEzUNBPmU2IeSSukifQZsdBi6r4PUkuBDkxM9CbthcMghPLEjnKStnVCmrg0YVo45oCJ4efZbQ144EvvRUd3P5rrqqzfC3fFMwRFdFYme4/bzYrk5aCvtLRorDZMFdLE2ORGLSrqSUlKVLYRKqTnqN6hRmC7GxZNFCwShDSJ5dShH0BJU5fm7tnIo1OGUEMd5clFOxM1BSVB2GTBNb1+pLk2smBTcepETQ8leDJlddoWq0s2QMp+KYFPJ6QJNZ8x7SjThNlqrMTNmLbDg+VGxPq9F6wwtpvhABR/1JQvKjZNWUrCkCaS84iENEloWn+b4bUd+/DQy9vROzCElvrqRG05TV2WCNdyjQUrrKMb0kQ021py6iS7wNiQJkk5dZQzRFy0exvzn0RwzCJNmCqkCacBtRFKY/oPhLqu6nr0VlQNL6fOWKgTni1Smx0sKmrvu1JZok9TQZQqH2qxi98Jj87otaG0wcz55PNARQXtRBIzZvo9UvQLUVMjLOpGnDqW4pBSSJOgrqlwaMsDJa4bXa/4N3hGTO6j1jh4zTF/zHRTT5nthU0p56gkzG22aSrfZti9rx+X/O+zeOzVnfAAPPjl92HmhHr8429eQHNdFb7+oYXGbTqhLkuQnn2i+pqvo5ywlDytwDSSzDTKLZjDFtKEMfGQC6hEgDMgn5eKCAseJOZX6rpZhkRQOsOw987GfBzT/zhvEDWD/eirrMYfZy/Dy6/sQeXuN+P70RjG5JpGjO/s1B6LiDC3b2DSoeLURUKaMEKBKMRQ4zDVuBAbh9D8KgqlUp6ZQb9sfZ0UanFjJjl1MRunsA3BKpA0pEkaC38uZ55L1VLwsU8TJmqYk5lfSUcP27kprC/2xT7rwjpApglzIU108C93rUJlRQ6P/tOxOP47D4W/f2hxO7511yp83aJNJ9RlCTIBttw0p5smTOS7+ZZaNJJTFxE4bXl7hDbA0DTkQZxoLRc8yuwA8ZClyVHUNAVgMzJoaerMtGM5L4eJPR14s3ES/mfRqcBfNgHYpDXkOBxy0Bn494f+i+nM8HkTTVPEM0WlCTMS7k01rTYhTaTvuIGGiCnr+34h2nxKAarJ51eH/iATqmO6l4Y0SSGWWShUw2ADa0sZSI1Tl2VIk4TmV1lIE19yHiLv2iSm4tsYf31lB37+ySWY2lzH/T5nQgPe6uixatMJdRmC0kLEpwlTmF9VPC3rNGFRwUnJBRuONGGRrSJbTzKZWZlfJf0n4tRpnr8qFqGhps6YE5TL4RMr78afZr0Lvueh7p1HIFdbR9eJQc/AEJ7csAsbxk3ix2bJqRNNOlppwhhtgDQUjwLGIU0or1VxwxNKGMTGDUQZ2RgjThg62mi7jRO9YQk0dRqcOIk5PEI/SMv8qupTVcX2/bUWBoXNXOKQJtTzGCmcrG3S/Mqch7BGuDRheujpH0RddUXk946eflRX2gnETqjLElScOnHBCuvEhSYRJlqxnnXcMIT9qnh7wxHShCaTy4QxC3ODRFMT4dSR5lexvuFiIl7HYebUIefhyM0v4cjNhQjl8/7lbFRPnx7fD4HO3gEsuvr/0FlVj96KatQO9euNRURYXMPEGPwU4dR5Ei2KgVAee/0o7XFwT4OxBWOKNmPkVEKYX7Uusc7iHB6LCqmlr9FzFYUT6RyjxalLqLES61pq6mxDmugKgxGv4cQhTdT3NnFIE1JTK2xK2fNQhjRxQh2Fd85pxe3PvokvnTAfQOHRzOd9/PihV7Fs7gSrNp1QlyWICT+yCwqgaX6NBrQNVQaGg1SbX5VaRFvtTPhdYuIp/aCu50UXSh1NkVaaMANHCVPzTcT8ymjqrEKyxEycVmFfYtBYW4XGmkp09g1ie10zZnRtl48tBtEUSuqNj+ghnl6aMDOhjsuVGr4bOo4eBv2y5tcIMV3jGpOcOuJ50AmFIprYZPdK9j5FNFZ0YHUtUHxcFUw2AFw10bSp+ayLXsMjOE0Y6T0rCuXseUQ01i6kiQ6uPHkBzv3p43jhzT0YGPKx/J7VeHlrFzq6B/Dbi13u15EPIjCpKttA7G5WwdNKLU0Yow1TcsESx0IidtsEF0ga0iQt8yvRjvVuWJVRgv1uMf5YTUNS8rQC7S0FE+62uvH2bUc4dXYhTYzI74YhTcgI/qJJkYrPZRvSROQw6WxcIteD6JeMU8cKsIIATnKEJcJFhH6QDqdO2acKtiFNEnLq0gtpItGChn0l28CR3rOR82CeR2Fu81ktuoMS86c04oEvvxfvnD0e7184Gd39QzjpoCn44+eOxqwJDVZtOk1dhiAJsnEhTVSCkxgSIkBKacI86WQM7nviNGGaRG3pwm1lfo32YZTP1VLzJWZPCMAJyxrjN44NZ8M71EB7Sy3Wbu3E9vqWUtOmjYSaruL30MQotV8WioSLSklTEI1TR3Vpdv200oSJ2kNi/DqD5MYY8X61oRhQgpumUBCeq+jUote/yBtOLaSJok91FTszanT+0asWecaTaiipTYbJ5kYGUsNb/Cty6tj5U3LMgUZTbRUuPXZ/7rfNe3pw5e0vYPkZhxi35zR1WSJczDUWLLGO4uWMc7CwJq6HHbALZgYhTcg4dRLhxGLXLQ1pEvGiNTHfme30I7xJ9ntS05q0X/k4kmJqUVO3va5FfyziUETzJek9GgjFEqHAxDRmfP0IITBiklTzzIw0vOyxCIdJ450mF2e1AKwTfDbK8dPQ1DEUh4hQmBanTltTR2i6yHoGcwTXvvCMj+Q0YTrez5KQJmotuhMxbLB73wBufWqjVV13xbMElQrKNqSJShi05W3IBCelwJkOp45MNk44UUhDmlhx0iQav+EIaSLuZgOwIU20zK+iAGOmaUqLvDwtFOoSmF8F7aVPOBOp04RJzK/DyKnjKAGRoKuEUGrSL9OHH9HUmT8j1Hukq8WLaGOoDDkUxSEfLwDrguM36leivyurJTO/hs940hRakQ2MpqVDB5FLI2lb5v0saKyTxuJzsIe74llCJ62OcZoweT1rzzJxDsh5hDBiGdKENP/o70I9URiz9H4z5dTZhjSJeI8FSBrSJG7iTLp7V6C9pRYAsI0xv9oK+FHBRVKW0AYYXZPIrY67foSGRtjwkFwiE00Pe8z3jT2ko/xTicZF1p6MflH6UhyPIIArqSHMu+uxJjpBK2sd20MYr7bG3Fy7L61nON/oxGLUbFD9PaFTlA7f0g815RJOnUyL7pApRg2nbsf116PrwYfQu2YNvKoqzH/qyUiZgU2bsPmaa9D9xJPI1dej+cMfxqTLvwivcmScZjgtS/k2woIVVqIFp5JqX+FRmTD4JLdgqtKEJTW/Epo6flGRLNw25heJ5spIm2XqqBBAJYBnENJEOo6ECAJmsuZX6zRhOnHqRKcgVigw4dQZcgzJOHXhPQX/V9KmUZowtmw+b551hOJWkc5IxLWJCCcxC7d4nSIhTVIIUGvx/stSIer1FbUUGNUTOHW2Gko6pInhhi/auNC2RMMrowNENNaOU1cujAxpRwN+/wAaTzoRdYceio7f/jZ6fGgIGz9zESontmH2Lf+Lwe3bsemKf4JXWYlJl3+xDCOWgJoExQUrQBxvTUG+h22asEg/HsLFRyWMJO2D87CjdqHRBYcU+hSITqYJzXfa5x+YKJJp6ow1hcO0W57GcOp8xGieFCjd73gTo+ghzgkFkc2AphZM9t2gvJIvRW3cwnY07pvvl/6JfVqOmTTfU8KgKJxQacKCPoeGSu2qNFYphTSx1tSbxplUfFd3J2qYEwqz1PtvaUUIQQn8In9bEtJkLHDqfv7Ya/jxQ69ie1cfFkxtwjWnHoRDZ7Qoy+/pGcB//nkt/vTSFuzpHsC08XX45ocW4n0HTlLW+cz/e5ocw96eQdvhjx6hbuLnLgMAdNx+h/T4vkceQd/69Zj5sxtR2dYGLFiAiZ//HLb953cw8dJL4FVXZzlcOcho+QrBKW43LJqvIvVMXyqZaTLHtxnAdlI2SHNDeublGIETBgKs1PwqE2YV1W01XwreZGJOXcw9jmoh05loJzfVwvN9DFRUYU/1OLTke80bMYhTF9EGBJeN9dAWy0r7JLTBMlAcUNGkaBDmI/Y+FIUiP+/zgr+O+ZXUxlFaPGLDJXLDYjacbAovaWaaFPKDSmMGxlay3JSlFNKkNFdbCrPU+2+94SyCogiEa43k/gvrkJ+Gab0M+MPzm/Ctu1bjW6cfjMNmtODGRzbgvBuewANffi/axtVEyvcP5vHxG57AhIZqXHfuOzC5qRZvdfSgqbaK7KdR4/gZ4+0CxI8aoS4OPStWoOaAAwoCXRENRx+N/NXXoG/dOtQuXCit19fXh76+vvB7J5ucPG1QWghxwRLrxIU0UaYJS/ZS66UJM5uUrXNPpmV+lexmpenRVIgIhboaQvk9NjVD2aQJMyqvierKHFoHu7GzqgHb6lvQsm+reSPhgieaXwltdkQrljMyqZqYQaWHZXSBYDGjSPBUOzIEmi4/n9hEb+2MxJUVtZImnDrmHkU0PQkWfgtOndG7rupL9j2unszBxwYkfUU4ZPiu05y64l9JmrBIuso0PJvLgJ8+vAEfXTIDZx0xAwDwrx9ehAfWbMOvn96Iz753v0j5Xz+9sRgo+EhUVRTOdUZrfWw///mRxekOnMHouuIEBrfvQOUEPq1G8H1wxw5lveXLl6O5uTn8t1Ah/KUBOk4dbZpTCU6eONGWOuPa1YUsv2p8XlpT3gYhlJCLkWThTsX8EjW/krt+8Rrp7kaVIU0Mr6Pp4hIRJtJ77Sf1FzZB2+tazE39QHTBo55bkYzNCQUG2jdDIZeMU5cLTIriQiczH5tpesIWBPOrlvaD1Hjrb5zoNGEa5lfuMz9XjfY0YbqcuFJ8Sg3eqE57JKfOUpsYllcLvFHvc+Y8Ilr05J7NWaN/MI+Vb+3BUfuVFEO5nIej9mvDs693SOvct3or3jGzBd/83Uoc8a17ccL3HsKP/rIOQ6ICJEOUVVO37Tvfwc7/+SlZZu4f70bN3LnDNoYrr7wSl19+efj9rbfeGj7BjuLb2IY0UZDvbbVopMATyf06DJw6yjQkq8cWtyVKs3GWdNqy9Z4TOUkBTGMKGvJmrInhGpg02IXVKDpLJOHUiSmUJG2pQ5pIzOdGnDoz8yv7rET4UqSm0bJfwVHCKk4d6YykR3+IcBpjNG0eIJhfBaEwjYVfRuSPrWNnorTPJCM8I0lTaFHPb+KQJhqb6nAdYM5D5MZa03+GB52dndi7d2/4vaamBjU1vDl1d3c/hvJ+xMw6cVwN1m/fJ233jV3deHR3Dz58aDt+dsESvLZzH77xu5UYGMrjC8cfkP6JaKCsQl3rJz6B5tNPJ8voJh6vnNiGnhdf5H4b3LmzcIwxyYoQby5741MHSQJXCGeaIU1Evpu1Z5lMuBEn43BslpHRNbQBsrKyNGFsXe1RSDl1hDApVred3FVOLabu/6aahqQ8GwKTBgqT3fb68XYaF/H5JeLURRYVLk2YoqwUptdPLC/5IqZOoniz4RD1zOa+7yfPOkKFNKGckWQCQ8TRQUNTxzo1STKC2MLjOLW676Hl+0uFEiGrBdpckTeajvmVMq0ba881vKbD8+CCf/Ma65GWJkxU1Fx11VW4+uqrE7fr+0BbQzWWn3EIKnIeFk1vxta9vfjxX199ewp1la2tqGxtTaWtukMPxY7rf4zBnTtDs+u+Rx5Fbtw4VO8XtYWXA4nShCnDBhT/psSpk8W3UsZXs+XUkZwQ9WIknXBS49SJgg9R35RoH5YTFsUiTM1QidOEpchzmTRYEOq21bXYUaKV5ld1WVlIE5P7Zxo8muQwRgjixIJtbDZnr40f/T0OgfcshHeUpD+ITUTfP18mVMsgcOpKc1yKscwszK+RYrYavoQhTdLj1EXpANJjOk2TZnvRjFxaYyJz2wgLabJq1SpMmzYt/C5q6QBgfH01KnIednT1cb9v7+rDRImTBABMbKxBVYWHCuY8500ah+2dfegfzKO6MntN5cjQjWpgYNMm9K5ejYHNm4ChIfSuXo3e1auR31dYVBqOOgo18+Zh0z9egd41a9D1t4ex/fvfx/iPfQy5keD5CmiGNDHjW6lSeFmnCZOSyAXVethFWuZX9cTMB3qVaJwod34Forwh9hwl/YqgNB1kx7wAEMI0xIGpkEYt1AkRCHXb62w1dYJQZ+Ahzoc0EU3MJuZXQ02nzCQp8KVS4dSxWkDW/Gpjpqc2P5wyjhijIqSJ6jwiXsIRR5eUQ5pYvj+6m1KZpUCrntJEb7f8RgUvQgub0FIjDVotpgmT8CVHWkiTxsZGNDU1hf9kQl11ZQ4HT2vGo+tKHPx83sej63biHbNapO0eMWs8XtvRjTyjVNmwfR8mNdaURaADRpFQt/0HP8SG08/Ajh/+F/Ld3dhw+hnYcPoZ6Fn5EgDAq6jAjOuvAypyeO2j52DTP/4jmk87LQyFMiKgQwKPrPd6IU1UWjRj04ZsUlCYeK09nAiOF+mZKPFa45wUrB0lckYLPZkRg4JS41mcAPVaIa+fDCTRPyEmDwVCXbMlp45/filtdjQjQfFAzqO1T9GGhK+aGjPZdyLLRVr9+jbBhwHlZimyqaG0XTISvmh+0zG/UiFNEjyPViFNLDl11mZb8brBcjOs6Jfe+Bq2bfCsc+GHBI11KtlCyoBPHz0Htzy1Eb955k2s29aJr925Et39g/jI4QVv2MtvXYF//9OasPzfv2sW9vQM4Jo/vIRXt3fhgTVb8d8PrsN5y2aV6xRGT0iT9muXo/3a5WSZqmnTMPMnP8loRBYgdmgq01zsblY0SRVh71kmMX/GhTQxNfGSghuhFZEtRsRxJaSCKzEmEZSJmEB89g9b82tMveE0vw71AAB21TXjmkVnYdzP6aCaIronHYOhJYtR93w/Kjc9ja4DT4ff34+Wv2zBxQ2Tccj0Fqa0qOlh3iej+xf7Aw9RQyOjC/jxmjqrkCYA4AvaXd3nBGASXBCbHzLOGftZ0MYwIS3kA2AFLiKkSVppwrSFJLv3V27F0K8X3sNhTRMmHDF81+kYhsJaQ6YJG50hTU5Z3I5d+/rxvXtfxvbOPixob8LNn1yCiY0Fzd5bHT3cu9TeUoebP7kE/3LXKpz0/b9hSlMtPnHUHFx0zLxyncLoEepGO7hJWfoyCxNmWDEubECMoGBqfZU5I6icOGy9uEhOD8FbkZk9bcwvkoWLIpZHEDHfmAmTYkgT4wnQlpulW94ALfk+tPR2oqO2EY9OPBBYZRirrn5G4d92H9i+FWibX/j9tS4M3L8OPz3/iFLZcOOjwakj7p+piYoOaRJosUVOHbFxK/0Q0y8zJ1gIdfrmV9bERmnx+HON1bSJGkBR01O2NGF2ZtTEacJGQ0gT0rSrokow83DEYWh0aeoA4PwjZ+P8I2dLj936mWWR3w6fNR53XnLUMI9KH06oywpxk7KwOETqKcMGqIRBS9OGlC8m78Oa6EwtwBH5Q6L+Z9ohNRAKRCZ1SUgT8rrZRpYPTY2RmCbFcdhqGmPMr5SmKSG8XA7XPnI9XmqdjVxDAyZfcYVR/Z033oD+117H+LPPQu1BB2Pr8uXYWNmI2/c7Bm/s4sMIRNOEscKwwUJtSngnhOJImjDKecAmTRhQWChNs44Aaq4q6eFKaGrERd2WUych2luDGrsKlhq39NKEJdRiUc+v6bMdgYb5VRTcPPb9S0dwdbCHE+qyQgzRObILKiJWi6PQovm2nDqZFi2WU5dMqOPCkugQtcNDHj9eWzOKYMaVlhH7FevrdKvi1BmHNFFfv9jyKU+ynudhVudWzOrcioq2NhywdKZR/df/awO6X38K06aejaalM7F283N4Y7AKt+93DDbu6oHv+6X3hdIGmGjfKE6ZDNSz4Qn3lLqXpkIBy1Oy2EBF0nSF/Uo2NYoxkmnCTDJKcDQOQQBOK02YtRfrMGnIhXLppQmjNmkJtfKkpjYwIwsxJT0vskaM1jRhYwFOjM4KcURnVZqwOPf3tAUu2S4+jlNn6jYf+YHaaRKcuQinzsIsBUCaJoxqKyIUGC4mKo2n9s4/7gdFvwZ9aIOb9O3r+4xQNKlnNzwAPQND2LmvnynMLypsMO/oPSCEclNNDaU9jhDEqbBFkYHQ/TIbNiuOksBpU/ZLaPFkAoOU0yiDYLoVaRypxDKj+IDKOpZmVFsNvbjxThzSxGTjazg362yqpSFN1MccsoUT6jICJw5JJ3xhwgwrxghOwTtjaLZVQWaqUxL8MwhpQmeM8GBjfpGGNDER1KQmaq2eAchCmhgu2KaaBu4SpTzJqgQH0/phmAwf1fkhTGooGBE27uoulRU8xDltdJL7F8epo4RikSCuE2C89APZb8mixcSpM7l/upw6SjCXafF0HR0i764oFKZApqfmDgXIVGhkX3abOVXYmxHJqSMEXjpNmEIL68yvmcNd8azAaeokl10V0iSOU6eMU2enRZNyasL4agkJ/gEiZihWMIhX/5fa8SDTmpj2z56jsi/ukJ35Va3xjPEijLRjxpshr2FSWMQJZFGiHfDan+lNhdiSG3f3MGUJ86tJuAljTp1aIFLGIKO08Zr9cuFeqHZVUHLq1MIJ5UQiCidkMHWI2kGm3LClCbN9/3WFM1uzraiht3QwU/TLXb/EIU0ITS2ZJkxYh9IILO1gBSfUZQWO6Bw9HB/ShDZxpJYmTLbgiZNxODa7kCY0GZvYacoEPpaPZ0uUzuWiC6wBJ0s7pInyHpsJ4MaahmHl1CUUGBVx6qY3FUIIcJq6CH+N0QZEzOfUWCSaWnKMhDZY4EvR5lfDfsN3m+HUGdw/rnUqFiS1MfIk5XSzBgjUiAhvOAXeFZ8mTLMdW+EsaZow0cHHVuAhzedJza/E3Cw4unDnkROOpZACzsEO7opnBXYhpyZ8lfk1Jk6dMk2Y8U4tOimonDhsd5xGacI4IrRkh22jhZIsXEY8K8ud/ogIaZK2OUTmCWpRX+SkBZq6N3ezQl1OKFvSBpikTjPiTwK0QBThiVHmV0MNL0N7KHHr7TR1dH5l9julKRee31hOnfDcRRwtUg5pon1t7Myo1p6lSvNrWkKdRJsqOWbVNme2F4X6EjdwpKcJezvBCXUZITZ4qBgDqlQxKCBtVylwWXIa5IujXOBMlLtRNlkAUfU/aVrIRRcODUhNvCbR/lUmuPiOC39V93i4FhdKKEmKpE4YigVvRnOgqeuJlo3kDpXdPxPzKz1uSiDyxHuaJzQUhnwnPk6dhQCkEniI54cUCihOowRepG4gwKe48Fs8f6a5f1X1jEOaRIQhu+WXjMlorYVUlOemX34DM5rShL2d4K54VogLPqwMaRIzAUR4DkEzlupv2cKjMPEmmpQV5F6tRYX5zqUJMxmHyBUxmAxtOXVqh5Pi5KirVo1wamKEg2Hk1HkWQjVXX5F6aEZLLQBgI6OpI9OEmSxmpt7LOppkizh1sf2y52vFqZPfGyPzKxHSJDYzgqhlFwX4lNOEWW+KbL1mTekewTOeNE2YkaXDuHH+G3eteKGcC80SWiGiWnSHbOGEuqwQG6dOxbeKEZxETk+kXkKhTiekidVizp6PpvlVpmFjFyuTGUzUFJru3pMsJsqwNXaaxtiZexg5dTznxqa+IOgKQt2mjh4MCcKDLKSJSbgQ4+tHCUSi9iLNNGGsadrC05zjmxFe4vrhTgTzW5yjgyAQDHeaMO3335ITK7UU6EAUeJJy6ihLQUJOXXQelMwdsrAlohNNeI5OxMga7opnBE7okr7MwoJVqlisEsNbidDdLDl14qg8jZAmNp2otAMmpgWRU5fANJUkn6q+g4YwuReRNAaZNjcLhpoew3FYhTQRtcDFv5PGVaOqwsPAkI8te3v5vsQ0YWwMtHAsxHmaml9J81awqfJjKRbG4SYY7b3VMyLhw0nbIDS5Uk5dxMNRYX4Vr5sgFKaSH9TG/Gor+IyUkCaEpSBpfsN2qAAAaXFJREFUSBPKtKtOE8Zk9tEV+B2GDU6oKwdkL7O4CwqgG9JE5VFp7P0kmRRUJt4k3BAlp47SFEiEOk9RNgaeKIzYmsZk41LWESa+EH5kTPFtEWZpAUlNpPQ4EratWPAqKyswraUOQMkDNhK8lhUKTEzixoR3DS2XmJ9VSrEw65d7t23MWbqcOu70KE2NoI2J4/mJdSOOLmlw6iyev0g5XeHMbDPAVCz8HQ1pwiLPt6RtWZowVUgTx6nLHO6KZ4UYTZ11mjCF1+zwpAlTeNgm5dQRYUkovl1hh6gv3PCVhcnK0PzKHdUmaAvmpwA2DieK66foWFovDSQNaVK634Kmy/Mwo7UeABPWhNIGGMQZJBcuGShtEDumGIqFKDxoh1JhzK9Ggj9blNW4iMV0zo/tOxJSJt786rFOTaKmJ4H2mDO56jZjyYlNzqkTPKQzSBNmfG3JeI+8NYlPE1bSWHPHXJqwzOGEuqwQN+GLE6ZQL27ijGQpsOVtREj4XnQyDpAgdyM3KlKLEMP3MRFuWIhaDNOJnquv2afICSvCRuOpvH5Ev1plTcGR4S3aDr2+BU1XLofp44tCXRCAWNT05KOLitiufMimpnbCfM2+f3Fhi0xDmjCbKatnxFO8G4TgJn3/xfEInEblMyU8d5HcsWnEMrN5/221WdacOl7gyTJNmOkmTstRTZomTNDiuZAmZYMT6jJCXPT10oIlN80pJQelE4Mdp0HmGRfZoYddpBXShBLcFHUAREKa2Jpf2UlJty2bxSQ0p4n3KmjT1vyaQChJChszNAuWJydsfGa0FsyvbwaaOjGkCcupi2h4E2jfIkMknjHm/ePuahqculCJyQi81iZ6SqiLamOkZUONU/ADTYaPmO4iji4phzTRvDbSNIFafRk+Y2E5UeBJyKkjBLfU04Sxj77CKcilCRtZcFc8K8QJdQqHh7gdelyYjOQvdYkvERE4kxCdVWZVKt6YZEG1ShMmtiXj1MWZXy36LRGmVc4wlubXWE7d8JlfU+PUsR6eAOB5mBFq6gROnSykCWk2koC7f3GaTvX1C81/fl64rzJtPKEFkw6RWURt+GeqDQ/h/UlpaiKaNpOMEjlGG55mSBPb54/i6ir7MnzGxPaHLaSJ5jEdRDS1kvk3fM6jnLqoE43T1GWNynIP4G2DmIfcPqQJP2EESCsvKxnSJEFkdBUPhFxUZHw7W06dKOiYmi1MhAKxTVVIExMB3MSkOqI5daXnV/QeDTh1T722Gwd8/R4gn4d/yvKC9vjr9wA174N/yjHwVhamMf+U5aV2v/uEcjwN1RX4ysT9cdiWNcUxmGj1FM+JYH6Vx6mT0Ac0+vW5OHUmJnr5e0VqqggnisiiHptRgtfiKkOaJFr4Lc3/uRwwNBQdJ9mV4f0TykVDmli+i6TgRRzTAUVDEegPsjRhkbzALqRJ5nBCXVaIIzqrOHVxseCCCSNSzzKkicwMqdIGxpmGKagWEmrilI2N1QbYxqnzJPfFgFNnHNJE+NlGAPc8r9ROrBlvGM2vSdtmn19BU3fA5HGY0lSLLXt70T9YfL4rqgp/B/OAVwFUVJQuaHAMAIZ8RK90Af2DeTzcvigU6rTNoJA8Y6zgFeP9ap8mjF0kbZ9xiZZJtpmQbZyENkJtTJxQxv4sMdH5NpsZERIivxZsuKC2Qp0ypIndu0hxQo2fsdi2JZvXiPnVi9zbVDybHazghLqMEO/Fyu+CShU1OXXi+mUb0iQyLHaHnUFIE4rELCMIiwuHJnhOXS6ZRlObU1f8qxLArTWNcRofA62eKZKadsNnCxFOXX11JR78ynuxc18/AKDn+efx1he+iKqZMzHr5puw+evfwL5HHsHEyy9HrrYGW/+tpKmb+7s7kWtqinT3p5Vb8C93rcKmhjZmDPbmazYGWWwqQFO+U/hu5+2oDiR1gRHqyE2V5DnTDDDLa3ERneNsuKQiLM2v/KZIr/9ILERd2oUYdirLkCYJHeUgzpOA/Dwovp1DpnBCXVaI29UqQ5rEcerkJr1U04SxHooshiNNGKUpkBCVSa8+CnGcujjyPPtFm1OnML+apgkT+jRKE5a2+TWhwMjxDCXeo7VVpXh13Q2VGOjpQHVfC6a11CGf70FXTwem1AK52hz8no6wentLHSqa6iL9HTqjGQCwqX6Cwbipc2QEL+bd1QlpEpsIRBKnLo2QJsWGpOUohyFVgFk9Tl0uOselENLEigYhjE1/U5bM/BpIsVZaV6Jf0pEnoVAn49RFQprAYwR2SbgTh0zhxOisEGN+VXmYaqcJUzkxJN2pcSFNhLJJiM6e4gsxKUlNA4IZVRviZBVZq+O0Xxb9BqY60/y+EnjEt2hhA62eMSwX1Uh9n9/PyK5/jl84+DRheman2RMaAADba5vQnyvsaWOfXw1OXSSkiXT8xIZFBpaLZZMmTObkEB6TaGBk7cu0QOL1V3Lq+I1TVNOT3Pxqzem0EQaTpgkTuIjWAg+l8aU2xVogNLWiowsX0kRxzHHqMoe74lkhbuEWF6wAcVw8Ue0t1EsjorhS4EwQYFKpYaMmLJn3GUcANzFN8ZO6sWebgaaMKVj4qzS/WprWYoUD5mPakyynZbU3v/ps1gShXaaDwt/QeZIJaSIKTIr3pbWhGo01lfC9HDY3TAjr02MknjHW/BoTp876GbOMUxfLqZMd0yDhh0T5GKEsEhg8vH+i92yCZ9L2+bN5f61DmogCT8KQJsQGJnmaMGJTTZlYFVpclyYsezihLiPEqtyFBatUL2bijPVMNXypZZyatD1sxToEJ4QKdwJRQ2Ok6RIWasOQJiTXT9VnTBBna03jWAhpIolTJ0KL0xMzFs/zMLutoK17a1wbPwYFKPOWcsOjxanT7Jc17VqbGAlNJqkNZwUGlTYmZk5DsPAHArwY0iTBwp+AU8d806tjKpSXKhb+imnC0jI7e4rfbfog51+V+Z1dI1xIk3LDCXVZIUYbEx/SRHWr+N1vqbsEpg1RCMgJk3E4tgSR0RUhFkjvq8h6I6QJs/UMFDR+Om15NmZHpYndPFwFuRBHylpeI61hJGyb9ayOy50qXj8uTZX+/QuEusBZwuj6KTUh8UKpOEarNGFGHp7MZ1HLBMWxyPsnGU8kpEmMFaHYkCohfJJnkuST0RVLn7WFM0uByePPOzYQvQ5U2jlKKNMBKfyLmlrGiS/nCcdS8Gx2sIK74lkhjhQct+DHTZwR7Y/QrglEQSr4qkwTZmF+5dnZRP+UacETzC+2WgzQk1lsfc1+0+TUKa6RojBTNOWds4lwKa1e0mLEeo+K3pNUmjDiWs6ZUIh/F3rAxppfiWeMNR/HxqK0e8a4to2eEcI0qS0USI75vKZNvVEVBCdh45rKwk+F86BgoOmW9SX9ruyrKPCI5tckGyyF+dw4NJMIQlOrcnThTOuywOAOmcIJdVkh1vwqX/BjY8GJE0aAJLGQhAlfpUVMTxtITESku76gYTMikfOmoWw4dQrB3WYCNDGpWpiKh2UcRH1OcAHk91JYVLjnj/IIFDCr6CyxadxEvXET5i1pSJMY3ixTme6X4+sNQ0iT0kH1mCRtaGtjFJy6sF4qIU3kwk0cSOuAqo41p46gDViCDxgdM0fatgsIj4b8PPiwVy6kSbnhrnhGiJ2UrUOaqAQF+xhy3GutlSYsueDID0AhqEk884YtTVhsffazXr/DF9IkxlQ8kjl1oRYYsSFBoiE1SmMwyd0bcupCTV3MEMnrF7y3eY2NG2HalBVnL44N75J6NxRCQXToEuFHav6WQHzHRd5wGrwrQuCm61lsdKz5agrza2qcOmKONO2CdJRhnnUIYUvENcJx6soGJ9RlhZi4PfYhTeTm15LmLpnAlUlIE0LLQsawYyaTcKy6ECcrsWrMOVlxyZg2OY2sjWejyWI2jCFNeDOwRX1G0I01Q+fkC0fkOaDaADCnKNTtqG9BX64y/vmlrh+roYilWBALpgzsJiCMU2epjSK8g0mhVSa064bmEDY+qpAmiXK/ppIm0Pz9lX6PqRcVeBIsv6pNcdI0YdQ5io4ubNgSlyZsxMBd8aygHZrELqSJKhRKYi2aJ+FLhH3Y78Z4oUhTUyebcKw5dbymIpn5VbNfdnyMUGdDnCavH9GvkTZQayDs9bcR7pnnN+46hBuY4ndWCBRPi3gWxtdXYdxgLwBgc0Ob2fWTaIuB4kJnwjEjyon9+mxIE2veaLxZVdY+lSbMKKSJZB6Jy0ihBdv3XyXUataRfldBGdLE/l1UcWqTpgmTdBRtW5ImTBWY2oU0yR5OqMsIsVoIFaculrcSlBN+T8JpEASp2DRhw8mpI01IwmJuosWAMKkbmO8KYzE333ATMSsg5y1MawaahghhPU0kNr8yC0WMWYrLPoGScMFpgYr1qQXe8zy093YAKIY1Mbl+Kk1IPs8nOJfBllPn+4yp2eAa63LqtLx7ERVO4jhx4sZHnOPSyA9qyxe14OKmniYsLUcJ8h0064MKUh11hpCEFHIhTcoOJ9RlhZgJXxVvLo6LNxxODJFdoKh2D5CIU0dpPxSmBTEkRC5BmjBxUTOMU8eHNDEzwwDg75eFac3I63QYOXVkNgIdSOLUaXuIs8+f4Tim9e4GUPSANTJfqxZNP57HGqEPxHTLxjcL2zbRRjGfIyF75AOhQgpFOXUxG0fxHVNpehIs/LacWiNNd6kS/T22nkZ+YF2o7pnKkUcXlMVCsArJ04QJWlznKJE5XO7XzBDHjVOYOGNjwQUTpcKj0mqhZSc8MOtWiiFNCKKyB0iTbUujnYtj1QXFqdOZiGz6FTh14WUd7pAmMrJ7auDN2Ma1GfJ1vDORoOnhhAKzxX16XwcA4M3GiRhEDv2DeWXZAd/DgFdRaNqr4MoOeBUY8CrQP5RH/+AQhuChStUQ6YFKlLeMU0enCVOY7CihQKWN0TE356KcurRDmtg7kegKZ4YUDaF9LQ9vXag2aqbPmIiI4CppO6Q/MGtaUE10YnKcuszhhLqsEBdgNoYbF8+pSzEwsMA3ifPatHpxKe2HrmkolwOv8TMQith6IqdOZ7JVahOJPhWcukxDmqRufmU5TQmeA99HeCHiNHUybQCl+ZVgWt8eAMD/zVqK/3sBwAv3EKXHA6f9e+nr19myRwCnHQFsBPDjlzDuA9fgO8/chPmy4VvyNjlOna02WpR4VM+PDlFeFnxWCmFDFnAEfVHTmuCZtH3+bLh4hLMJhdL8yQfYTuYgIt/UJU4TRmlqxXWAdZRTCPyOU5c9nBidEWKJzuIuKKgXJzilnCasMBRBCFCENEkrTRhJ7o1JE2Yd0kSMzWVoxiXTlykrMXU4Tl1CErxJSJO0NXWJ04Qxpv0Yc5wypIlnLpQv7noL4/q7zccbg67qejwx8QD5wci44szmzPnavGskH5Wzv6rHKPNuFr1fdTJKsB7KwX2zCdMiwlTDHg7H/Lkls93QFQt/GQ9po/pUmwBUpnSrPiK8QcmzIfN+FlOhOU5d2eA0dVkhhugcnyZMc6ELuktCxhUnY3anyXdSKJJQG0hNRFTIjEgoC2vPQI/vU6sBYvwafXL8RCtOHdt9nHCgLwCawjpNU1in+FfDUYIMqWG4SE8c2of/veca9FVWYfLXvobm005Tlt3z299i678XNHW1Cxdi5k03hce2ffs/0XHbrzHhU5/Cr6cegeuf24mNDRPlDUWcLGKEcT6IX/CjNnjzJ6FlorScupoaGYSNj+jokkaAWusNixF9oQhTTavQvq+TNUUXKksBJZTpQMOhJqKpZfiSvhjSxHHqMocT6rKCT2sh4jh1yomPzT3J9ZdAqBMXanbhlYzNpg+SU6dYoKXmK1uBRahn7CFq0y9bh9F62nHqFCZqeWl5vTRgm6YprFMSFLTj1AXf2XfDVNPq5VDlD6FqYAhNVTk01ymZcMhX5bBvoBACpRaDXNmeCh+DA70Yh0EsaK0BALwRBDUW+0whTZiZ4E+YJuPeK9m8I5jYjEKaSFJJpc6ps3z/9UMSWZo2Jc5AgMZmTKdNYRyJ04RR5lsipElk/UrDw9fBCk6Mzgq6acKiEX7peuzEzyLJLliY8MuaJiyOU8fJn3bml0hIE0OhzopTx3m/hgW02hH7j13MMuLUJeFW6sSpE7XSfEgTQtskg8n95pTFgsaLWbDnNhWEvY31EyTp/iT9aAp1SINTR2pgKPpDtFzJUSXG+Ut8R0T+rw2XNNKH5YbFKqSJ4t7H1mPmT/a5SOT1q3j/STO7Truippb5qNDUcpvrFD2bHezghLqMEK+FYHZzsnpxcerEeknShIlaNAWnLq00YVo8Hkk5z4JLJe9D0PTotMONS9cMw1TiHCUsSMUGZs/h5NRRnpN6DQS7fzAenjFlZSFNTM3AhFk/UpQUAEvai1mNlcj5eXRX1mJbZx/dpw4407RFG2xRMqQJJQhIhGXRfBpnfQg+C44uqSz8luZ/j5dWzPsy6q903hztIskGS3XeSTl14hwrFepFTasXXSNsNiEOqcBd8axgyY2LrSfukAKUYoKYjbMwGP6zwokjmYmX+RjRYHjSY1K+Typx6jwYcdQg7JR1T5/l1LEZJWyCOCuukRScVjLlnbOCm6UNzhlA0/wqEwoMNa2e0fWL0RYDgJ9HdQ6Yum8nAGDdti66HY1+ZXHqTAQg3ZAmuny7CKfRJIOGJ9H4p7Dwj7o0YezGOBNOXULzq0wTL4Y0YYPAB5w6sY5DZnBXPDPohiYxDGkieh0FSBLSROCbRAjO4diSeNiqzXbKgMJSTp2lwEKlCRsm8ysnAHHmV3NSsVmasIQmUs22bfh6rOAS603NhT9B6ZnP5XjBVUtTZ3L9CK2ekCZsRudWAHKhLg1O3XCYX7WDfwucxlj6RSynzo+WM4XNeyjU096USiwFWtWGgVOnDGmSlFMXGZNkfpWkAosoF1xIk7LBCXVZIdaMKuyCAsROnMyiIunPjlMn7M5VnLokuRupnbLC/CMl8arKxoBME6bFyTI33yjz6Lo0YcUFPo53WvwrEQqMvXBNyhO8LVbD7ufzmNG5DQCwfrtMU2doGmM05Fbe7JSHJ+UtrLw2cvO3cuGO5dSlEdLE7v0nLQXKrixNm6zZOSVOnS5FxfTiiueoFdJEtka4kCZlgxPqMkJcXkiVNiw+TRgzYbD1fPuXKsI3EVzZQ6QV4JjUFBCTtkebHkhwZT2ubS3zq01IE6bf5CFNDMZrY2qyGIfVBG6QJixqvmOEgkSa1jihmGib1R7mfczoKgh1UvNrxASqKYxzcerstdHStgsDUY9L5t2saz4Vza8qTl0S86vlpsIqTZit+ZXVRo/0kCZiGzJNbSSkiRdZI1xIk/LBXfGsEPeQKzl1MWpsT1jowv6E4ybgtFYoyTtZpQlTaBGi3mc5vq6FcBV+ziKkCcCMUcKpM1qUTMbLCICJ1CKycegLR9L6jKCmG9IEKC4aXEgTs/tndP0owZWjTfihpk7OqTM1jQVCUPqcOvK9UXEwBRNb3MYxoj2NmF9TINPbvv82XFBrTh1jTUktTZji+U1qfhXbkLUtpoljOcmRkCZOxMga7opnhbhJWenwEGeSigoJAJJxGrhJPYuQJprmH9mkaukE4An1skgTxvWbZkiTuOs/okOaMM9v3HVgf2dNWYJwbxzSxICTGOXF8ZrGQKjb1tmHvb0DQjOGQgGrGbFZJCPaaPkxclyS6xQJSRLH90XxukXMrzH1dWCgcVXW0+XGWXPqmPmTTROWiFMnf345ikfhB/PGFc8NFXxayalz1tfM4YS6jKCbJkw0ceqmCVNx6qwWcQWnTh3SJAVtoPIYrVGwStcltiVy6nTOh7MKWyy0kjRh9iFNYoramqh1kDikSWCOZjwD4zzEgYJmj9nwGIdWMbp+GlplvxBLrmGwFxP6C1q69aK2zpSTxQiMVin5tHlzhFAnu066GSHEeUR0dEmDd2X9HlpsdGyFJeEZMepTayzUMfN+xA1vpF0Zb05cI1xIk7LBXfGsYBhYNYRuSBNRixZHOifAc7sY+6sypIlxFyCJyooJS7pTTsP8asOpS9gvJ7zbaDxHSEgTZfgL/QYKfzlOXbz5lQ2BEtFOaJnP7a5fVDALBJV8+H7M7N0NQGKCNeXUyQj2JrIE4RlOOZZ4fEGmDWGuiVm4PWFzNpLShFnFqbPdHBkE2NaGpqY1cQpHGaeu+JX3XmbeY6aME+qyh0sTlhV8WjhTeZhqm18jTgxJYsgJi4EqpEmCSZkOaaJYcGWTly23LRLSxHAXbjlxep5XmPCYa2lDKh6RIU1snoOcTHCJeUcA/hpaPAfKsDnyQarbDjXlJU3jzL7deA4z8JO/vooH1mwrjXlgAJ3vPC/83vir50nBrsdbiIF3tqB2UxO8HRVoOeiDuNSTcPV0xk2mCdM0zQqcxtiQJKL5NcKpS4F3lUacOt1q1jExZRuXZJurOO1xIqFKIShHFA9s7m9FCjFnf80eo0ao23H99eh68CH0rlkDr6oK8596kjveu2YNdv7kf9D97LMY2r0bVdOmYfxHz0breecpWswYwcusmkGEXVCIuFhwymwPSUKa8JNXWdOExQl1lMaPQPI0YRbmm0LHhb+sEJ5lSJO0J9nEnLqSpivW01s0vzJpwrjFR+dCctdB0wwKiRZRomk8oGc7AOCVbV14RdTWTTuk9PmlrTGDbAOmtQH7UPi3//vw7q7HMTumVmRs4ue4Y0rzK/OZcVRRXj6xriAUppIfVLUBjIMNJ1bfYs9Xk2pck76HlvdWp2VWKJS1ZRDSxKUJyx6jRqjz+wfQeNKJqDv0UHT89reR470vvYSKCRPQ/h//jqqpU9Hz3HPY/M2rgFwFWv/+3DKMmEecNkZlfo2NBRe8M6o0YTYvtbgLVIY0sQizELZLmDtVC27kXAQHBzPbFN+u4UTomQgFLALhnXOUsBDATcZrq83UGgf72f454OPU0WUB8GE+PE8wA+sI5QbXhDJVMgTx4P04vuMVzLziy+jo4R0l/N5ebL3238PvU676JnnN9vzud+h5bgUajzsOf+hpxEvdFVhX2USPlQUR0oSMs6i4lpHcxQxRPrZ/MaYk572c4JmkQh5R4KrpvXfW3FQmQoEVN1IGTU1rckuNxPyqEdIkNTOzgzFGjVA38XOXAQA6br9DerzlzDO579UzZqBnxQp03nvviBDqYp0KlJy6GPK46HUUIElIE1GQUpl4E4Q0ITVdCi6QNDBmKmnCBE2PFtE+odknYZowszRXhKYpIbykAqPUNKUSEpjfRaHAcMFVmvhlZam2WU158R2vzPk4ZXF7pJ2hrn14+bXHggFgwbLZZL+b796Ojtcew8TGJdhdWY+XuiuwvkJfqEsjTZhSWPb92JAkYh/cGDjHGPtn0siMToxNC7ZCHetEkEYYl7ix2GghddpWOrowFpN8irH4HKwwaoQ6Gwx1dqGiuZks09fXh76+UvLtzs7O4RmMH2OqUApnMYKTKk5dFmnCEng4WaUJC75zan9CG0GhHGnCoNDIxvEtpQ0ZmD1tBV/DcVilCWPMNsZx6jILaUKZKhmhNCaItHGgXMYzeL/aQQDVeDXXGF9P1gdhYiVTSxGculjerviOKL2XEzyT1pxaw+elUNC8Dpj7ni89s4mNr4SHq9J8qgsVp45IE8atX+I6Mcrw88dew48fehXbu/qwYGoTrjn1IBw6oyW23u+f34TP3fIc3r9wMv7nvCOGf6AKjFkxuvvZ57D3nnvQctZZZLnly5ejubk5/Ldw4cLhGVAonKk0dXITZ3x+RY8vFyBFTl3phRU5dQkmZYqorMsFEhYKo4k2aZowtojNrl2aJsxEqNMn+Hi2gq8OEvP1gjrxceq4X0WhwNQMbGK+JryHjfhSplwnpu39aocAABty4zAkhi+Kqw9E31HKXK0cp2j+juFNiX1EHF0SeM9LhmRkMTA114vt2/TFCjxJN1fU+29xblx1rinJORMhTdjnArBcf8qIPzy/Cd+6azU+f/z+uPuyo7FwaiPOu+EJ7OjqI+tt3NWNf7t7NZbMbs1opGqU9Ypv+853sPrABeS/vldfNW639+WX8eYll2DiJZ/FuKOPIsteeeWV2LNnT/hv1apVtqdDIlYLwaivOcSZbUOvI6G/BCFNogtkIDiqAiObd0ESnHU1DGJd28CsIqfO1HvSiMsjuV82acKsza/pCnXGXDYRoZDLaLo0colyi4cHC02rWlATQT5jJnwpU+0Qo+GZXjmEmsF+9HkVeGNXd3xdtr74Wew/4hkrP8ZdJ/b6q8yvAt8twslLPaSJhcbcpF5STp2GM5A2KEuBjRZSUZ/S1HI8cZYbO4rNrz99eAM+umQGzjpiBvaf3Ih//fAi1FVX4NdPb1TWGcr7+MKtK/DF9++PGa31GY5WjrKaX1s/8Qk0n346WaZ6+nSjNvvWrcMbn/gkWs46C20XXxxbvqamBjU1NeH3vXv3GvWnjTgthOg9FNajBSdlvTgHCwKRGGys+YDrI0FIE21OHWFaEMxu9pw6fsHREq6szT6BUJdiSJO4eraCr9ZAFIu+LliTThy3MGL+Y54/w/thFtKEMr8GGnY2BpniHTcUgD1GGKjw85jZuRWvjJ+BNZv3Yk5bg359xG2cqHqKMfs+Y+KjrQ+FusLGKZ9PP02Yrfl12Dl1RYGHM9En3FwR82fijZbqeRcdXdjg34w2ktv8j6I0Yf2Deax8aw8++9554W+5nIej9mvDs693KOt9//5XMKGhGme/cyae3LA7g5HSKKtQV9naisrW9NSVfa+8gtcv+ASaP3waJn3xC6m1mwoMtBC+70e4V+qQJlEhga+XbKemlSbMauJQa+M80VFDMbaCUMdVNOifHYqF+dWaUye5ljbmV1tOWNo754QCo3Qx0DHnRTh1hkK5iaaGEhxCDTuzYCt3YHbm18AzePbezQWhbksnTl40Vbs+P9DoMTr4t/wzL1THz2niO1YQcBRjM0FSk6hRPU/ySacrxvyaUkgTj5r4bK9JAMU7TWlafZX5NV3DgDU6Ozs5hY2ozAGA3d39GMr7aBvH/z5xXA3Wb98nbfep13bh109txB8//+70B22JUSNGD2zahN7VqzGweRMwNITe1avRu3o18vsKF7v35Zfx+vkXoOGoIzHhggswuH174d+uXWUeeRHhg665YIUf4zh1gaZArkWzM78KQgCrjeD6SCfAcazgRtRjFyQT82VEG2kq+ERM1JpgzY0BMk0TlvIsa3sdwjrMs2Uap06mKdAdB8XpjJRVC4xcSBMDRw8jZ5x8oe05ezcDANZu0XTm0tSGU96TSlOehvk1YsblyqUf0sQsTp35RsfY0UUsq+MMZNomEH2n09pogThnNo8tw6ljhf1InTJi4cKFHHd++fLlidvs6hvEF29dgeVnLkJrQ3UKo0wHo8b7dfsPfog9d94Zft9w+hkAgJk334yGpUvQ+ef/w9CuXdj7+z9g7+//EJaram/Hfg/cn/VwI9COUwcUXgpmQi/UU5lt5abRJBHFozHYgp2mUDDJrpOajAlOCGt+jaQJsza/8mZcnUXGKKMD169Es5plmrCRHNJExzSVy5UWlIzShJECI5cmLGVOXagFLAi8s/cUhLo1W/aq63BDUz/TJCdUJaiL5teY919MIWcsFGrANk5lOTh1YyVNGCA4euVyCK99Ps8HcBghQt2qVaswbdq08LuopQOA8fXVqMh5EaeI7V19mDguWv71nfvw5u4efPrmp8Pf8sWTn/fVP+KBLx2DWRPiaRJpY9QIde3XLkf7tWrpeuJll2LiZZdmOCJDxAXqFXdBAWJDmnhcuUgbCbVoOiFN0k4TRmp/gr7Ev7KyFKg0YTqLg+XEGZpNOG1sQk6dUZqwtDV1dmboUiVD01RRqPOZ8BCiZ2XqnDpqMef4UjH8V1tOHQptz9m7BQDw+q5udPcPor46Zvqm7jtxvZRcPHFRj+NAiqY7UdPKZgSxhe2mjrs2mnWS8mg1nhFdUM+StZeurD2Vk9XQEP87l+6PWSdGiP21sbERTU10jMfqyhwOntaMR9ftwIkHTQEA5PM+Hl23E+cdOStSft7EcfjzF97D/faf/7cW+/oGcdUpB2Fqc116J2CAUSPUjXrEZXhgJ0ww73ys12yOLyfUSzWkSYRTl1ZIE0KLoDK/Br9zG267nbpVmjBbnprsWtqEdjCYuDMLaWKxUhnFqQMYITDPC8OsAJF2mjBKi8sKpXHBk4Pyvq+32IWm+kLQ2pb+LoxHP3b71XhlaxcWx8XOorRRFKdO9W4qOI1qTp3wjgi84UT0DcmYjLRSFpxY/omxmGt0nxG9RhUjE45Zzf8KQY7lVDJCHWt+jXLqRoZQp4tPHz0HX7rteSya3oJDZzTjhodfQ3f/ID5y+AwAwOW3rsDk5lpccdKBqK2qwPwpfNzIptoqAIj8niWcUJcV4uLUiTGgwmoxglOgKVCGG0lmGmX5Zn4kbko6nDrlQilrOxTmvGJdSy1UQk6dsWZPaFvOqbMzH8cuZtQCnhSJnTCC5zfee7TQXdH8zi0eHn8LTPhq0Ll+yi+8UKqraRwa0jS/BsJA6f2eh248jWp86bbn0VpP83j6e/bD4NGfBQBUv+ih8q3HwmO9TUcjf/QiAEDtnzbhiNc8XHHSfNKUbWo+jYQbEYXCFDh11nmNTZ8XsZw1p244zK9qLayNUMUJrCpNLSvU5fh7GzXNjh6csrgdu/b143v3voztnX1Y0N6Emz+5BBMbC+bXtzp6Rryg6oS6jBCnhYjEgAorxmhxFOZXG5Ne2CSv/mK0gaqQJjYaGkIYILV4HvcXJmZIZR/CgqNzOpahFEq7dlbraa7xNCJtJyRO0+OwNEmFdYr1fZQ2PtQNCMvzQoFpnDqT62eaJoxsryjUGY2RyXO72NuLp/0WrNvWFVsfGAe0jSt83AtgL+M0VjUBaJtQ+Ly1F09vXY9zlszArAkN3LWRZpsochpjN5yChjPq6JJySJMkjlI6sObUMRvv8JwTCga2TjBabSvOU0UREufPUSzUAcD5R87G+UfOlh679TPLyLrfOWvxMIzIDE6oywoGKXU4AS1Gi6OOU5cgHpKwC1Ry6lILaaLmhChNQ4LGrvCb3U5dFApM49RZadhYbaxVRgmDxWxEpwkrPVta5tdA0ymGNDHWThCmSUWfhc+iVrn4V9PRw0NRhNfS1AUCbD5s+7yKzTj642eit3+IqFhAxx13ouvBvwAoxAStP/TQ8NiOn/wPel9aCQC45f3/gFf39GPlW3sLxG5K4AkEFCZXb+yGE+Df2+Bex8Tu1ILt+2+jzTLd+In1GI9RE/OtvEm1hpIMCaUDFaeOKeIPMpw6Nk2YeGyEa7XGIpxQlxni+CcC3yT8rMepU6UJS/xSMwum2IefIMAxOUGS3oYe99fW/FK2kCbsrj2ATZ5egwWGv0b6XZiPI4EZXtNRIhSKImnCDMdhZLYnFlBWc6hrfhX7V3bLangKbVd7wPvmT4qvC2DrPV3YtelFAMC0SRVoYmLbbcxvQ1fx2LqpdQWhbtMefPCQqfS7EGgafY2MELJ3M9T0IdkcJekjyzRhRuGTJNrlxJsrbScYm7mZbVpxnYYG+f5lx5xAVxaMPt3oKEWohVAl+2a/mASmDX4W6W7Bh4QvNSfwKEOamHehG9JEZVrw2EUiHKql+VV0lNCYjBKHNGFN2ZmmCUvb/GqpKSk1AEA0X2oIRWKaMNNF2ihNGHH9uDRh+ppG0zRhNvHNqHvDHjtoYsFLb+Vbe6J9CP2JQdGpMcn4rhz9oIxpwlSp0OLrGQjlQvv+KEkTFj7jRLsR3pyMUzcKTa9jAe6qZwUT86uUUyevF2d+tdGiKbVYaYY00RDcCt0Li5E44VjHqeO1CPwu3EzTY+Z1y5jUisg0TVjaE62tGTqszwi5OsKtxPw67GnCyGfVTCiVbUaUZTkBVkPgjTYQ7VdybGFbSajjstnI6gXny3GqVBtOybPBzCVJeL+yPqzfHxO5JxTqTEy97EYuJkSVaZvsmIoo8Y0t+5BRW8TvQkgTabgTp6krC5xQlxXiPPsU5lftNGFKgSuZ+bUsacJ0zK/hxMMeM+lf0HQZaupszDdsWV+qjdVvhh9jnP01oTaNbNvwuonVDc2vMn6SqCkwDmkSN26SKlD864f/0Qu20YLLNB4Xr5LqC4g+o8yxA9tqUZnzsLt7AJv29NLXJvg+WDK/aZlfRQ0Xl/g9wTOZlOcGw81IoHFMGNIkqcBD8uYMNg7yxuX12Wcv4v3Krl/FY45PVx44oS4rxGkh2BdAFpg2Lk3YMIUb4c2vKhtvsj4oLYLSBBBy6uw0RYk5dbahFEIBOb2QJnGCmu010gInW9po6ljzZbzmJnhWInGyTDU2JkI8EWCZ16ZpaMdNND3MBiA2XaC0PvGMMseqqypxwORCXK0X39yjZX6NXH8JoplpSu1p5Y7VgXWaMFsNn4XAxD3j6acJU2lTbfsI7odUKAvu36DAqWMFvuCYM7+WBe6qZwWTlDoG5lcZR4vT9CUxiQX1Y/LL2mkDCSGK4MlEQppYc2qEeknMdyb9hk2z19LC4cSSU5dIKyJr2vC6SRoAwId7IJ8nidbY84SMIFqmTZPrp/xSume6fKmQU2ewccgzgXqNOHWEMCpsag6eVoi2/9KmPTHCYPF+iZoa+QCYMoGGq4jhSBNmGxIoQ06dlRmdGodsLJRQpgVCcJVZbURLh+PUlRXuqmcEkwlfHtIkRhjkzHnJ0rR4AhcnLk2YzcurmyYsMvzIpGqrMeNNkhyPaDjThEkygPgWJpkRw6lLnCas+FfXHKcSKjhzmolpE7HXhI5TV9RcaaaACg9pOePITNOx1WS9qU10AODlsGhaM4ACr459/qNa9OhcoBQeZEIlq7VSjc0Ilu8/d44m1QLzuUVXaXLquH0a39awceqY33yCU+c7Tl1Z4YS6rBAX0wlgzC1Rz0jlwkMIgoDtQisseEpOXVohTcRJKX4RLfE+eOFMv3th4TI1vxKTKgmKU2cb0iRmhRETq6eKhFpA8zRhxb8Ep0drHCblCW1kKECymkYt86vOM8ZoeKw8pImNk7ApOago1L341l741BhD85uGpo7g1PkcvyzBMmSrKU5ofk0c0iShFzq9KU5mfi1pk6PXM/xNFNzYvhynrqxwceoyQ1yaMJReENYzMi4WnCxOHSvg2bxYIt8o2J2J5RKlIiM0XRqmhdDEYMsXEwVHw0neNINBqSwjBASw4tQZaKY4ATblfVxK0ev1vUclmjpYCOUm14/SXLEbHh1vTmLBjHZbMr/aaHOpDY8Y33HBlCbkPGBHVx/W1LShpr4VqKxEw85urt6WuvEYGqhAxd4+bK5vBQDUdfQi1x2ZHbBnoALb61sxqacjHLc0D2pKacKGO04dV9aaU5ddmjBroSqoRgn1wfsn0epFjjlkCifUZQQdLQSX1zKsGJcmrPg3TU4dp3zJlQSgFD1sSQ6UhhYvFE44IcVyp540TZiJ2TRonLuWNmnCLM2vKe+ePWpx0Wuh8IdJE0aOUcapE1NQ6XAiDa4fyb/iYpBpCF7hpsRA8PT90o7KllMX44xUV12B/Sc1Yu3WTlw85URgyomFY9/+C1/vXZcW/v5+M3DCVwufv/+oYgTjgBO+ioN3vIrfihr2tEKapMGps5k3jDaQxU1x1mnCLK9raW6VjFF8/2SmWsepKyvcVc8KOqmgSE6d/FZ5RJ1CdxYCl5izUcGpSy+kiWJSgmwxEiYs2x03t057nAlWS5tlGxKBNT8VYZUmzIRLZJmnVm8YCQVG9tnSMTEGC6Ro/jMWXA2uH8mpK/71oadpDCrocOrYBdRqA2W2cfr7d81EU20l6vIDqBvoRd1gHxqqK7h/dYN9qBvoRX2lVygz0BspE/yrzxWux8q2udjVJ8wVuiFskpwjWc1yM2LBqZNxIzNJE5aUUye5nuHjPsibWNn5Mzxm17tDQjhNXVaIi1MH8Du6sJomp06m3WPaNILC/KoMaWLTB6EZIzl1gjDnGZnRFH2wWgTfNzbf2XDq5CFNbDWNdD0jT09TiFpd0+qs5kZTmw0gmqbI1MRsouGhnlXu/dMgwYcLpr7gyXLqrJ61wkCFY9GN08eXzcbHl83G6+edj+4nn4RXW4sDVzzHVXv53e/G0PYdmHnTTXjjggsAAAe+tBJeRUWk+47f/AanPLAXG5sm4/ntfZjKjInPHZtg+bdNgWe5GbTh1PHm1wzThNn2IZrKZW3LUoEF8+eQC2lSTrirnhU0tBByT9Y4j8DixA+J5gew1KIJE55Eu8SNM4mGBhJBg9qFEmnCrBc8cRLU0aJYhjTh0iQFsHE4sQ1pknqasIRawODZgq+3SQg5PYI2ejg5dZRWVrZgazhKGAmevp1TErXhoTO6EJqakIqhF9LkwN2vAwCe395TrM88/ymnCbPlpA47p04a0iThe0idd0JOHRmLT3z/JM+R9JhDZnBXPSPo8W0kptQwFZK8Xsk0KvGYZds0QIR8LBM2me/ppwkjBLWIZ5elwCLRtJUmM43J0JZLJtGs+hZamBET0sR2US1VKvxl04RpxanjhQruOdWKM6i/qNOx0BjtukHwZD1nHOa9S+ohHXm21OcfbpyINsWQFlLkcjhwV0GoW7Gthx9HwrBL0rq2nFSb/mycMpiQJoltk5yGXJwjFb/rgtrchucS9XD1hGNp83cd9OCEuqwQEp01tBCymHMm5teEnDqRRK1OE5Zk1+kpPvNflZw62QJuJBRJJiNLTp3NBM+ngkt7wRaLWpqo9AaiPQ6yum6cukDRIwt+S5mNIu0YaHipa805M2gs2CZCgYSLZfasaW6cohXVZUJtjMbC7QELdr8BAHhhaw+G8j4i2pzYscTAmtNpoOlmYRHYlwt7k4+32Gi1SdzbSH5s88aL9aPnGMkoItkcuTRh5YUT6rKCjlZLwl2LTxMWrZOYUycuYsx3X9qPvdkNkJiGqElJ4CRZm/9kk6KJ+dXafCPRrCZMExY7eVLmw6SwjcwfVjHjG4UhTcQ0RWw9Y05dzPUjnjFuw2MUp05f8LSPU6chjELyTJDmV0HTRt2rXA4z925B7WAf9g3ksW5bV6lfhhOZaPG35NTaaq+tBKbh4NRR778Rb1PWNrG5FYV6yXvkQpqUF+6qZ4RSHDn1iybl1MXt0CUpvFJPE8a2YZDtwqgP7lj8oiKbXBPnfjThy1hz6gITe9KQJgZCJWk+TIb00oRpmhglWmMydZyyW31Bl9fqCmVlIU2o9qgFU1GWi1NnIoAQ7wbtjERoo4JFXSe/p5dDBXzM370RAPDcG7tDz0zOGpESp85qcwWYbXwTcep8O628dBzU/GnwjEmgFdKE4NRJjzlkBnfVs4JBYFIjwcnjy0U+W+yCI2nC2DZMTMOafUTqUyaqyKRKmHHJAbDdCYuYTjOc9st8UWAXNauQJibm36SCFzkOA42htH6gaUaJP0qa9AhtgMn9MwoJQ5Tlxh/fnlG4Cc78GjZgAI1xU8coTpWOia34rIW8uo0dzMLPmM/T4tQZXBwp/cKkPxtLr8+kCUvKgyDuX+KQJtTmKHgki5pW2XX0Q89Yu+4dksEJdVlBZ4cWvBRcIGFacJLGqWM+J1poZZM7qxEUy9v0UfjCH6I0BSL/zTZNmFQYsNCisPV1QJhfrc3HMePlJt60d8+WRPVSFUY7HTqMUCY9XqiQcXqMQ5oYOZrIn1XtWHIGmp7Su23pKUppaAnzHU1/KM5Rg/EmtmCsgQfsc290RM13srGZwLN7/0m+IdmduRZMFm8wqRZLK+yTbR/hexS9nmG/svcvIvA78aIccHHqskLIiYnf2XKmuTgtTjBJcqnFEk4chDnS9/2SCJYkjyHFhdFYVMI6tuZXilNnsuBqli9VZLQvAYY7TVjQr+8j7e2zNbdQrKObQilME0aYf3TGYZJeyiOeMQmnTi+kic49C7S6PuMhbWlijEkTJhujnP4QnK+Oo0Th2Pyis8TL2zpxzdwPID+5G/WP70X3O88DADT+9iVpnLs45HIeTq/JY1rQXVL6hUk9a07dMIQ0Udw/65AmVEaKXPz750KalBdOqMsKGnGmSnwridZN+YJKND9J0++ILzU7Zon51S5NmJ35NZIezNb7TULwF71gSdimCZNw6vzhThMWlBkaSn+i5YRqe41tIU6dhvdouEBKQiqgqD1OOaQJGT6CCRDsa3iokgumql9L71faxEicP2ViDE1sGpvU4vM8vq8L81prsX5XL/7Wsh/QAmDLADDtkEK51dvpEyGwelwOPxLHrQPynlL1bEybwTOi+YzrNykfi6f43bRxylISCPWyzZELaVJWOKEuI2jxpiR8q/g0YYTmx3anJnDMuMWai6+WQHikOD0G5ldr8x9Xj/9NW/MVfjQRJmX3eJjThAX9Dg0NA6fO0gwt1mHj1JmkCZMIt2mHNCHj1IXvHzRJ8PpCAW+2swl7o2Gikxwr0R8oTY2GowQz1h+feSAe3z6I7f/1Iwzu2IHx53wUu2/5FQBg8te+Bq/KbCkaGsrj6j+swqtdeXRUj0NLf5fZpsiWCypaCnT64sLepBTShLp/SUOahNpI2aaaf/88yeZATCHmkC2cUJcVDNKEgePUxQhOEm/AxDkVRe8nBacuUT/EohpOWIT6P1zAU+DURfoz5dTZmE0zTBMGlLRYI49Tx5qm9NOE+bI0RUb3jxDUop3KP0MQvHwNMzqxYEb7ZagVCU30SmEUMqWRWpsY4TRqcOoAYHZrPfabNx7rv7UK/a+tx/RpH8Obrz0GADhw6Qx41dXUmUhxy5MbsXZrJ16aMBtHbV5ppv0y0dRy1QyeMbH9zNOE2c7/8UJ9SVMnGYfsmENmcFc9K2hMymQKKdWMFSxysgTxti+V6P0kcOpCDFeaMEKbQYWvMPNik+x0Q6HAQIsijCG2niykiY3G0zSfq4nAY4DkIU1YLYbwmwxBfzLzH+W1F2mHvX4x46ZMzJxQp+GiGmoTdcyvrBbe3P3VI8atlyZMpikPNHX6nDq2v5JQnjykyZI5rQCAF9vmcX1owXBTFKln0Ve6IU1Kc1WUU0cIZVptE9pkx6kb8XBXPSPoxKkLXwKjkCYS82uMx2wsBPNnXEiTYUsTpqGps91xy7QvRmnC2Ij0FpwcPq6gxrMRacbC/GrWhR5sheqwErvgaXgBE9oAk5A0JtePLyvfgPjQjCUnmPpJcHHqLAR/8hyJ9yZMEyYT6nhNnU74Ge6zLHespUVh6dyiUDdhbuEHk82Vrfe6wTPGVCr8sc0MQjRJ8t6s6TfE/Bs0SYQ0gQtpUlY4oS4rhGnCqAm/uEAYxIKTpvAK4n3ZjBOsiUFtfuU0dlaTBzGpZsCpi+S3ZdoyDolhs9PnzK8p86VkxUO+YNqvvKVQHVYPBBfdjAzFd2RQHVJB6xxNrh9pfi0JXjrKNBO+ExeMPNSKx1ZjB1f6THHqxHOiNJ4G2hjpxk3gXcW1QWHJ7IJQt6F5KrqqamF0cZh33ibll1lIE8NnXKdN4jlKK02YTJFQyuiifv9KnDonXpQD7qpnBR0thMTpIZZTJ9PUJeVtUObXoO3EWSvUGh7SCzX0HpQs4EkXPCPzq50ww03wAYY7TVihUDAA/T60xmEnVJeqlJ5fLe/RMMyH2lHClBMZe/0oEzO7qdK5jzIuaGy/JQ2PPadOvnEqHBKOkQKDWlMa7V/yjAZCeQppwiY11WLWuAr4Xg6rWufYbYpM564RliaMyvph5Y3O1Je+R7n49096zCEzuKueFTTi1JEhTVQSC8vXCLtKGtIkJ//LjkeSpskEpFCksQsdnjRhhIYiMpCc/LNuPRmnbrjShLFlUp5oE3PqwufXME2YjFMnCPwUjDiRVJy60Jye14sllzMQrhPGqeM4dRbaODKkiY6Ho2TjFJp0A01fQjPkEW1VAAomWCuB17R/G9MmS7nQ4Y0mHUf4m6X5lbo2nnD/ZI5qKd1bBzs479eM4Oss3DJTagynTp4vNmFIEx1OXdLcjRTfhyRqixMO0Q7Zf/RLuOAYhzTR77a0m5VoY224Pbr1ku7eNcaRKHtJnuHUafC0ZCE1rFJwaZT3JM9K6WsgpEOLL2U2xuJfW2GA4ptS+T3DIVLmV4n3saIdrlzK2pwjJtXgt6/14pnJ8/H4jkHUrduhVW93fz32tu0Hr7ICuyV1qitzWDyjBVUVCrO1kVaQsab49Hyu3SSxATWKhShvPbbtUpowduMgPBtpzzUOWnBCXVawThNmYX5NTMaVLDyexxF9fa64zWJOaLqC7mU7TUHjxBOeLbUYwiSoJZzYhjRhF+oASdOE6fCzwg9pC3Vm44jWZ5/fIPerup0SGTthmjCTcRNaPT5NmIGm0USbyKWXSukZoYQCjYwuOknbKU6dTkgUHRwxqQYAsKG5HZ96ZC/wyBOaNacBR19U+PhTeZ3PHDMXV568gPstaZqw0PyalAZBOjMk1MpT82CYJkyyARO0eI5TVx44oS4raGghSvwig5hzEu1e6mnCgs9DQyWBk9XUpZwmTGdRkZqPki54Bpys4QhpYp0mzEBTl35IE0tNaVhfsuBp8LR8qfnHYDEbDk6dlqOHueDp+5ox8CLV1ecohhiRjVEefFbUtOmZX0Wtv6/jPauB6Y3VOG39X/F82/6omjEdubp6rXqDO3diaOdOIJdDzX77ccd6B4fw+s5u/HnllohQZ0VjCMpyIU0Svoc6nDrba6uTJsxx6kYsnFCXGTQWbhmnLk4YZENChF2llSZMWDCHhkrCCMupK0easFBIsTT/STU8BqYx25Am4cTHZuYw56BYhzQZqRkldE2MAlGfE448oQzZrZ2pNupUUBRSuDRnGiZJk3599v1OyUSvwckivc91PBxlArfIyUqBW3bRi78HAMz6xf9D/RFHaFXb/qMfYcdv/gtefT0O/NEz3LHO3gEc+s/34rWd3di4qxszWhlBMQGnDoCdF7O0TUnbOsd0mtbh6wVCuWzjoBPD0GHY4ETpjKCldg/NrwaekTJzXsL8guGumhVcxLaThjRJi1Nna/6TRdQPtX8GQhJbz6RfWUgTo4XC8Lxl3sJpwNZRpVQJAB+njtwkiCFNOGcAiUk+pl8t0zX3rCo2IJqx5IzCTZiadiOdURsnDRMryakzyygharh06mvB8v2nNJWNtVU4bEYLAOBhkW9nkyaM6aOkoUx23lTWneQhTShNrfD+STjNLk1YeeGEuqxgkPs1KMtp3xQvqDROXT4hp0E2KQj96IxNqw/ITEMEb0UQ+GzNf9SCoxenTqKFMOnXNxDcpf2bCZUlgn7Krzwl8OhUl8TwotoJ740sabiJidnIVKs2v8p4b7RQqq8xlbdtt3GJXBMiFiQdA81AGyPTcIacvGjwWitYBxGm7//R+7cBAB5+hRfqEqUJA0qBeVMSZk3N51qg5sGc8P5J1whnfi0n3FXPCiFvSv2ilV5QA22YxFEi9ZAmzOdQmEsY0oQUiijzqyjw2WrMpJw6fdOKLacu3NkmNZczYzXj1KW7e04zTZiWF7DAqbNNEyZ6eGuNUTY2jlOnM35iw6LoV9u0K1bn3g3FMcrEJrufgqZNK6QJK9wFGThSMr9KMxroVST7f3dRqHtk/Q4M5SXzsKX5Na3z1jKfW5tqhD4kbcvThKV7bx3s4IS6rKAVw0rQuukITsxLFS6KYZqwZC+1dMJMKaQJyQkjd9Gi+ZUZo8k42C5FDpFWO5aLiZRTZ5HX03RxyYBTZyfcs+ZXAw9xWUiT8Jpo9GvLqYs8G4HgxXIjKU2jRb+Wcep0xk06I1FpwjS0MdLQGmlrc2w3VzFC/eLpLWisqURH9wBWvrUn2oetGTwf5aJZYRhDmug4qvnSNGE57pgLaVIeOKEuI2hpIUROnYbgJI0hF6YJs3uppLt4QSOYOE2YRrgF2rQgG6OFGZTtx4STZRu8VMqpSxCuQnfiDk8x5VfeWmNZRGhO1c3IUDwRWZqiwGykMw5bTp3wThmHNDHplzO/psypIzR1FF+L4jRGyxIaf536OuAcZSw2RYr+KytyeNe8CQB4Xp1dSBNGUxc+t8nOm7xHaaUJo0zzLqTJiIXzfs0KWjGsBMGJPRZnfgUKk39FRfI0YbJdvKhhGsY0YaQWRfDM5U1MCYWi8HN8O+SkStVLOaSJrnbMiguk1a6dUF2qX/zAxKmjrj8ZUkPmPKOC4fVDLld4r1TCkbb51WDjwG6kgmfExilHMiba/ExogYTrT56HhPcVBq/Np0Omt41TqSP4vHv/Nty7aiv+52+v4v9WbQUA9E96P/LvORIV3nhU/egRvb7yefS+53MAgMptk1B15IW4wutCu/5oleMfnpAmlFAvvn+yNcJx6soJJ9RlhbyEAyQgkiZMJxYc++IEwmBqnLqoFiT1NGHEwkEdKwkp0QVDbwAywdXAbGG7G5aYX2ER0sSY25OB+dVKMcwIRVrPLaUNMNGe2ly/fD76jHGCl4aGwot8IMoypmnffKNG8s0oTVWoxZM2Wvgr835UlZVpOtPmlsHw/dfgmL5v/iRUVaxCR/cAOro7Cj9WTwBaCxo8bOzQ7691ZuHvAIBJB+BX2IJl+rWjIDl1UB/TgU6asEHJporSojtkBifUZQaNNGGE+VU5YTHt+b7PMHxgt8gCUk5N+EkMaWL74pLaOEIAEesl5NRwi4JFmjDjsw+FgNJPoTBjYz7WPWdTzZQuWI1rAo0tG9JEJyODLCRGxMOSgPH1Uz2vjOClQ7EwCjfB8FhLWWYsBBdZf2SaMMLEaKCNoTh1Mk6kFaw19UEVdZ0ZrfW4+3Pvxhs7u8Pftn3/++hbuxYNRx6J1r//e62u/MFBvPm5gqZu+7EfxH93T8YjfmthvrZ8H+k0YcnMr9R7FAkejej86Uti2DlkByfUZQQtLUSotRA0bkQ9bk4QtGi2nAZ5tgbGzIQUtIFkmhthHCyECYviO9HdS+qbmC0sycgcByuATiiMaENG/XuESS0RkqYJY72BNUyM4TWShdQQtbhkt4bXz/MKcrjQ9vCmCYtem0zShJEZBQRNm8Z8xr9jhKbHBpL3V6uapuBzwORGHDC5Mfz+xsBW7NuyCi0VB2HqwslaffmDg1izZRUAoKFyCW4cbMGOyhq8tGkvDp7WrD1m4QSK45cJ5Qm18tR7FFwvWZxB8Zjj1JUF7qpnBY1I4uHkF/LVNJwR2JcqFLgScuoIvlkozFmYgzhQcbJC04h6wZFrARIKRUS/yjGanj/BqUvTey9aXv/cTJA8TRijjdLx8Aw5XRJB2OSe2F4/8RnjnBl0HD0MBM8c86xYxKnjNwmecIzYwJDBZ3lNqVZIE4k2zU+48Sw1Z/n8UZpKukOLvkplq/0hHLbtZQDAfau3mvUtaZPyUE6cJozQ4krXGJFa4syvZYET6rKCDhmemcQHt29H/7p14SGtkCZhXlaLXb2kTX7BDARO3jRsbT4gOSHU4uzxfzlOjcHjLOs/+GhiGjP2fi20ne/tQ37fPgBsKAwDTaMlpy51kwjF2zKpz4Y0IQWFQFNUNN/JvB+1rOeG10+1UAaLHPM/PX7ElxEK+6ymzlKYUHIBKfMrFdJEw3wq23iVvCdT4l1RDlcUDEz10v5s+HsAMDSEpUWt3QNrtpn1zbWpoU21Dj6vo6mVhTQRnw0n1JUDzvyaEfS0EIWXoGfF83jr8i+ZBR8u9ML9td6peZEPpQk+LU4dpVXR4ttJNE8mQpFEU1NyvtBqIFLfpN/dv/gFdv/iF2g5+2y7NGHGnLDgb8oTrS2nUVZHi1NXFHQkZOww3MQwOLqE5tcIN43RNGqkArRLE8by9Uw2LsS90UkTRjhRyK5/tH/Je0xwIq2QkFNrrCmUed3HQEwT9s6tawAAL7y5B1v39mJyU63ZGNj+ZebzhCFNPC1NrTqkie9CmpQVo0ao23H99eh68CH0rlkDr6oK8596Ull2cPdubPjw6RjcuhUHPPkEKpqaMhypAlppwgrH9j3xBOD78KqrkWtowLj3vhdeVZW0ijROnU6eWQLSCUNQrfs2JkO+k8IfqeBGmA8iIU3YScVkUlefo86EbRvgs37JEuz6xS/h9/YCAPb+6U+oGDdOu19mAIU/mkJaw5FHYqhjD2oOOMBovPHjsLz+kvqlMBnxQtHgzp0AgIrGEt/JyMRsqnFRtG0cS86IUxc17ZppiKLCVOSYbOGmBIZi+cFdwfUfp+y+qr0dFRMmoHbBgmi/aYU0sXz+EockMhYGc8X7OITWvk4szO3DqnwDfvPMmzjxID1uHouO/krsHDcJVbWtwLbO8PeW+mo7baI4ViiEsuKxoeL7lxtXuv/B5+BY6vxdBy2MGqHO7x9A40knou7QQ9Hx29+SZTd//RuomX8ABrcm4CykDQ2ic/AS9W/YAACY8JkLMfGSS+h2pZy6YXBiEJw4kppfSaI2oanzxAmH4+sY9C89R8G0S8FyURj3nvdg/lNPIt/Tg5eXvgv5PXvgDwwUuzXXNOrWmfLVr2LyP/2TnYcqNQ5bTpOsfrD71wiT0b9+PQCgeu7caP864wgttWbm10hx1nysE0vOhO9k2nakOqtplx+Tnz9lxg6u/6sAgOrZc5T95+rrsd8D93MbUk/Q5iTWHMvoE3oV7fq3pV0I53105V6s6m/At/+8Ft/+81qztgAAzcDx/1j4+N2/hr/mPOCndfWYCoNnWzFWyjTf92rx/s8p3f/qOXOw7+GHw2OOU1cejBqhbuLnLgMAdNx+B1lu9y23IL93L9ou+Sz2/fVvWQxNDzpE5+DF7+sDANSwC1ZMHYBNE5ZWuBH2t7CXVPpIzKmT1LdKE8YtfCbaN4/53wxeVRUqqqpQNXUqBjZtgt9dDJlgkwLKxuMvTbCcJhvNAMsJ1THJBZzEIh+RXVQo7ZMI85AwCi0ux2mN9/orCeP6JuJCuBQLxyTKNEmaX+M1NfmuLgCCUC0bQk2NvN9hCGkynMG7I/3ZcPGGhsLz/lBNBx5o2R87uvrM2inC7+tDvqcHyFWgoqmgre4dGELvQB53D7bi0+xYDaHj/ZzvLGgHq+fMDg8Fn4NjjlNXHowaoU4HfevWYft//zfm3Hor+je+We7hcAgnZUoMEF4ibsFSgZ2UhNyvSWMgsZN6+DktD1tqUaUmTqGeLCSJDqiQJlqTkaX5lUX13LkY2LQp2qYOkqYCSgtpcuo04luJx2rmlt6RMDD1MHHqZOW550cn9ZVBuAlpuBQbD0/ZmMj3L35RD8Au6loQOXmJQ5rYPX/W5ldLLl7AyQzOe3LFEO67/BijNljs/tWvsOXqa1C93zzMu+suAMBDL2/H+Tc+iQcGWvAJeMmpMQSnLgCreBCVEI5TVx6Mmaue7+/HW1/6MiZ/5SuoatdPwNLX14e9e/eG/zo7O+Mr2SDwYSC1ELwpq3rWrNhmPc8rTfSZhDQR0oRZ90HslCnTGBXSxCYwq4xTp7FwJg3wCUSF9kw0DSkjaZow9p5phUIQ+uCuYai91RiH6fULywnlOU1dfNgiE96mzPxqZaKX1CtpDGXdqjWe1KKuN6jCn1KasIRLEGdNMBF4Lc2oCc22JW1u0vc2+vweOW8CWuqrsNuvxMq2uXZmBG5savNrANH8SpV1yAZl1dRt+853sPN/fkqWmfvHu7Umju3f+S5q5s1F86mnGo1h+fLluOaaa4zqWEEjwCw7wVVNnYpcXZ1e257HT/yJOXWSSZ0NhAok59Rp8OZIvp1scjXa9Uvqh00bLLgJJi5Wy2TcVgr9pwJrTlOxCnvPZGFKiP68qipUTZtWOhY6M2gI5abXT6XF5TiB8Y4eRmnCgo2UZZw67lqJ5xluqiTtaWSbAACvrg6Vk81I/mRCeAuw18MspEkCMyr717TekIXDi7S96AamqiKHExdOwa1Pb8Tf2hfjaM9SQaHh/QwAFc3NqBg/PvxeOWkScvX1yAd0knJbESzx88dew48fehXbu/qwYGoTrjn1IBw6o0Va9pYn38Dtz76JtVsK13rR9GZ85cQDleWzQFmFutZPfALNp59OlqmePl2rrX1PPIG+l1/G3j8fXPihKHy8vOxItH3mMyEnT8SVV16Jyy+/PPz+1ltvYeHChVp9GkEnFhlzLI6rwqHoWVXKQDEcacIEoS4pp46aHMlsE8KxhJwadnI1S+Gkr9VTIbqzHX7zUeqwvf6S+r7Ogsccq549C15FRan/MKSJvsCkz6kL2lZw08BwAtMKaRJSHixDmui8Y6T3Ob2oV8+ZbX7PA0G13CFNKKGW7M/gGeO6K5pfdQR/nfYU9/YDh0zFrU9vxKPtB2PIf8KubUpTy75/c+bwzjieh+o5c9D70kuRsqMFf3h+E75112p86/SDcdiMFtz4yAacd8MTeODL70XbuJpI+cdf3YlTF7fjHaeOR01lBa5/aD0+fsMTuPeLx2BKs3momjRQVqGusrUVla2tqbQ1/QffR74YJgIAel9cic1f+xpm/eL/oXrmTGW9mpoa1DBk3r1796YyHhFakzI3Yc5RlxMRmmnEwMBJNXWSCTN1D1tCGyCbEwSNia33ZcSLlm1bp5k0OHVzBA6KFaeuzBNnUk6dTNNF3EePe0eEjY+J+dXw+nkKsxuvadQwrZnwNoMi1sGHCaGOen4JJxz2fGsIz1clwuC1KeUHtX7/7d7fRCFNgPRSaCme3yPnTUCTN4TdtU347eBMHLrGPAJER38jOicvQH1uIiYw9WeMr0cdM26Z4qF67txQqEt8jmXATx/egI8umYGzjpgBAPjXDy/CA2u24ddPb8Rn37tfpPz3P3oY9/3fzzwEf1q5BY+s24EzD9dTSKWNUeMoMbBpE4b27MHA5k3A0BB6V68GAFTPnIlcQ0NEcBva3QEAqJk3b9TEqeMmTNE0RyAMjOoHOWOTceroOHVimjDLSZnUBqiPeTKNSVFTaRWYlWtHoY2RVk+uKaucNNHeXGEbPDVleMQ3rfqs97bWgsdrCjgYmF+NQ5rkFIu5bPzUO2EQ0kQWp85M8I+OsTQMtcbJI6+jpTVB6DfkllmbE/j2Cl8stJhZhzRJi1OnCElTVZHDMTVd+ENvM35QOR+46WmLxqcDyz5V+MjUr8x5+HmuAYHBVeYkw/1WbmqIIfoH81j51h589r3zwt9yOQ9H7deGZ1/v0GqjZ2AIA0N5tNTL48pmgVEj1G3/wQ+x5847w+8bTj8DADDz5pvRsHRJmUZlgDBNGPWgEwsWBUGLFjplWPPdJBorVmvA/LWNhaQTi44MacL2a2J2E+pId/pGnDr9LqNNeIWd7cqV0bFo1DWtMyzgzK8WY2HvcV4/pAkg2fgMZ0gT1f2WjJ8U2IxCmhQFAd/Xo2+I1SnHn3DcasFNej8F86sxgvPW8RTWAVvf6PHTf1ak/dnWS8vrl9A0ntfYgTc2bkP/hMmonjnDuOmBrVsxuG0bKlpaUD2jUP+tjl7s6OrDPZXt+FixnIzrzv1WbisCg87OTs4KJ1roAGB3dz+G8n7EzDpxXA3Wb9+n1c+196zG5KZaHLVfW/JBW2LUCHXt1y5H+7XLtcs3LF2CBWtWD+OIDKGjPaNMSxTCyb/4PWFIk5KliVmwhUT0wxrShPIwU2kRh4aszC/yNGE6mh6J+dYC1XPmWAl11oTttJGi+bUUkJbqT73xMUoTlhKnzpOOP2VOnT+MnDqKDE9o0QELz1em7eHg1Nl5jxuaXy3ShBX6Kc7RQ+l4/VKbktlVQ7j2kR+j6ZRTMO3Sc4zb3v6DH2DHbdeh+bRT0V6sf/cLm3HJ/z6LP1dMxdnwUAFfqnhgfyu3FYGFyJO/6qqrcPXVV6fax38/uA5/eH4zfnXhu1BbVRFfYZgwaoS60Y5wUibj1BWO5errUTlponbbJfOrkCZsWMyvQR8ZpAmTagqiO2xlXk4KxDnqaJxsOTkiWG3HcKYJGzZw3scW14JzlCgmCSfaYRcKpaOJgRZMV7uo5FKxY9Uxv9o8Y7opyCINEM8oldGFPMZcf42QS8p+NfiTOkgap9Jc0y2xFGhV4887LfOrXNGa0IoQPuOlBo5bMAlNtZXY1luLF9rm4bCO10ItHovqWbMK/ft++a0IDFatWoVpjKe8qKUDgPH11ajIeZGA0Nu7+jBR4iTB4id/XY/rHlyPX356KRZMLS/da+SI0mMdBmnCqufONZvssnBiCPtIJ8AxyfchNAWhNkZqNjUZS1rm12QTV40szZUOiOuXJfj7bz4WaZowDQ/xioltfN5Xtp6WptVwcVa1zWrqtOLsRevF9pkwTZh83bcVCgo/VrZPRa6+XnssYr9a10qvQfln3XqW3ru29XybHL4yUJaCpHxbybWprarAKYsL8V/vn3kEqqdPl+Yjz9XWluLEltuKwKCxsRFNTU3hP5lQV12Zw8HTmvHouh3hb/m8j0fX7cQ7ZrUo277+ofX44f3rcPMnl+CQ6epyWcFp6rKCQZowIz4dU6/roYdQOXEielasKP5uOki+PV5wKvzpee45+P196H/tNa6scRekaYhYnGUaE4o7pIJM42eSTzUlTRmf5spC0zASJs6io4q1J2NxZx+kntLxEK+R0RMySRPmSX8HSqmzSE0jZdpU9OkPDoapAxNro4VjVJw6KqSJlecr03ZqscxY86uFZ7B5mjD9Z0xWL9/TU+w+qflVQ5tqTY2Rn+OZh0/HL594Aw+3H4ItrftQ29Ejrb57v4PQvWsferwa+IoyMrQ315bd8vDpo+fgS7c9j0XTW3DojGbc8PBr6O4fxEcOL2glL791BSY31+KKkw4EAFz34Hp8796X8f2PHorp4+uwrbMQgaOhuhINNeURr5xQlxF8DaKzV10NwMzzFUC4Y9r6b8ulv5vCqyo+FpWlx8OrLLS147//my9bafcIBfXYOGM6x1BZUSzDxCerqCiYXw3GUuqDqVP8zLatrl8sIxujAVhzhRknqHgdKkaAUFdRUdi02C4iFRXA4CD6Xnml8J1ME1bUZks2Pl5wTbQ4dcX7pjlmnTRhfS+/HAyEaEiiBVd3CqAgLGoJvMq+iI2ToWk2OGa88RTq961Zw/dlC85RwmJTZyhEkM4nVL3ivegrRm1IrKGkzMcm3GAJVKbpw2a0YCa68UZlPc4ddwxw7QPyBsafAJx4AjAEdRkJ1n7rJNRozL3DiVMWt2PXvn58796Xsb2zDwvam3DzJ5dgYmNBs/dWRw9373/x+OvoH8rj4l8+y7Xz+eP2xxfff0CmYw/ghLqMUH/ooahobELlhAnKMuM/dg6QH0LzGWcatT3xC5/H3rvu5n7zKisw4YILbIaKhqOPRtMHPoDmM84If5vwqU9h189/XuKEAIDnoeUjH7Hqo/agg9D0oQ+hYdm7pP2PO/44jD/rrMix5g98AH2rVqPplFLmkAmfuRD9r7/OZxeI6//gg9H4/vej4eijw99a/u7vkN+3D+OOic/JWLtoEcYdeyzGvec92n3KkKutxYTPXIiBjW+icupU7Xp1hywqXKdj35eo/zTQeu65GNiyxTi7QIDxHzsHnf93L4BC7MqGZUcqyza+/3h0P/00mk87LXKs+dRTMLhrFxreFX2mRNQtPgR1hx2GppNP1hpj85lnouuhh1ArCUzecvbZ6LzvvsL4J0wgvfEb3/9+dD/zDBrfF3/fqmfORMORy9C7qhi+adYs1C44UGu8hfozUL/sXag9YH7kWN2hh6J24UI0n/KhyLFxRx2FPfvvj8YT3h8d/7HHofvJp9D0wQ9qj4Orf9xx6Lr/AeR7e+Hlcmi2bCdArroaTR/4APJ9fcgZhK6qP/RQ1Oy/P5o+oHf/A4x737HofuppNBx1lFG9pg99CB2/+hV8ABWNjcb1RdQddhiq581D00knRY41HHUkOu64HY2Wc0PDkUei4/Y7Is+o53m4aEEj/vXFbgzW1KqFRj8Pf2CwsHEeCZYEQ5x/5Gycf+Rs6bFbP7OM+/7IPx2bwYjM4PklBr8DgDfffBMzZszAxo0bMV0zm4WDg4ODg4PDyMLbcT0ffWK0g4ODg4ODg4NDBE6oc3BwcHBwcHAYA3BCnYODg4ODg4PDGIAT6hwcHBwcHBwcxgCcUOfg4ODg4ODgMAbghDoHBwcHBwcHhzEAJ9Q5ODg4ODg4OIwBOKHOwcHBwcHBwWEMwAl1Dg4ODg4ODg5jAE6oc3BwcHBwcHAYA3BCnYODg4ODg4PDGIAT6hwcHBwcHBwcxgCcUOfg4ODg4ODgMAbghDoHBwcHBwcHhzEAJ9Q5ODg4ODg4OIwBVJZ7ACMN+XweALB58+Yyj8TBwcHBwcHBFsE6Hqzrbwc4oU7A1q1bAQBLliwp80gcHBwcHBwckmLr1q2YOXNmuYeRCTzf9/1yD2IkYXBwEM899xwmT56MXC4963RnZycWLlyIVatWobGxMbV2RxLeDucIvD3O053j2IA7x7EBd452yOfz2Lp1Kw477DBUVr49dFhOqMsIe/fuRXNzM/bs2YOmpqZyD2dY8HY4R+DtcZ7uHMcG3DmODbhzdNCFc5RwcHBwcHBwcBgDcEKdg4ODg4ODg8MYgBPqMkJNTQ2uuuoq1NTUlHsow4a3wzkCb4/zdOc4NuDOcWzAnaODLhynzsHBwcHBwcFhDMBp6hwcHBwcHBwcxgCcUOfg4ODg4ODgMAbghDoHBwcHBwcHhzEAJ9Q5ODg4ODg4OIwBOKEuI/zoRz/C7NmzUVtbi6VLl+LJJ58s95CssXz5crzzne9EY2MjJk2ahA9/+MNYu3YtV+a9730vPM/j/l100UVlGrE5rr766sj4DzzwwPB4b28vLrnkEkyYMAHjxo3DmWeeGaaYGy2YPXt25Bw9z8Mll1wCYHTew7/+9a845ZRT0N7eDs/zcOedd3LHfd/HN7/5TUydOhV1dXU4/vjj8corr3Bldu3ahXPPPRdNTU1oaWnBpz71KXR1dWV4FjSocxwYGMAVV1yBRYsWoaGhAe3t7TjvvPOwadMmrg3Zvb/22mszPhM14u7jBRdcEBn/SSedxJUZ6fcRiD9P2fvpeR6+/e1vh2VG8r3UWSt05tI33ngDH/zgB1FfX49JkybhK1/5CgYHB7M8lVEDJ9RlgFtvvRWXX345rrrqKjz77LNYvHgxTjzxRGzbtq3cQ7PCQw89hEsuuQSPP/447r33XgwMDOCEE07Avn37uHL/8A//gM2bN4f//uM//qNMI7bDQQcdxI3/4YcfDo998YtfxB/+8AfcdttteOihh7Bp0yacccYZZRytOZ566inu/O69914AwEc+8pGwzGi7h/v27cPixYvxox/9SHr8P/7jP/CDH/wA119/PZ544gk0NDTgxBNPRG9vb1jm3HPPxUsvvYR7770Xd911F/7617/iwgsvzOoUYkGdY3d3N5599ll84xvfwLPPPovbb78da9euxamnnhop+8///M/cvb3sssuyGL4W4u4jAJx00knc+G+55Rbu+Ei/j0D8ebLnt3nzZtx4443wPA9nnnkmV26k3kudtSJuLh0aGsIHP/hB9Pf349FHH8XNN9+Mm266Cd/85jfLcUojH77DsGPJkiX+JZdcEn4fGhry29vb/eXLl5dxVOlh27ZtPgD/oYceCn875phj/M9//vPlG1RCXHXVVf7ixYulxzo6Ovyqqir/tttuC39bvXq1D8B/7LHHMhph+vj85z/vz5s3z8/n877vj/57CMC/4447wu/5fN6fMmWK/+1vfzv8raOjw6+pqfFvueUW3/d9f9WqVT4A/6mnngrL3HPPPb7nef5bb72V2dh1IZ6jDE8++aQPwH/99dfD32bNmuV/73vfG97BpQTZOZ5//vn+aaedpqwz2u6j7+vdy9NOO80/9thjud9G070U1wqdufSPf/yjn8vl/C1btoRlrrvuOr+pqcnv6+vL9gRGAZymbpjR39+PZ555Bscff3z4Wy6Xw/HHH4/HHnusjCNLD3v27AEAtLa2cr//8pe/RFtbGw4++GBceeWV6O7uLsfwrPHKK6+gvb0dc+fOxbnnnos33ngDAPDMM89gYGCAu6cHHnggZs6cOWrvaX9/P37xi1/gk5/8JDzPC38f7feQxYYNG7BlyxbuvjU3N2Pp0qXhfXvsscfQ0tKCI444Iixz/PHHI5fL4Yknnsh8zGlgz5498DwPLS0t3O/XXnstJkyYgMMOOwzf/va3R50568EHH8SkSZMwf/58XHzxxdi5c2d4bCzex61bt+Luu+/Gpz71qcix0XIvxbVCZy597LHHsGjRIkyePDksc+KJJ2Lv3r146aWXMhz96EBluQcw1rFjxw4MDQ1xDyQATJ48GWvWrCnTqNJDPp/HF77wBRx11FE4+OCDw98/9rGPYdasWWhvb8cLL7yAK664AmvXrsXtt99extHqY+nSpbjpppswf/58bN68Gddccw3e/e53Y+XKldiyZQuqq6sji+TkyZOxZcuW8gw4Ie688050dHTgggsuCH8b7fdQRHBvZO9icGzLli2YNGkSd7yyshKtra2j8t729vbiiiuuwDnnnMMlSf/c5z6Hd7zjHWhtbcWjjz6KK6+8Eps3b8Z3v/vdMo5WHyeddBLOOOMMzJkzB+vXr8dXv/pVnHzyyXjsscdQUVEx5u4jANx8881obGyM0DxGy72UrRU6c+mWLVuk72xwzIGHE+ocEuGSSy7BypUrOb4ZAI67smjRIkydOhXHHXcc1q9fj3nz5mU9TGOcfPLJ4edDDjkES5cuxaxZs/DrX/8adXV1ZRzZ8OCGG27AySefjPb29vC30X4P3+4YGBjAWWedBd/3cd1113HHLr/88vDzIYccgurqanzmM5/B8uXLR0Wapo9+9KPh50WLFuGQQw7BvHnz8OCDD+K4444r48iGDzfeeCPOPfdc1NbWcr+PlnupWisc0oUzvw4z2traUFFREfHm2bp1K6ZMmVKmUaWDSy+9FHfddRf+8pe/YPr06WTZpUuXAgDWrVuXxdBSR0tLCw444ACsW7cOU6ZMQX9/Pzo6Orgyo/Wevv7667jvvvvw6U9/miw32u9hcG+od3HKlCkRB6bBwUHs2rVrVN3bQKB7/fXXce+993JaOhmWLl2KwcFBvPbaa9kMMGXMnTsXbW1t4bM5Vu5jgL/97W9Yu3Zt7DsKjMx7qVordObSKVOmSN/Z4JgDDyfUDTOqq6tx+OGH4/777w9/y+fzuP/++7Fs2bIyjswevu/j0ksvxR133IEHHngAc+bMia2zYsUKAMDUqVOHeXTDg66uLqxfvx5Tp07F4YcfjqqqKu6erl27Fm+88caovKc/+9nPMGnSJHzwgx8ky432ezhnzhxMmTKFu2979+7FE088Ed63ZcuWoaOjA88880xY5oEHHkA+nw+F2pGOQKB75ZVXcN9992HChAmxdVasWIFcLhcxWY4WvPnmm9i5c2f4bI6F+8jihhtuwOGHH47FixfHlh1J9zJurdCZS5ctW4YXX3yRE9KDjcrChQuzOZHRhDI7arwt8Ktf/cqvqanxb7rpJn/VqlX+hRde6Le0tHDePKMJF198sd/c3Ow/+OCD/ubNm8N/3d3dvu/7/rp16/x//ud/9p9++ml/w4YN/u9+9zt/7ty5/nve854yj1wfX/rSl/wHH3zQ37Bhg//II4/4xx9/vN/W1uZv27bN933fv+iii/yZM2f6DzzwgP/000/7y5Yt85ctW1bmUZtjaGjInzlzpn/FFVdwv4/We9jZ2ek/99xz/nPPPecD8L/73e/6zz33XOj5ee211/otLS3+7373O/+FF17wTzvtNH/OnDl+T09P2MZJJ53kH3bYYf4TTzzhP/zww/7+++/vn3POOeU6pQioc+zv7/dPPfVUf/r06f6KFSu49zPwFHz00Uf9733ve/6KFSv89evX+7/4xS/8iRMn+uedd16Zz6wE6hw7Ozv9L3/5y/5jjz3mb9iwwb/vvvv8d7zjHf7+++/v9/b2hm2M9Pvo+/HPq+/7/p49e/z6+nr/uuuui9Qf6fcybq3w/fi5dHBw0D/44IP9E044wV+xYoX/pz/9yZ84caJ/5ZVXluOURjycUJcRfvjDH/ozZ870q6ur/SVLlviPP/54uYdkDQDSfz/72c983/f9N954w3/Pe97jt7a2+jU1Nf5+++3nf+UrX/H37NlT3oEb4Oyzz/anTp3qV1dX+9OmTfPPPvtsf926deHxnp4e/7Of/aw/fvx4v76+3j/99NP9zZs3l3HEdvjzn//sA/DXrl3L/T5a7+Ff/vIX6bN5/vnn+75fCGvyjW98w588ebJfU1PjH3fccZFz37lzp3/OOef448aN85uamvxPfOITfmdnZxnORg7qHDds2KB8P//yl7/4vu/7zzzzjL906VK/ubnZr62t9RcsWOD/27/9GycQlRvUOXZ3d/snnHCCP3HiRL+qqsqfNWuW/w//8A+RTfJIv4++H/+8+r7v//jHP/br6ur8jo6OSP2Rfi/j1grf15tLX3vtNf/kk0/26+rq/La2Nv9LX/qSPzAwkPHZjA54vu/7w6QEdHBwcHBwcHBwyAiOU+fg4ODg4ODgMAbghDoHBwcHBwcHhzEAJ9Q5ODg4ODg4OIwBOKHOwcHBwcHBwWEMwAl1Dg4ODg4ODg5jAE6oc3BwcHBwcHAYA3BCnYODg4ODg4PDGIAT6hwcHBw04Xke7rzzznIPw8HBwUEKJ9Q5ODiMClxwwQXwPC/y76STTir30BwcHBxGBCrLPQAHBwcHXZx00kn42c9+xv1WU1NTptE4ODg4jCw4TZ2Dg8OoQU1NDaZMmcL9Gz9+PICCafS6667DySefjLq6OsydOxe/+c1vuPovvvgijj32WNTV1WHChAm48MIL0dXVxZW58cYbcdBBB6GmpgZTp07FpZdeyh3fsWMHTj/9dNTX12P//ffH73//++E9aQcHBwdNOKHOwcFhzOAb3/gGzjzzTDz//PM499xz8dGPfhSrV68GAOzbtw8nnngixo8fj6eeegq33XYb7rvvPk5ou+6663DJJZfgwgsvxIsvvojf//732G+//bg+rrnmGpx11ll44YUX8IEPfADnnnsudu3alel5Ojg4OEjhOzg4OIwCnH/++X5FRYXf0NDA/fvXf/1X3/d9H4B/0UUXcXWWLl3qX3zxxb7v+/5PfvITf/z48X5XV1d4/O677/ZzuZy/ZcsW3/d9v7293f/a176mHAMA/+tf/3r4vaurywfg33PPPamdp4ODg4MtHKfOwcFh1OB973sfrrvuOu631tbW8POyZcu4Y8uWLcOKFSsAAKtXr8bixYvR0NAQHj/qqKOQz+exdu1aeJ6HTZs24bjjjiPHcMghh4SfGxoa0NTUhG3bttmekoODg0NqcEKdg4PDqEFDQ0PEHJoW6urqtMpVVVVx3z3PQz6fH44hOTg4OBjBceocHBzGDB5//PHI9wULFgAAFixYgOeffx779u0Ljz/yyCPI5XKYP38+GhsbMXv2bNx///2ZjtnBwcEhLThNnYODw6hBX18ftmzZwv1WWVmJtrY2AMBtt92GI444AkcffTR++ctf4sknn8QNN9wAADj33HNx1VVX4fzzz8fVV1+N7du347LLLsPHP/5xTJ48GQBw9dVX46KLLsKkSZNw8skno7OzE4888gguu+yybE/UwcHBwQJOqHNwcBg1+NOf/oSpU6dyv82fPx9r1qwBUPBM/dWvfoXPfvazmDp1Km655RYsXLgQAFBfX48///nP+PznP493vvOdqK+vx5lnnonvfve7YVvnn38+ent78b3vfQ9f/vKX0dbWhr/7u7/L7gQdHBwcEsDzfd8v9yAcHBwcksLzPNxxxx348Ic/XO6hODg4OJQFjlPn4ODg4ODg4DAG4IQ6BwcHBwcHB4cxAMepc3BwGBNwTBIHB4e3O5ymzsHBwcHBwcFhDMAJdQ4ODg4ODg4OYwBOqHNwcHBwcHBwGANwQp2Dg4ODg4ODwxiAE+ocHBwcHBwcHMYAnFDn4ODg4ODg4DAG4IQ6BwcHBwcHB4cxACfUOTg4ODg4ODiMATihzsHBwcHBwcFhDOD/A2fusSumQQEoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.00001,  # Further reduced learning rate\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Compile the more complex model with MSE loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "# Initialize the LossHistory callback\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# List of callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1),\n",
        "    loss_history\n",
        "]\n",
        "\n",
        "# Fit the model with the callbacks\n",
        "history = complex_model_v3.fit(x_y_combined, y, epochs=200, callbacks=callbacks)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W2lJyZ8xXu3h",
        "outputId": "d45bdb33-0ab6-481c-8528-68280557749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0981 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0981 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0981 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0981 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0981 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0981 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0980 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0980 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0980 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904899762754212e-06.\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314409827406053e-06.\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0980 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.782968926519971e-06.\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.874204867315711e-06.\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867845442931865e-06.\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138106171718391e-06.\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295575010183e-06.\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418659561182724e-06.\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876794218973373e-06.\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-06.\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.6677181747581927e-06.\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0979 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009463368187425e-06.\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0979 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508517440641298e-06.\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0979 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0979 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0979 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0978 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0978 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0978 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0978 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0978 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0978 - lr: 1.3509e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.00001,  # Further reduced learning rate\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Define a combined loss function\n",
        "def combined_loss(y_true, y_pred):\n",
        "    mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "    kl_loss = tf.keras.losses.KLDivergence()(y_true, y_pred)\n",
        "    return mse_loss + kl_loss\n",
        "\n",
        "# Compile the more complex model with combined loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=combined_loss)\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Example training step with learning rate scheduler\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=600, callbacks=[callback, loss_history])\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2P4_z5-cYcAI",
        "outputId": "ea78a08d-8af1-4638-c80e-9402c5f1de9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/600\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.7720 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7712 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7704 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7696 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7688 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7680 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7672 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7664 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/600\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7656 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7648 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7640 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7633 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7626 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7619 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7612 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7605 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7598 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7590 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7583 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7576 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7569 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7563 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7556 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7550 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7544 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7537 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7531 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7525 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7518 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7512 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7506 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7500 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7494 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7489 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7483 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7478 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7472 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7466 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7461 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7455 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7449 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7444 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7439 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7434 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7429 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7419 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7414 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7409 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7404 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904899762754212e-06.\n",
            "Epoch 51/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7399 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 52/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7394 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 53/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7390 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 54/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7385 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 55/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7381 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 56/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7376 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 57/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7372 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 58/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7367 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 59/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7363 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 60/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7358 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314409827406053e-06.\n",
            "Epoch 61/600\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7354 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 62/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7350 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 63/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7346 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 64/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7342 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 65/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7338 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 66/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7334 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 67/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7330 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 68/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7326 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 69/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7322 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 70/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7318 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.782968926519971e-06.\n",
            "Epoch 71/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7313 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 72/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7310 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 73/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7306 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 74/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7303 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 75/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7299 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 76/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7295 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 77/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7292 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 78/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7288 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 79/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7285 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 80/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7281 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 81/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7277 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 82/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7274 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 83/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7271 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 84/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7268 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 85/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7264 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 86/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7261 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 87/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7258 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 88/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7255 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 89/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7251 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 90/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7248 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.874204867315711e-06.\n",
            "Epoch 91/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7245 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 92/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7242 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 93/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7239 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 94/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7236 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 95/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7233 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 96/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7230 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 97/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7227 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 98/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7224 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 99/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7222 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 100/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7219 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867845442931865e-06.\n",
            "Epoch 101/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7216 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 102/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7213 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 103/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7211 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 104/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7208 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 105/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7205 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 106/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7203 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 107/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7200 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 108/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7197 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 109/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7195 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 110/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7192 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138106171718391e-06.\n",
            "Epoch 111/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7190 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 112/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7187 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 113/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7185 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 114/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7183 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 115/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7180 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 116/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7178 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 117/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7176 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 118/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7173 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 119/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7171 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 120/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7169 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295575010183e-06.\n",
            "Epoch 121/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7166 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 122/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7164 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 123/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7162 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 124/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7160 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 125/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7158 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 126/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7156 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 127/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7154 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 128/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7151 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 129/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7149 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 130/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7147 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418659561182724e-06.\n",
            "Epoch 131/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7145 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 132/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7143 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 133/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7141 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 134/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7139 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 135/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7138 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 136/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7136 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 137/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7134 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 138/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7132 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 139/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7130 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 140/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7128 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876794218973373e-06.\n",
            "Epoch 141/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7126 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 142/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7124 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 143/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7123 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 144/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7121 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 145/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7119 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 146/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7118 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 147/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7116 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 148/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7114 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 149/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7113 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 150/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7111 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 151/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7109 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 152/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7108 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 153/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7106 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 154/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7105 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 155/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7103 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 156/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7102 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 157/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7100 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 158/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7098 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 159/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7097 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 160/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7095 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-06.\n",
            "Epoch 161/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7094 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 162/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7092 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 163/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7091 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 164/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7090 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 165/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7088 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 166/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7087 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 167/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7086 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 168/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7084 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 169/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7083 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 170/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7081 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.6677181747581927e-06.\n",
            "Epoch 171/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7080 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 172/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7079 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 173/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7078 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 174/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7076 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 175/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7075 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 176/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7074 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 177/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7073 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 178/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7071 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 179/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7070 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 180/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7069 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009463368187425e-06.\n",
            "Epoch 181/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7068 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 182/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7067 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 183/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7066 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 184/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7064 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 185/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7063 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 186/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7062 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 187/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7061 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 188/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7060 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 189/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7059 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 190/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7058 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508517440641298e-06.\n",
            "Epoch 191/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7057 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 192/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7056 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 193/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7055 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 194/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7054 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 195/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7053 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 196/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7052 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 197/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7051 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 198/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7050 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 199/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7049 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 200/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7048 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1.2157666105849786e-06.\n",
            "Epoch 201/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7047 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 202/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7046 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 203/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7045 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 204/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7044 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 205/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7043 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 206/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7042 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 207/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7041 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 208/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7040 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 209/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7039 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 210/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7039 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1.0941899290628499e-06.\n",
            "Epoch 211/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7038 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 212/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7037 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 213/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7036 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 214/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7035 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 215/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7034 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 216/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7034 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 217/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7033 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 218/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7032 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 219/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7031 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 220/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7030 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 9.847708952293033e-07.\n",
            "Epoch 221/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7030 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 222/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7029 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 223/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7028 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 224/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7027 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 225/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7027 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 226/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7026 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 227/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7025 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 228/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7024 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 229/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7024 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 230/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7023 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 8.862937647791114e-07.\n",
            "Epoch 231/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7022 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 232/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7022 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 233/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7021 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 234/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7020 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 235/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7020 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 236/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7019 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 237/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7018 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 238/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7018 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 239/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7017 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 240/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7016 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 7.976643985330156e-07.\n",
            "Epoch 241/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7016 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 242/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7015 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 243/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7015 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 244/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7014 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 245/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7013 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 246/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7013 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 247/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7012 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 248/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7012 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 249/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7011 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 250/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7010 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 251/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7010 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 252/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7009 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 253/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.7009 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 254/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7008 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 255/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7008 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 256/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7007 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 257/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7007 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 258/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7006 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 259/600\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7006 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 7.178979331001756e-07.\n",
            "Epoch 260/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7005 - lr: 7.1790e-07\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 6.46108139790158e-07.\n",
            "Epoch 261/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7005 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 262/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7004 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 263/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7004 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 264/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7003 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 265/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7003 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 266/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7002 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 267/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7002 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 268/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7001 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 269/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.7001 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 6.461081625275256e-07.\n",
            "Epoch 270/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7000 - lr: 6.4611e-07\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 5.81497346274773e-07.\n",
            "Epoch 271/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7000 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 272/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6999 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 273/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6999 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 274/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6999 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 275/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6998 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 276/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6998 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 277/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6997 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 278/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6997 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 279/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6996 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 5.814973746964824e-07.\n",
            "Epoch 280/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6996 - lr: 5.8150e-07\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 281/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6996 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 282/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6995 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 283/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6995 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 284/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6994 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 285/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6994 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 286/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6994 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 287/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6993 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 288/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6993 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 289/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6992 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 5.233476372268342e-07.\n",
            "Epoch 290/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6992 - lr: 5.2335e-07\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 4.710128735041508e-07.\n",
            "Epoch 291/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6992 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 292/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6991 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 293/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6991 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 294/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6991 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 295/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6990 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 296/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6990 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 297/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6990 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 298/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6989 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 299/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6989 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 4.710128678198089e-07.\n",
            "Epoch 300/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6989 - lr: 4.7101e-07\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 4.23911581037828e-07.\n",
            "Epoch 301/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6988 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 302/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6988 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 303/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6988 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 304/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6987 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 305/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6987 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 306/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6987 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 307/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6986 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 308/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6986 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 309/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6986 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 4.239115867221699e-07.\n",
            "Epoch 310/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6985 - lr: 4.2391e-07\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 3.8152042804995293e-07.\n",
            "Epoch 311/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6985 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 312/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6985 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 313/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6985 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 314/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6984 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 315/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6984 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 316/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6984 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 317/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6983 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 318/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6983 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 319/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6983 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 3.8152043657646573e-07.\n",
            "Epoch 320/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6983 - lr: 3.8152e-07\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 3.433683929188192e-07.\n",
            "Epoch 321/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6982 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 322/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6982 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 323/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6982 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 324/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6982 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 325/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6981 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 326/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6981 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 327/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6981 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 328/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6981 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 329/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6980 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 3.433683843923063e-07.\n",
            "Epoch 330/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6980 - lr: 3.4337e-07\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 3.090315459530757e-07.\n",
            "Epoch 331/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6980 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 332/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6980 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 333/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6979 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 334/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6979 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 335/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6979 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 336/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6979 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 337/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6978 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 338/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6978 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 339/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6978 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 3.0903154879524664e-07.\n",
            "Epoch 340/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6978 - lr: 3.0903e-07\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 2.78128393915722e-07.\n",
            "Epoch 341/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6978 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 342/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6977 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 343/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6977 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 344/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6977 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 345/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6977 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 346/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6977 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 347/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6976 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 348/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6976 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 349/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6976 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 2.781283967578929e-07.\n",
            "Epoch 350/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6976 - lr: 2.7813e-07\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 2.5031555708210366e-07.\n",
            "Epoch 351/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6976 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 352/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6975 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 353/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6975 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 354/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6975 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 355/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6975 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 356/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6975 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 357/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6974 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 358/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6974 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 359/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6974 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 2.5031556560861645e-07.\n",
            "Epoch 360/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6974 - lr: 2.5032e-07\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 2.2528400904775482e-07.\n",
            "Epoch 361/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6974 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 362/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6974 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 363/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 364/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 365/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 366/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 367/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 368/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6973 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 369/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6972 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 2.2528401188992575e-07.\n",
            "Epoch 370/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6972 - lr: 2.2528e-07\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 2.027556107009332e-07.\n",
            "Epoch 371/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6972 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 372/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6972 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 373/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6972 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 374/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6972 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 375/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 376/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 377/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 378/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 379/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 2.027556149641896e-07.\n",
            "Epoch 380/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6971 - lr: 2.0276e-07\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1.8248005346777065e-07.\n",
            "Epoch 381/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6971 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 382/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 383/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 384/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 385/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 386/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 387/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 388/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 389/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6970 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1.824800506255997e-07.\n",
            "Epoch 390/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6969 - lr: 1.8248e-07\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1.6423204556303973e-07.\n",
            "Epoch 391/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 392/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 393/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 394/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 395/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 396/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 397/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6969 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 398/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6968 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 399/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6968 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1.6423204840521066e-07.\n",
            "Epoch 400/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6968 - lr: 1.6423e-07\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 1.478088435646896e-07.\n",
            "Epoch 401/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 402/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 403/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 404/600\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 405/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 406/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6968 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 407/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6967 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 408/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6967 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 409/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6967 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 1.47808847827946e-07.\n",
            "Epoch 410/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6967 - lr: 1.4781e-07\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 1.3302796304515143e-07.\n",
            "Epoch 411/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6967 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 412/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6967 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 413/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6967 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 414/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6967 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 415/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6967 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 416/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6966 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 417/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6966 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 418/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6966 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 419/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6966 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 1.3302796730840782e-07.\n",
            "Epoch 420/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6966 - lr: 1.3303e-07\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 1.1972517057756705e-07.\n",
            "Epoch 421/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 422/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 423/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 424/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 425/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 426/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6966 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 427/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6965 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 428/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6965 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 429/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6965 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 1.197251719986525e-07.\n",
            "Epoch 430/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6965 - lr: 1.1973e-07\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 431/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 432/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 433/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 434/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 435/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 436/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 437/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 438/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 439/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6965 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 1.0775265479878726e-07.\n",
            "Epoch 440/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 1.0775e-07\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 9.697738931890854e-08.\n",
            "Epoch 441/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 442/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 443/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 444/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 445/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 446/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 447/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 448/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 449/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 9.697738789782306e-08.\n",
            "Epoch 450/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 9.6977e-08\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 8.727964910804076e-08.\n",
            "Epoch 451/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6964 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 452/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 453/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6964 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 454/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 455/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 456/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 457/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 458/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 459/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 8.72796519502117e-08.\n",
            "Epoch 460/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6963 - lr: 8.7280e-08\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 7.855168675519053e-08.\n",
            "Epoch 461/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 462/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 463/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 464/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 465/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 466/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 467/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 468/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 469/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 7.85516860446478e-08.\n",
            "Epoch 470/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6963 - lr: 7.8552e-08\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 7.069651744018302e-08.\n",
            "Epoch 471/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 472/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 473/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 474/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 475/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 476/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 477/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 478/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 479/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 7.069651530855481e-08.\n",
            "Epoch 480/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6962 - lr: 7.0697e-08\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 481/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 482/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 483/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 484/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 485/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 486/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 487/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 488/600\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 489/600\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 6.362686377769933e-08.\n",
            "Epoch 490/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6962 - lr: 6.3627e-08\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 491/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6962 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 492/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 493/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 494/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 495/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 496/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 497/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 498/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 499/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 5.7264177399929395e-08.\n",
            "Epoch 500/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6961 - lr: 5.7264e-08\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 5.153775965993646e-08.\n",
            "Epoch 501/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 502/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 503/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 504/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 505/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 506/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 507/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 508/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 509/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 5.153776072575056e-08.\n",
            "Epoch 510/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6961 - lr: 5.1538e-08\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 511/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 512/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 513/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 514/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 515/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 516/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 517/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6961 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 518/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6960 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 519/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6960 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 4.63839846531755e-08.\n",
            "Epoch 520/600\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6960 - lr: 4.6384e-08\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 4.1745586187857954e-08.\n",
            "Epoch 521/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 522/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 523/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 524/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 525/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 526/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 527/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 528/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 529/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 4.174558654312932e-08.\n",
            "Epoch 530/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6960 - lr: 4.1746e-08\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 3.757102788881639e-08.\n",
            "Epoch 531/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 532/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 533/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 534/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 535/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 536/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 537/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 538/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 539/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 3.757102717827365e-08.\n",
            "Epoch 540/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6960 - lr: 3.7571e-08\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 3.3813924460446286e-08.\n",
            "Epoch 541/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 542/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 543/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 544/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 545/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 546/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 547/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 548/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 549/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 3.381392588153176e-08.\n",
            "Epoch 550/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6960 - lr: 3.3814e-08\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 3.043253329337858e-08.\n",
            "Epoch 551/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 552/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 553/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 554/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 555/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 556/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6960 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 557/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 558/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6959 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 559/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6959 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 3.0432534714464055e-08.\n",
            "Epoch 560/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6959 - lr: 3.0433e-08\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 2.738928124301765e-08.\n",
            "Epoch 561/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 562/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 563/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 564/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 565/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 566/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 567/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 568/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 569/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 2.7389281953560385e-08.\n",
            "Epoch 570/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6959 - lr: 2.7389e-08\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 2.4650353758204346e-08.\n",
            "Epoch 571/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 572/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 573/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 574/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 575/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 576/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 577/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 578/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 579/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 2.4650354646382766e-08.\n",
            "Epoch 580/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6959 - lr: 2.4650e-08\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 2.218531918174449e-08.\n",
            "Epoch 581/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 582/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 583/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 584/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 585/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 586/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 587/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 588/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 589/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 2.2185318471201754e-08.\n",
            "Epoch 590/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6959 - lr: 2.2185e-08\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 1.9966786624081578e-08.\n",
            "Epoch 591/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 592/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 593/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 594/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 595/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 596/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 597/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 598/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 599/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6959 - lr: 1.9967e-08\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 1.9966787334624314e-08.\n",
            "Epoch 600/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6959 - lr: 1.9967e-08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.001,  # Further reduced learning rate\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Compile the more complex model with KL divergence loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.KLDivergence())\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Example training step with learning rate scheduler\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=600, callbacks=[callback, loss_history])\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tv_lNM92aYhq",
        "outputId": "0aaa501b-5365-4a99-b1ef-6cd1479b5b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/600\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.7665 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6773 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6015 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5375 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4769 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 6/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4167 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 7/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3557 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 8/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2933 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 9/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2287 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 10/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1614 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 11/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0910 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 12/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0246 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 13/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.9552 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 14/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8826 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 15/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8070 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 16/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7285 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 17/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6472 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 18/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5633 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 19/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4774 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0009000000427477062.\n",
            "Epoch 20/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3898 - lr: 9.0000e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0008100000384729356.\n",
            "Epoch 21/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3009 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 22/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2203 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 23/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1394 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 24/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0587 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 25/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9785 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 26/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8993 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 27/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8213 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 28/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7447 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 29/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6699 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0008100000559352338.\n",
            "Epoch 30/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5969 - lr: 8.1000e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0007290000503417104.\n",
            "Epoch 31/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5337 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 32/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4829 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 33/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4438 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 34/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4074 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 35/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3722 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 36/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3438 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 37/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3211 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 38/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2993 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 39/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2783 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0007290000794455409.\n",
            "Epoch 40/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2580 - lr: 7.2900e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0006561000715009868.\n",
            "Epoch 41/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2384 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 42/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2213 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 43/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2109 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 44/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2012 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 45/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1920 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 46/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1831 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 47/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1746 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 48/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1663 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 49/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1583 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0006561000482179224.\n",
            "Epoch 50/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1506 - lr: 6.5610e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0005904900433961303.\n",
            "Epoch 51/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1430 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 52/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1364 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 53/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1300 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 54/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1237 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 55/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1176 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 56/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1116 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 57/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1057 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 58/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0999 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 59/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0942 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0005904900608584285.\n",
            "Epoch 60/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0894 - lr: 5.9049e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.0005314410547725857.\n",
            "Epoch 61/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0869 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 62/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0848 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 63/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0828 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 64/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0809 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 65/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0791 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 66/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0773 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 67/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0756 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 68/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0740 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 69/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0724 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.0005314410664141178.\n",
            "Epoch 70/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0709 - lr: 5.3144e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.00047829695977270604.\n",
            "Epoch 71/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0694 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 72/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0680 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 73/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0668 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 74/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0655 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 75/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0643 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 76/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0631 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 77/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0619 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 78/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0607 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 79/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0596 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.00047829694813117385.\n",
            "Epoch 80/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0584 - lr: 4.7830e-04\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.0004304672533180565.\n",
            "Epoch 81/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0573 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 82/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0563 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 83/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0553 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 84/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0544 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 85/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0534 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 86/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0524 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 87/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0515 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 88/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0505 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 89/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0496 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.00043046724749729037.\n",
            "Epoch 90/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0487 - lr: 4.3047e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.00038742052274756136.\n",
            "Epoch 91/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0477 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 92/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0469 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 93/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0461 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 94/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0452 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 95/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0444 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 96/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0436 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 97/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0428 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 98/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0419 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 99/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0411 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.0003874205285683274.\n",
            "Epoch 100/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0403 - lr: 3.8742e-04\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 0.0003486784757114947.\n",
            "Epoch 101/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0395 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 102/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0388 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 103/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0380 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 104/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0373 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 105/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0366 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 106/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0358 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 107/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0351 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 108/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0344 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 109/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0337 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 0.0003486784698907286.\n",
            "Epoch 110/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0329 - lr: 3.4868e-04\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 0.00031381062290165574.\n",
            "Epoch 111/600\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0322 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 112/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0315 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 113/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0309 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 114/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0302 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 115/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0296 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 116/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0289 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 117/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0283 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 118/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0276 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 119/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0269 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 0.0003138106258120388.\n",
            "Epoch 120/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0263 - lr: 3.1381e-04\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 0.0002824295632308349.\n",
            "Epoch 121/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0256 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 122/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0250 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 123/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0244 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 124/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0239 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 125/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0233 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 126/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0227 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 127/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0221 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 128/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0215 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 129/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0209 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 0.00028242956614121795.\n",
            "Epoch 130/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0203 - lr: 2.8243e-04\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 0.00025418660952709616.\n",
            "Epoch 131/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0197 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 132/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0192 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 133/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0186 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 134/600\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0181 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 135/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0176 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 136/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0170 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 137/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0165 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 138/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0160 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 139/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0154 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 0.00025418659788556397.\n",
            "Epoch 140/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0149 - lr: 2.5419e-04\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 141/600\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0143 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 142/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0139 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 143/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0134 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 144/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0129 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 145/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0124 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 146/600\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0119 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 147/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0114 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 148/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0109 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 149/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0105 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 0.00022876793809700757.\n",
            "Epoch 150/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0100 - lr: 2.2877e-04\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 0.00020589114428730683.\n",
            "Epoch 151/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0095 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 152/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0090 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 153/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0086 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 154/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 155/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 156/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 157/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0068 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 158/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0064 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 159/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0060 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 0.00020589114865288138.\n",
            "Epoch 160/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0055 - lr: 2.0589e-04\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 0.00018530203378759326.\n",
            "Epoch 161/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0051 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 162/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0047 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 163/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 164/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 165/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 166/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0031 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 167/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0027 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 168/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0023 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 169/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0019 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 0.0001853020366979763.\n",
            "Epoch 170/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - lr: 1.8530e-04\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 0.00016677183302817866.\n",
            "Epoch 171/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0011 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 172/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.1976e-04 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 173/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.5834e-04 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 174/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3567e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 175/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3571e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 176/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3575e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 177/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3578e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 178/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3581e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 179/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3584e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 0.00016677183157298714.\n",
            "Epoch 180/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3586e-07 - lr: 1.6677e-04\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 0.00015009464841568844.\n",
            "Epoch 181/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3588e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 182/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3590e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 183/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3592e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 184/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3593e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 185/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3595e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 186/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3596e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 187/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3597e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 188/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3598e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 189/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3599e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 0.000150094652781263.\n",
            "Epoch 190/600\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -6.3599e-07 - lr: 1.5009e-04\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 0.0001350851875031367.\n",
            "Epoch 191/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3600e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 192/600\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -6.3601e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 193/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3601e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 194/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3602e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 195/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3602e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 196/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -6.3603e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 197/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3603e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 198/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3603e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 199/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3603e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 0.0001350851816823706.\n",
            "Epoch 200/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3604e-07 - lr: 1.3509e-04\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 0.00012157666351413355.\n",
            "Epoch 201/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3604e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 202/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3604e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 203/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3604e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 204/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3604e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 205/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 206/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 207/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 208/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 209/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 0.0001215766606037505.\n",
            "Epoch 210/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3605e-07 - lr: 1.2158e-04\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 0.00010941899454337544.\n",
            "Epoch 211/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 212/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 213/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 214/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 215/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 216/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 217/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3605e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 218/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 219/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 0.00010941899381577969.\n",
            "Epoch 220/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 1.0942e-04\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 9.847709443420172e-05.\n",
            "Epoch 221/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 222/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 223/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 224/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 225/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 226/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 227/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 228/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 229/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 9.847709588939324e-05.\n",
            "Epoch 230/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 9.8477e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 8.862938630045391e-05.\n",
            "Epoch 231/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 232/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 233/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 234/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 235/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 236/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 237/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 238/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 239/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 8.862938557285815e-05.\n",
            "Epoch 240/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 8.8629e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 241/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 242/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 243/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 244/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 245/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 246/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 247/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 248/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 249/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 7.976644701557234e-05.\n",
            "Epoch 250/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 7.9766e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 7.178980231401511e-05.\n",
            "Epoch 251/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 252/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 253/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 254/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 255/600\n",
            "1/1 [==============================] - 0s 41ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 256/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 257/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 258/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 259/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 7.178980013122782e-05.\n",
            "Epoch 260/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 7.1790e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 6.461082011810504e-05.\n",
            "Epoch 261/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 262/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 263/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 264/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 265/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 266/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 267/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 268/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 269/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 6.461082375608385e-05.\n",
            "Epoch 270/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 6.4611e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 5.8149741380475466e-05.\n",
            "Epoch 271/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 272/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 273/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 274/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 275/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 276/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 277/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 278/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 279/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 5.81497406528797e-05.\n",
            "Epoch 280/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.8150e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 5.233476658759173e-05.\n",
            "Epoch 281/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 282/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 283/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 284/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 285/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 286/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 287/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 288/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 289/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 5.233476622379385e-05.\n",
            "Epoch 290/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 5.2335e-05\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 4.7101289601414466e-05.\n",
            "Epoch 291/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 292/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 293/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 294/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 295/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 296/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 297/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 298/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 299/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 4.7101289965212345e-05.\n",
            "Epoch 300/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 4.7101e-05\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 4.239116096869111e-05.\n",
            "Epoch 301/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 302/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 303/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 304/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 305/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 306/600\n",
            "1/1 [==============================] - 0s 37ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 307/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 308/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 309/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 4.2391162423882633e-05.\n",
            "Epoch 310/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 4.2391e-05\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 3.815204618149437e-05.\n",
            "Epoch 311/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 312/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 313/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 314/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 315/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 316/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 317/600\n",
            "1/1 [==============================] - 0s 36ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 318/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 319/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 3.815204763668589e-05.\n",
            "Epoch 320/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 3.8152e-05\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 3.4336842873017304e-05.\n",
            "Epoch 321/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 322/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 323/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 324/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 325/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 326/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 327/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 328/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 329/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 3.433684469200671e-05.\n",
            "Epoch 330/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.4337e-05\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 331/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 332/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 333/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 334/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 335/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 336/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 337/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 338/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 339/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 3.0903160222806036e-05.\n",
            "Epoch 340/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.0903e-05\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 2.7812844200525434e-05.\n",
            "Epoch 341/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 342/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 343/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 344/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 345/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 346/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 347/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 348/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 349/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 2.7812844564323314e-05.\n",
            "Epoch 350/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 2.7813e-05\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 2.5031560107890984e-05.\n",
            "Epoch 351/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 352/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 353/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 354/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 355/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 356/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 357/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 358/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 359/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 2.5031560653587803e-05.\n",
            "Epoch 360/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.5032e-05\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 2.2528404588229024e-05.\n",
            "Epoch 361/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 362/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 363/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 364/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 365/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 366/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 367/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 368/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 369/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 2.252840386063326e-05.\n",
            "Epoch 370/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.2528e-05\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 2.0275563474569936e-05.\n",
            "Epoch 371/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 372/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 373/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 374/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 375/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 376/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 377/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 378/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 379/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 2.0275563656468876e-05.\n",
            "Epoch 380/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.0276e-05\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1.8248007290821987e-05.\n",
            "Epoch 381/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 382/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 383/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 384/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 385/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 386/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 387/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 388/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 389/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1.8248007108923048e-05.\n",
            "Epoch 390/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.8248e-05\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1.6423206398030745e-05.\n",
            "Epoch 391/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 392/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 393/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 394/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 395/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 396/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 397/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 398/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 399/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1.6423206034232862e-05.\n",
            "Epoch 400/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.6423e-05\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 1.4780885430809576e-05.\n",
            "Epoch 401/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 402/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 403/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 404/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 405/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 406/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 407/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 408/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 409/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 1.4780885067011695e-05.\n",
            "Epoch 410/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 1.4781e-05\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 1.3302796560310526e-05.\n",
            "Epoch 411/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 412/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 413/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 414/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 415/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 416/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 417/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 418/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 419/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 1.3302797015057877e-05.\n",
            "Epoch 420/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 1.3303e-05\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 421/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 422/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 423/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 424/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 425/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 426/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 427/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 428/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 429/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 1.1972517313552089e-05.\n",
            "Epoch 430/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 1.1973e-05\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 1.077526558219688e-05.\n",
            "Epoch 431/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 432/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 433/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 434/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 435/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 436/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 437/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 438/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 439/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 1.077526576409582e-05.\n",
            "Epoch 440/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 1.0775e-05\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 441/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 442/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 443/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 444/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 445/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 446/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 447/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 448/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 449/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 9.697739187686238e-06.\n",
            "Epoch 450/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 9.6977e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 8.727965268917615e-06.\n",
            "Epoch 451/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 452/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 453/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 454/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 455/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 456/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 457/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 458/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 459/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 8.727964996069204e-06.\n",
            "Epoch 460/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 8.7280e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 7.855168496462283e-06.\n",
            "Epoch 461/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 462/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 463/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 464/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 465/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 466/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 467/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 468/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 469/600\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 7.855168405512813e-06.\n",
            "Epoch 470/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 7.8552e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 7.069651564961533e-06.\n",
            "Epoch 471/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 472/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 473/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 474/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 475/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 476/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 477/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 478/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 479/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 7.069651474012062e-06.\n",
            "Epoch 480/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 7.0697e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 6.362686326610856e-06.\n",
            "Epoch 481/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 482/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 483/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 484/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 485/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 486/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 487/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 488/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 489/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 6.362686235661386e-06.\n",
            "Epoch 490/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 6.3627e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 5.726417612095247e-06.\n",
            "Epoch 491/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 492/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 493/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 494/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 495/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 496/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 497/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 498/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 499/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 5.7264178394689225e-06.\n",
            "Epoch 500/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 5.7264e-06\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 5.15377605552203e-06.\n",
            "Epoch 501/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 502/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 503/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 504/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 505/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 506/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 507/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 508/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 509/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 5.15377587362309e-06.\n",
            "Epoch 510/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 5.1538e-06\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 4.638398286260781e-06.\n",
            "Epoch 511/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 512/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 513/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 514/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 515/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 516/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 517/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 518/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 519/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 4.638398422684986e-06.\n",
            "Epoch 520/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.6384e-06\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 4.174558580416488e-06.\n",
            "Epoch 521/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 522/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 523/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 524/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 525/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 526/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 527/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 528/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 529/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 4.174558398517547e-06.\n",
            "Epoch 530/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 4.1746e-06\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 3.7571025586657926e-06.\n",
            "Epoch 531/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 532/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 533/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 534/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 535/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 536/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 537/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 538/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 539/600\n",
            "1/1 [==============================] - 0s 33ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 3.7571026041405275e-06.\n",
            "Epoch 540/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 3.7571e-06\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 3.381392343726475e-06.\n",
            "Epoch 541/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 542/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 543/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 544/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 545/600\n",
            "1/1 [==============================] - 0s 34ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 546/600\n",
            "1/1 [==============================] - 0s 35ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 547/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 548/600\n",
            "1/1 [==============================] - 0s 30ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 549/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 3.38139238920121e-06.\n",
            "Epoch 550/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 3.3814e-06\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 3.043253150281089e-06.\n",
            "Epoch 551/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 552/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 553/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 554/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 555/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 556/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 557/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 558/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 559/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 3.0432531730184564e-06.\n",
            "Epoch 560/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 3.0433e-06\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 2.7389278557166107e-06.\n",
            "Epoch 561/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 562/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 563/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 564/600\n",
            "1/1 [==============================] - 0s 25ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 565/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 566/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 567/600\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 568/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 569/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 2.7389278329792432e-06.\n",
            "Epoch 570/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.7389e-06\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 2.465035049681319e-06.\n",
            "Epoch 571/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 572/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 573/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 574/600\n",
            "1/1 [==============================] - 0s 19ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 575/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 576/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 577/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 578/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 579/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 2.465035095156054e-06.\n",
            "Epoch 580/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 2.4650e-06\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 2.2185315856404485e-06.\n",
            "Epoch 581/600\n",
            "1/1 [==============================] - 0s 28ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 582/600\n",
            "1/1 [==============================] - 0s 27ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 583/600\n",
            "1/1 [==============================] - 0s 29ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 584/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 585/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 586/600\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 587/600\n",
            "1/1 [==============================] - 0s 18ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 588/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 589/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 2.218531562903081e-06.\n",
            "Epoch 590/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 2.2185e-06\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 1.996678406612773e-06.\n",
            "Epoch 591/600\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 592/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 593/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 594/600\n",
            "1/1 [==============================] - 0s 24ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 595/600\n",
            "1/1 [==============================] - 0s 26ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 596/600\n",
            "1/1 [==============================] - 0s 32ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 597/600\n",
            "1/1 [==============================] - 0s 31ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 598/600\n",
            "1/1 [==============================] - 0s 20ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 599/600\n",
            "1/1 [==============================] - 0s 22ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 1.9966782929259352e-06.\n",
            "Epoch 600/600\n",
            "1/1 [==============================] - 0s 23ms/step - loss: -6.3606e-07 - lr: 1.9967e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.0001,  # Further reduced learning rate more further\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Compile the more complex model with KL divergence loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.KLDivergence())\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Example training step with learning rate scheduler\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=400, callbacks=[callback, loss_history])\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kizE_ch9b0QV",
        "outputId": "ec8100e2-90db-49de-9c48-adf74dc10c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 1/400\n",
            "1/1 [==============================] - 4s 4s/step - loss: 2.7827 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7734 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7643 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7553 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7465 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7378 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7293 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7209 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7126 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7044 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640876e-05.\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6964 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6892 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6821 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6751 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6682 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6616 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6552 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6490 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6429 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 9.000000136438757e-05.\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6369 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.100000122794882e-05.\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6309 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6256 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6203 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6151 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6099 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6048 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5998 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5948 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5898 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-05.\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5849 - lr: 8.1000e-05\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.289999848580919e-05.\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5799 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5755 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5711 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5668 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5624 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5580 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5537 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.5493 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.5449 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.2900002123788e-05.\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5406 - lr: 7.2900e-05\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5362 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5322 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5283 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5243 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.5204 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.5164 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5124 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5084 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5044 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.56100019114092e-05.\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5004 - lr: 6.5610e-05\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4964 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4928 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4891 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.4855 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4818 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4781 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4744 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4707 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4670 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904900172026828e-05.\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4632 - lr: 5.9049e-05\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314410154824145e-05.\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4595 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4560 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4526 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4492 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4457 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4422 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.4387 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4352 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4317 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314410009304993e-05.\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.4281 - lr: 5.3144e-05\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.7829690083744934e-05.\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.4245 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4213 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4180 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4147 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4114 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4081 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4048 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4014 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3981 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-05.\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3947 - lr: 4.7830e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-05.\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3912 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3881 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3850 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3819 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3788 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3756 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3724 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3692 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3660 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.3046718928962946e-05.\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3627 - lr: 4.3047e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.8742047036066654e-05.\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3595 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3565 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3535 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3505 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3475 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3445 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3415 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3384 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3353 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874204776366241e-05.\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3322 - lr: 3.8742e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867842987296176e-05.\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3291 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3263 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3235 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.3206 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3178 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3149 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3120 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3091 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3062 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.4867844078689814e-05.\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3033 - lr: 3.4868e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3003 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2977 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2950 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2923 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2896 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2869 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2842 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2815 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2787 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.138105967082083e-05.\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2760 - lr: 3.1381e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2732 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2707 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2682 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2657 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2631 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2606 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2580 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2555 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2529 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.824295370373875e-05.\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2503 - lr: 2.8243e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418658333364876e-05.\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2477 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2454 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2431 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2407 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2384 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2360 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2336 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2312 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2288 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418657969566993e-05.\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2264 - lr: 2.5419e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876792172610294e-05.\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2240 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2219 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2197 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2175 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2153 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2131 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2109 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2087 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2065 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-05.\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2043 - lr: 2.2877e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2021 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2001 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1981 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1960 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1940 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1920 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1900 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1879 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1859 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-05.\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1839 - lr: 2.0589e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-05.\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1818 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1800 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1781 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1763 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1744 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1726 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1707 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1688 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1670 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201487010345e-05.\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1651 - lr: 1.8530e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.667718133830931e-05.\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1632 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1615 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1599 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1582 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1565 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1548 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1531 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1514 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1497 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718061071355e-05.\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1480 - lr: 1.6677e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009462549642194e-05.\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1462 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1447 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1432 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1416 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1401 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1385 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1370 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1354 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1339 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009462913440075e-05.\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1323 - lr: 1.5009e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508516622096067e-05.\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1308 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1294 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1280 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1266 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1252 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1238 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1224 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1209 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1195 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.3508516531146597e-05.\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1181 - lr: 1.3509e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1.2157664878031938e-05.\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1167 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1155 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1142 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1129 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1117 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1104 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1091 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1078 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1066 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1.2157664968981408e-05.\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1053 - lr: 1.2158e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1.0941898472083266e-05.\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1040 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1029 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1017 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1006 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0994 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0983 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0971 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0960 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0948 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1.0941898835881148e-05.\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0937 - lr: 1.0942e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 9.847708952293033e-06.\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0925 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0915 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0905 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0894 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0884 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0874 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0863 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0853 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0843 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 9.847708497545682e-06.\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0832 - lr: 9.8477e-06\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0822 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0812 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0803 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0794 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0784 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0775 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0766 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0756 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0747 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 8.862937647791114e-06.\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0738 - lr: 8.8629e-06\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 7.976643883012003e-06.\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0728 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0720 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0712 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0703 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0695 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0686 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0678 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0669 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0661 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 7.976644155860413e-06.\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0653 - lr: 7.9766e-06\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 7.178979740274372e-06.\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0644 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0637 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0629 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0622 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0614 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0606 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0599 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0591 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0584 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 7.178979558375431e-06.\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0576 - lr: 7.1790e-06\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 6.461081602537889e-06.\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0569 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0562 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0555 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0548 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0541 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0535 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0528 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0521 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0514 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 6.461081738962093e-06.\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0507 - lr: 6.4611e-06\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 5.814973565065884e-06.\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0501 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0495 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0488 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0482 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0476 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0470 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0464 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0458 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0452 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 5.814973519591149e-06.\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0446 - lr: 5.8150e-06\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 5.233476167632034e-06.\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0440 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0434 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0429 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0423 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0418 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0412 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0407 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0401 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0396 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 5.233476258581504e-06.\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0390 - lr: 5.2335e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 4.710128632723354e-06.\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0385 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0380 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0375 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0370 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0365 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0360 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0355 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0350 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0346 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 4.7101284508244134e-06.\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0341 - lr: 4.7101e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 4.2391156057419724e-06.\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0336 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0331 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0327 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0322 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0318 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0314 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0309 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0305 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0300 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 4.239115696691442e-06.\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0296 - lr: 4.2391e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 3.815204127022298e-06.\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0292 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0288 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0284 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0280 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0276 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0272 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0268 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0264 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0260 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 3.815204308921238e-06.\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0256 - lr: 3.8152e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 3.4336838780291147e-06.\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0252 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0249 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0245 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0242 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0238 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0234 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0231 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0227 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0224 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 3.4336837870796444e-06.\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0220 - lr: 3.4337e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 3.09031540837168e-06.\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0217 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0214 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0210 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0207 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0204 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0201 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0198 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0195 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0191 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 3.0903154311090475e-06.\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0188 - lr: 3.0903e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 2.781283887998143e-06.\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0185 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0182 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0179 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0176 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0174 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0171 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0168 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0165 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0162 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 2.7812839107355103e-06.\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0159 - lr: 2.7813e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 2.5031555196619593e-06.\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0157 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0154 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0151 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0149 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0146 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0144 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0141 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0139 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0136 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 2.503155428712489e-06.\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0134 - lr: 2.5032e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 2.25283988584124e-06.\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0131 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0129 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0126 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0124 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0122 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0120 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0117 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0115 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0113 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 2.2528399767907104e-06.\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0110 - lr: 2.2528e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 2.0275559791116393e-06.\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0108 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0106 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.0104 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0102 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0100 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0098 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0096 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0094 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0092 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 2.027556092798477e-06.\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0090 - lr: 2.0276e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 1.8248004835186294e-06.\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0088 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0086 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0084 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0082 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0080 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0078 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0077 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0075 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0073 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 1.8248005062559969e-06.\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0071 - lr: 1.8248e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 1.6423204556303972e-06.\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0069 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0068 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0066 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0064 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0063 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0061 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0059 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.0058 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0056 - lr: 1.6423e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 1.642320512473816e-06.\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0054 - lr: 1.6423e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)  # create logits for Ber(p) samples\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)  # Add small epsilon for numerical stability\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)  # s_0\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)  # x_0\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)  # x(t) = f(y_{t-1}, s_{t-2})\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(DV_hidden[0], return_sequences=True, stateful=False, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 10,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.0019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 80000,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'lr': 0.00001,  # Further reduced learning rate\n",
        "    'output_activation': 'linear',  # Add the output activation\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "# Verify data integrity\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "# Adjust input shapes to match model expectations\n",
        "x_y_combined = tf.concat([x, y], axis=-1)  # Shape: (batch_size, bptt, 2)\n",
        "\n",
        "# Initialize the more complex model v3\n",
        "input_shape = (config['bptt'], 2)  # Using combined input of x and y\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "# Compile the more complex model with Huber loss function and learning rate scheduler\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)  # Use gradient clipping\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.Huber())\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Example training step with learning rate scheduler\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=250, callbacks=[callback, loss_history])\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6arzblYOdZlk",
        "outputId": "33cb7d18-fe46-49ba-d9c8-2e2253dae3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/250\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2937 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2937 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2937 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2937 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2937 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2936 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2936 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2936 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2936 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/250\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2936 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2936 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2935 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/250\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2935 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2935 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2935 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2935 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2934 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2934 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2933 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904899762754212e-06.\n",
            "Epoch 51/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 52/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 53/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 54/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 55/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 56/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 57/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 58/250\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 59/250\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 60/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2933 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314409827406053e-06.\n",
            "Epoch 61/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 62/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 63/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 64/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 65/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 66/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 67/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 68/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 69/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 70/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2933 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.782968926519971e-06.\n",
            "Epoch 71/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 72/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 73/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 74/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 75/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 76/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 77/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 78/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 79/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 80/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 81/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 82/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 83/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 84/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 85/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 86/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 87/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 88/250\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 89/250\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 90/250\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2932 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.874204867315711e-06.\n",
            "Epoch 91/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 92/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 93/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 94/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 95/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 96/250\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2932 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 97/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2931 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 98/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2931 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 99/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2931 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 100/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2931 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867845442931865e-06.\n",
            "Epoch 101/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 102/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 103/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 104/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 105/250\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 106/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 107/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 108/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 109/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 110/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2931 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138106171718391e-06.\n",
            "Epoch 111/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 112/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 113/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 114/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 115/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 116/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 117/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 118/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 119/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 120/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295575010183e-06.\n",
            "Epoch 121/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 122/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 123/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 124/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 125/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 126/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 127/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 128/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 129/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 130/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2931 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418659561182724e-06.\n",
            "Epoch 131/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2931 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 132/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 133/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 134/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 135/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 136/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 137/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 138/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 139/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 140/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2930 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876794218973373e-06.\n",
            "Epoch 141/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 142/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 143/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 144/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 145/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 146/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 147/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 148/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 149/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 150/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2930 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 151/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 152/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 153/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 154/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 155/250\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 156/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 157/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 158/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 159/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 160/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2930 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-06.\n",
            "Epoch 161/250\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 162/250\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 163/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 164/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 165/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 166/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 167/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 168/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 169/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 170/250\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2930 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.6677181747581927e-06.\n",
            "Epoch 171/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 172/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 173/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 174/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 175/250\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 176/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 177/250\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 178/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 179/250\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 180/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2930 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009463368187425e-06.\n",
            "Epoch 181/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 182/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 183/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 184/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 185/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 186/250\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2930 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 187/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2929 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 188/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 189/250\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2929 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 190/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508517440641298e-06.\n",
            "Epoch 191/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 192/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 193/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 194/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 195/250\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 196/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 197/250\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 198/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 199/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 200/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2929 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 1.2157666105849786e-06.\n",
            "Epoch 201/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 202/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 203/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 204/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 205/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 206/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 207/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 208/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 209/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 1.215766587847611e-06.\n",
            "Epoch 210/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2929 - lr: 1.2158e-06\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 1.0941899290628499e-06.\n",
            "Epoch 211/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 212/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 213/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 214/250\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 215/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 216/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 217/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 218/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 219/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 1.0941898835881148e-06.\n",
            "Epoch 220/250\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2929 - lr: 1.0942e-06\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 9.847708952293033e-07.\n",
            "Epoch 221/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 222/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 223/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 224/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 225/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 226/250\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 227/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 228/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 229/250\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 9.847708497545682e-07.\n",
            "Epoch 230/250\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2929 - lr: 9.8477e-07\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 8.862937647791114e-07.\n",
            "Epoch 231/250\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 232/250\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 233/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 234/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 235/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 236/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 237/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 238/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 239/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 8.862937761477951e-07.\n",
            "Epoch 240/250\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2929 - lr: 8.8629e-07\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 7.976643985330156e-07.\n",
            "Epoch 241/250\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 242/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 243/250\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 244/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 245/250\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 246/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 247/250\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 248/250\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 249/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 7.9766e-07\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 7.976643701113062e-07.\n",
            "Epoch 250/250\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2929 - lr: 7.9766e-07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHdCAYAAACQZzRJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVMElEQVR4nOzdZ3RU1deA8Wd6Se89QEBaqApIkaJgA1GUV+wKiA2wIBb4iwI2QMGGlQACKigKVkDFrkgTBAWkmpBGes8kU+/7ITAQk0AICROS/Vtrls69557ZdyZhdk5VKYqiIIQQQgghznlqTwcghBBCCCHqhyR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QgghhBBNhCR2QnjA6NGjadmyZZ2unTFjBiqVqn4DEnXy008/oVKp+OmnnzwdSoNp2bIlo0eP9nQYQohaksROiBOoVKpaPZryF/nJjB49Gm9vb0+Hcc5ZsmQJKpWKP/74w9OhnFP++3vn6+vLwIEDWbNmTZ3rXL58Oa+88kr9BSlEI6P1dABCNCbvvfdepefLli1j/fr1VY536NDhjF4nISEBl8tVp2unTZvGlClTzuj1haitffv2oVZ7rg3g0ksv5fbbb0dRFA4fPsxbb73F8OHDWbduHZdffvlp17d8+XJ27drFQw89VP/BCtEISGInxAluvfXWSs83bdrE+vXrqxz/L4vFgtlsrvXr6HS6OsUHoNVq0WrlV1ecPofDgcvlQq/X1/oag8HQgBGdWtu2bSv9/o0cOZKOHTvy6quv1imxE6Kpk65YIU7ToEGD6NSpE9u2bWPAgAGYzWb+97//AfD5558zbNgwIiMjMRgMtG7dmmeeeQan01mpjv+OsUtKSkKlUjF37lwWLFhA69atMRgM9OzZk61bt1a6troxdiqViokTJ/LZZ5/RqVMnDAYD8fHxfP3111Xi/+mnn+jRowdGo5HWrVvzzjvv1Pu4vY8//pgLLrgAk8lEcHAwt956K2lpaZXKZGRkMGbMGKKjozEYDERERHDNNdeQlJTkLvPHH39w+eWXExwcjMlkolWrVowdO/aUr1/bz+HYZ7lnzx4uvvhizGYzUVFRvPDCC1XqTE1NZcSIEXh5eREaGsqkSZOwWq11e4NqkJaWxtixYwkLC3N/hosXL65Uxmaz8dRTT3HBBRfg5+eHl5cX/fv358cff6xU7sSfqVdeecX9M7Vnzx73533w4EFGjx6Nv78/fn5+jBkzBovFUqme/46xO9atvGHDBh5++GFCQkLw8vLi2muvJTs7u9K1LpeLGTNmEBkZidls5uKLL2bPnj1nNG6vQ4cOBAcHc+jQoUrHa/OZDxo0iDVr1nD48GF39+6Jv4dWq5Xp06fTpk0bDAYDMTExPPbYY/X+OQvRkOTPfiHqIDc3lyuvvJIbb7yRW2+9lbCwMKDiS8/b25uHH34Yb29vfvjhB5566imKiop48cUXT1nv8uXLKS4u5p577kGlUvHCCy9w3XXX8e+//56yle+3335j9erVjB8/Hh8fH1577TVGjhxJcnIyQUFBAPz5559cccUVREREMHPmTJxOJ08//TQhISFn/qYctWTJEsaMGUPPnj2ZNWsWmZmZvPrqq2zYsIE///wTf39/oKLlZffu3dx///20bNmSrKws1q9fT3Jysvv5ZZddRkhICFOmTMHf35+kpCRWr15dqxhq+znk5+dzxRVXcN111zFq1Cg++eQTHn/8cTp37syVV14JQFlZGYMHDyY5OZkHHniAyMhI3nvvPX744Yd6e98yMzPp3bu3O0kPCQlh3bp13HnnnRQVFbm7DouKili4cCE33XQTd911F8XFxSxatIjLL7+cLVu20K1bt0r1vvvuu5SXl3P33XdjMBgIDAx0nxs1ahStWrVi1qxZbN++nYULFxIaGsqcOXNOGe/9999PQEAA06dPJykpiVdeeYWJEyfy0UcfuctMnTqVF154geHDh3P55Zezc+dOLr/8csrLy+v8PhUWFpKfn0/r1q0rHa/NZ/7EE09QWFhIamoqL7/8MoB7zKjL5eLqq6/mt99+4+6776ZDhw78/fffvPzyy+zfv5/PPvuszjELcVYpQogaTZgwQfnvr8nAgQMVQHn77berlLdYLFWO3XPPPYrZbFbKy8vdx+644w6lRYsW7ueJiYkKoAQFBSl5eXnu459//rkCKF9++aX72PTp06vEBCh6vV45ePCg+9jOnTsVQJk/f7772PDhwxWz2aykpaW5jx04cEDRarVV6qzOHXfcoXh5edV43mazKaGhoUqnTp2UsrIy9/GvvvpKAZSnnnpKURRFyc/PVwDlxRdfrLGuTz/9VAGUrVu3njKu/6rt53Dss1y2bJn7mNVqVcLDw5WRI0e6j73yyisKoKxcudJ9rLS0VGnTpo0CKD/++ONJ43n33XdPeS933nmnEhERoeTk5FQ6fuONNyp+fn7ue3I4HIrVaq1UJj8/XwkLC1PGjh3rPnbsZ8rX11fJysqqVP7Yz9CJ5RVFUa699lolKCio0rEWLVood9xxR5V7GTJkiOJyudzHJ02apGg0GqWgoEBRFEXJyMhQtFqtMmLEiEr1zZgxQwEq1VkTQLnzzjuV7OxsJSsrS/njjz+UK664otqfndp+5sOGDav0u3fMe++9p6jVauXXX3+tdPztt99WAGXDhg2njFeIxkC6YoWoA4PBwJgxY6ocN5lM7v8vLi4mJyeH/v37Y7FY2Lt37ynrveGGGwgICHA/79+/PwD//vvvKa8dMmRIpVaMLl264Ovr677W6XTy3XffMWLECCIjI93l2rRp426ZOlN//PEHWVlZjB8/HqPR6D4+bNgw2rdv757NaDKZ0Ov1/PTTT+Tn51db17GWva+++gq73X5acZzO5+Dt7V1pDJder6dXr16V3vO1a9cSERHB//3f/7mPmc1m7r777tOKqyaKorBq1SqGDx+Ooijk5OS4H5dffjmFhYVs374dAI1G4x4j53K5yMvLw+Fw0KNHD3eZE40cObLGFtl777230vP+/fuTm5tLUVHRKWO+++67K3Xf9+/fH6fTyeHDhwH4/vvvcTgcjB8/vtJ1999//ynrPtGiRYsICQkhNDSUHj168P333/PYY4/x8MMPVyp3pr97H3/8MR06dKB9+/aV3v9LLrkEoEpXtxCNlXTFClEHUVFR1Q5A3717N9OmTeOHH36o8uVYWFh4ynpjY2MrPT+W5NWU/Jzs2mPXH7s2KyuLsrIy2rRpU6Vcdcfq4tiXert27aqca9++Pb/99htQkRjPmTOHyZMnExYWRu/evbnqqqu4/fbbCQ8PB2DgwIGMHDmSmTNn8vLLLzNo0CBGjBjBzTfffMoB/afzOURHR1cZXxgQEMBff/1V6b7atGlTpVx191kX2dnZFBQUsGDBAhYsWFBtmaysLPf/L126lHnz5rF3795KSW+rVq2qXFfdsWNO9vPm6+t70phP9bN67Gfhvz9bgYGBlf54OZVrrrmGiRMnYrPZ2Lp1K88//zwWi6XKTN0z/d07cOAA//zzT41J8Invv6jZ5n9zWfDLv/ydVkhWsZV3bruAy+PDG+z1Xl6/n1e/P1DpWFyIFz9MHtRgr9nYSWInRB2c2DpwTEFBAQMHDsTX15enn36a1q1bYzQa2b59O48//nitljfRaDTVHlcUpUGv9YSHHnqI4cOH89lnn/HNN9/w5JNPMmvWLH744Qe6d++OSqXik08+YdOmTXz55Zd88803jB07lnnz5rFp06Ya19M73c+hMbxvx2K69dZbueOOO6ot06VLFwDef/99Ro8ezYgRI3j00UcJDQ1Fo9Ewa9asKhMKoPqf1WPOhZ+36OhohgwZAsDQoUMJDg5m4sSJXHzxxVx33XVA/fzuuVwuOnfuzEsvvVTt+ZiYmPq7qSbMYnfSIcKX63vEcO/7287Ka7YN8+b9cRe6n2s9uDxPYyCJnRD15KeffiI3N5fVq1czYMAA9/HExEQPRnVcaGgoRqORgwcPVjlX3bG6aNGiBVCx9tmxLqxj9u3b5z5/TOvWrZk8eTKTJ0/mwIEDdOvWjXnz5vH++++7y/Tu3ZvevXvz3HPPsXz5cm655RY+/PBDxo0bV20MDfE5tGjRgl27dqEoSqVWu3379tW5zhOFhITg4+OD0+l0JzE1+eSTT4iLi2P16tWVYpk+fXq9xFJfjn3WBw8erNRqmJubW6sW6Jrcc889vPzyy0ybNo1rr73WvWB4bT/zmmZ/t27dmp07dzJ48GDZ2eUMXNwulIvbhdZ43upwMvebfXyxM52iMgdtw32YckV7+rQOqvNratRqQn2Mpy7YTDTvtFaIenSsBePEFgubzcabb77pqZAq0Wg0DBkyhM8++4z09HT38YMHD7Ju3bp6eY0ePXoQGhrK22+/XWmJiHXr1vHPP/8wbNgwoGLdv//OjGzdujU+Pj7u6/Lz86u0/hyb8Xmy5Sca4nMYOnQo6enpfPLJJ+5jFoulxm7T06XRaBg5ciSrVq1i165dVc6fuIxIdfe3efNmNm7cWC+x1JfBgwej1Wp56623Kh1//fXXz6herVbL5MmT+eeff/j888+B0/vMvby8qu2aHTVqFGlpaSQkJFQ5V1ZWRmlp6RnFLSpM/3w325MLmH/T+Xz9UH+GdQ7njne3kJhT9/c3KaeUXs99R/8XfuDBD/8kraCsHiM+90iLnRD1pG/fvgQEBHDHHXfwwAMPoFKpeO+99xpVV+iMGTP49ttv6devH/fddx9Op5PXX3+dTp06sWPHjlrVYbfbefbZZ6scDwwMZPz48cyZM4cxY8YwcOBAbrrpJvdyJy1btmTSpEkA7N+/n8GDBzNq1Cg6duyIVqvl008/JTMzkxtvvBGoGEf25ptvcu2119K6dWuKi4tJSEjA19eXoUOH1hhfQ3wOd911F6+//jq3334727ZtIyIigvfee++0FqUGWLx4cbVrCz744IPMnj2bH3/8kQsvvJC77rqLjh07kpeXx/bt2/nuu+/Iy8sD4KqrrmL16tVce+21DBs2jMTERN5++206duxISUlJne+xvoWFhfHggw8yb948rr76aq644gp27tzJunXrCA4OPqNWsdGjR/PUU08xZ84cRowYcVqf+QUXXMBHH33Eww8/TM+ePfH29mb48OHcdtttrFy5knvvvZcff/yRfv364XQ62bt3LytXruSbb76hR48eZ/KWNHtpBWV8vC2V36dcQphvRQvb3QNa8/P+bD7+I4XHrmh/2nV2i/Vn7vVdiQvxIqvYyqvf7WfU2xv5ZtIAvA3NM8VpnnctRAMICgriq6++YvLkyUybNo2AgABuvfVWBg8e3GhWyL/gggtYt24djzzyCE8++SQxMTE8/fTT/PPPP7WaOQgVLSFPPvlkleOtW7dm/PjxjB49GrPZzOzZs3n88cfdi9fOmTPHPdM1JiaGm266ie+//5733nsPrVZL+/btWblyJSNHjgQqJk9s2bKFDz/8kMzMTPz8/OjVqxcffPDBSScENMTnYDab+f7777n//vuZP38+ZrOZW265hSuvvJIrrrii1vX8t/XqmNGjRxMdHc2WLVt4+umnWb16NW+++SZBQUHEx8dXWldu9OjRZGRk8M477/DNN9/QsWNH3n//fT7++ONGt4fxnDlzMJvNJCQk8N1339GnTx++/fZbLrrookqzpk+XyWRi4sSJzJgxg59++olBgwbV+jMfP348O3bs4N133+Xll1+mRYsWDB8+HLVazWeffcbLL7/MsmXL+PTTTzGbzcTFxfHggw/Stm3bM307mr19GUU4XQoXz/2p0nGbw4W/uWIy2sGsEoa89PNJ67l3YGumXFmRBJ7Y7dshArrF+HPR7B9Y81c6N/SsOqGsOVApjak5QQjhESNGjGD37t0cOHDg1IWFOAMFBQUEBATw7LPP8sQTT3g6HNGAWk5ZU2lW7Jc703noox18O2kAmv+02JoNGkJ9jNgcLpLzLNVV5xZg1hHkXfPM+Ktf/41+bYJ5vA4tgE2BtNgJ0cyUlZVVmil54MAB1q5dW+NsTCHq6r8/awCvvPIKULG9l2he4iN9cboUckts9GoVWG0ZvVZNm9DqZ7zXRqnVweFcC9d29+wex54kiZ0QzUxcXByjR48mLi6Ow4cP89Zbb6HX63nsscc8HZpoYj766COWLFnC0KFD8fb25rfffmPFihVcdtll9OvXz9PhiQZQanWQlHt8IkRKnoXd6YX4m/XEhXgzolskD6/cwbRhHYiP9CO31MaGgzl0iPDhkvZhp/16z63Zw+AOYUT5m8gqLufl9QfQqFVc3TXy1Bc3UdIVK0QzM2bMGH788UcyMjIwGAz06dOH559/nvPPP9/ToYkmZvv27Tz22GPs2LGDoqIiwsLCGDlyJM8++2yN6xCKc9vGQ7nclLCpyvGR50czb1RX7E4X8384yOrtqWQWlRNg1tM91p9Jl7alffjJF8WuzsTl29mSmEeBxU6gl54eLQN49PJ2tAjyqo/bOSdJYieEEEII0UTIOnZCCCGEEE2EJHZCCCGEEE2ETJ5oQA6Hgz///JOwsLAqG1YLIYQQouG4XC4yMzPp3r07Wm3zSXeaz516wJ9//kmvXr08HYYQQgjRbG3ZsoWePXt6OoyzRhK7BhQWVjF1e8uWLURERHg4GiGEEKL5OHLkCL169XJ/FzcXktg1oGPdrxEREURHR3s4GiGEEKL5aW5DoZrX3QohhBBCNGGS2AkhhBBCNBGS2AkhhBBCNBGS2AkhhBBCNBGNYvJE3gcfkLdoMY6cHAzt2xM+7QlMXbpUWzZ/5UoKP/8C64EDABjjOxI6aVKl8o6cHLLmzqN0wwacxcWYe/QgfNoT6Fu2dJc58tR0SjduxJGVhdpsxtS9O6GPTMYQFwdAwepPOfK//1Ubw3kbfkMbFFRPdy+EEEIIUT88ntgVrV1L1uw5hM+YgalrF/KWLiN53F20Xre22uTJsmUrvsOGYu7eHZXBQG7CQpLvHEfcV1+iCwtDURRSJ0wEnZboN99A7eVN3pIlHB47ltZffYXabAbAGB+P3/Cr0EZE4iwsIOf1N0i+cxxtvluPSqPBd+iVePe/qNJrp0/9H4rVKkmdEEIIIRolj3fF5i5Ziv/11+M/8joMbdoQPnMGaqORglWrqy0fNfdFAm++GWOHDhji4oh49hlwuSjduBEAW1ISZTt3EjF9OqbOnTHEtSJ8xnSUciuFa9a46wm4YRTmnj3RR0dhio8n5KEHcRw5gj0tDQC10Yg2JMT9QKOhdPNm/P9vZMO/KUIIIYQQdeDRxE6x2SjfvRuvvn3cx1RqNV59+lC2Y0et6nCVlaM4HGj8/I7Waa+ox2CoVKdKr6ds2/bq67BYKFy9Gl10NLrw8GrLFH72OWqjEZ/LL68xFqvVSlFRkftRXFxcq3sQQgghhKgPHk3sHPkF4HSi+U/XpiY4CEdOTq3qyJo3F21oKF59+wJgiGuFNjKCrJdexllYiGKzkZOQgCMjA0d2dqVr85YvZ+/5F7Dv/Aso+eVXYhcvQqXXV/s6BatW4XvVMNRGY42xzJo1Cz8/P/ejY8eOtboHIYQQQoj64PGu2DORsyCBorXriH59PuqjLXQqnY7o1+ZjS0pi/4W92dv9fCybt+A1oD/8Z/Vpv+HDiVu9ihbvLUPfsiVpD03CZbVWeR3Ln39iO3QI/5H/d9J4pk6dSmFhofuxZ8+e+rtZIYQQQohT8OjkCW2AP2g0OHNzKx135uSiDQ4+6bW5ixaTm5BA7OLFGNu1q3TO1CmeuM8+xVlcjGK3ow0MJHHUDZg6xVcqp/HxQePjg75lS0xdu7Lvwt4Ur/8Ov6uGVSpX8MknGDp0qHL9fxkMBgwndAEXFRWdtLwQQgghRH3yaIudSq/HGB9P6cZN7mOKy0Xppk2YunWr8brchQvJeestYhMWYOrcqcZyGh8ftIGB2JKSKN+1C+9LBtdYVgFQFBSbrdJxV2kpxeu+xn+kTJoQQgghmqrN/+Zy55Kt9HruO1pOWcM3uzNOec3GQ7kMe+1X2j6xjoEv/sjHf6SchUhPzuPLnQSNvoP0KVMxduqEqUtn8pYuw1VWhv911wKQ/vjjaEPDCJ38MAA5CQnkvDafyLlz0UVFucfNqc1m1F5eABR9/TWagEB0kRFY9+8n87nn8Rk8GO+L+gFgS0mhaO06vPr1QxsYgD0jk9yEBNQGA94DB1SKr2jdOhSnE7+rh5+tt0QIIYQQZ5nF7qRDhC/X94jh3ve3nbJ8Sp6FsUu2csuFsbx6Yzc2HMxlyuq/CfU1MrBtyFmIuHoeT+x8hw7FkZdP9vzXcGbnYOjQgdiEBe6uWHv6EVAdb1gsWPEhit1O2oMPVqoneMIEQu6fCIAjK5vM2XNw5OaiDQnG75prCLnvPndZld6AZdsf5C1bhrOoCG1QEOYePWixYkWVNeoKPlmFz6WXovH1bai34LRYbA4Kd+9FFx2F2uxVpzrMeg1GnaaeIxNCCCHOXRe3C+XidqG1Lv/+5sPEBJqYdlXFRMk2oT5sTcpj0W+JzTuxAwi89RYCb72l2nMt3ltW6XmbH74/dX2330bg7bfVeF4XFkrsggW1iq3lhytqVe5smfP0UpY6woHDda7DpNOwenxfOkQ0jmRVCCGEaCjFxcWVxrz/dzx8Xf15uIB+bSrPBxjQNoRnvvTsxMlzelZsc6QJOfmkktooszvZmVJw5sEIIYQQjVzHjh0rLUU2a9aseqk3u8RKsHflBDHE20Cx1UG53Vkvr1EXjaLFTtTeE/dcwQ1XXonjSAZhT04j8KabTuv6Bz/awZc70ym1ee6HTgghhDhb9uzZQ1RUlPt5fbTWNWbSYneO0RgNhNx5J2oUChYtQuV0oFarav3wNlSMrbNYHR6+EyGEEKLh+fj44Ovr637UV2IX4m0gp6Ty2rfZJVZ8DFqPjmOXxO4c5P9/I9EEB2NPT6fwy69O61qTrqKR1uLBZmIhhBDiXNe9hT+/H6y8Du9vB3Lo3iLAQxFVkMTuHKQ2GgkafQcAuQsWoDhrn6R5SYudEEIIUUWp1cHu9EJ2pxcCFcuZ7E4vJK2gDIA5X+/l4Y92uMvfemELkvMszFr7DwezSnhvYxJr/j7CnRe18kT4bjLG7hzlf+NN5CQsxJaURPG33+J75ZW1us6sr/jIZYydEEIIcdxfqYXclHB8w4Rn1/wDwMjzo5k3qitZRVZ3kgcQE2hm8eiePPPVHt7dkES4n5HZ13X26FInIIndOUvj7UXgrbeS88Yb5LyzAJ8rrkClUp3yOrO+osWuTBI7IYQQwq1P6yCSZg+r8fy8UV2rvWbtg/0bMqzTJl2x57DA225FbTZj3buXkp9+qtU1xxK7Upt0xQohhBBNjSR25zCNvz/+N90IQO7b76AoyimvOdYVa5EWOyGEEKLJkcTuHBc0ejQqvZ6ynTuxbN58yvLmY5MnpMVOCCGEaHIksTvHaUNC8P+//wMg5+13Tlne61iLnVVa7IQQQoimRhK7JiBo3J2g1WLZtImyHTtOWvbYGDvpihVCCCGaHknsmgBdZCR+V18NQM47C05aViZPCCGEEE2XJHZNRNBd40ClouTHHynft6/Gcl6G45MnajPZQgghhBDnDknsmghDq1b4XHE5ALnv1DzWznS0xc7pUrA5XWclNiGEEEKcHZLYNSHB99wDQNG6r7EmJlZbxnzCxsQygUIIIYRoWiSxa0KM7dvjPWgQKAq5CQurLaPVqNFrKz52i10SOyGEEKIpkcSuiQm+t6LVrvCLL7CnpVVbxuvYzFirTKAQQgghmhJJ7JoYU7dumHv3BoeD3EWLqy1zbPeJUlnyRAghhGhSJLFrgo612hV88gmO7Owq54+vZSctdkIIIURTIoldE2S+8EJMXbui2GzkLllS9bxBdp8QQgghmiJJ7JoglUpF0LFWuxUf4iwoqHT+2MxYWaRYCCGEaFoksWuivAcNwtC+PS6Lhbz3P6h0zstQkdiVyRg7IYQQokmRxK6JUqlUBN9zNwB5772Hs6TUfU4mTwghhBBNkyR2TZjPZZehb9ECV2EhBStXuo8fmzxRJl2xQgghRJMiiV0TptJoKvaQBfLefReXzQZIi50QQgjRVEli18T5XX012vBwHNnZFH76GXB8jJ0sUCyEEEI0LZLYNXEqvZ6gsWMAyF24EMXhwORex05a7IQQQoimRBK7ZsD///4PTUAA9pQUitZ9jdfRrlhJ7IQQQoimRRK7ZkBtNhN4x+0A5C5YgElX8bHLzhNCCCFE0yKJXTMRcPPNqL28sB44gPrAPkAmTwghhBBNjSR2zYTG15eAm28GwPHNWkBa7IQQQoimRhK7ZiTwjttRGQyoD+4HZIydEEII0dRIYteMaIOD8f+//8PksAJgsUpiJ4QQQjQlWk8HkPfBB+QtWowjJwdD+/aET3sCU5cu1ZbNX7mSws+/wHrgAADG+I6ETppUqbwjJ4esufMo3bABZ3Ex5h49CJ/2BPqWLd1ljjw1ndKNG3FkZaE2mzF1707oI5MxxMVVer2C1Z+St2QJtqQk1N7e+F5xOeFPPVX/b8JZFDR2DMavvgegtMzq4WiEEEIIUZ882mJXtHYtWbPnEDxhAq1Wr8LYrh3J4+7CkZtbbXnLlq34DhtKi6VLaPnhCnThESTfOQ57ZiYAiqKQOmEittQUot98g1arV6OLjOTw2LG4LBZ3Pcb4eCKff464NWuIWZgAikLyneNQnMdbsHLfXUL2K68QdNddxH31JbHvLsbroosa9g05C3RRUYRePBCo6IpVFMXDEQkhhBCivqgUD36zJ466AVOnToQ/9SQAisvFwUEXE3DrrQTffdcpr1ecTvb3upCwJ6fhP2IE1sRE/r1yKHFffoHhvPPcdR64qD8hkx4i4Prrq62nfN8+Eq8ZQetvv0EfG4uzsJADAwcR89abePXpU+f7S01NJSYmhpSUFKKjo+tcT33L2XuAHksqxtn9dWsrfDt19HBEQgghRP1qrN/BDc1jXbGKzUb57t2VEjiVWo1Xnz6U7dhRqzpcZeUoDgcaP7+jddor6jEYKtWp0usp27a92sTOZbFQuHo1uuhodOHhAJT+/ju4XNgzMzk0dBiu0lJM3bsT9vhj6CIiaozHarVitR7v3iwuLq7VfZxt/ue1BioSu4ULviTiVu861dM7LohWwV71GJkQQgghzoTHEjtHfgE4nWiCgiod1wQHYU1MrFUdWfPmog0NxatvXwAMca3QRkaQ9dLLRMycgdpkInfpUhwZGTiysytdm7d8OVlz56FYLOhbtSJ28SJUej0AtpRUFEUh950FhP3vf2h8vMl69VWSx95J3Oefucv916xZs5g5c+ZpvhNnn1ajxkunptTu4jVzJ1j9d53qaRlk5qdHL67n6IQQQghRVx6fPFFXOQsSKFq7jhbLlqI+2kKn0umIfm0+R6ZNY/+FvUGjwatPH7wG9If/dDj7DR+Od9++OLKzyV38LmkPTaLFiuUVdblcYLcT9sQTeF/UD4CoefM4cFF/Sjdvwbt/9WPtpk6dysMPP+x+npaWRseOjbObc8Y1nfhy1U/Y09NR+/tjvuCCWl9rdbj4ZX82aQVlDRihEEIIIU6XxxI7bYA/aDQ4/zNRwpmTizY4+KTX5i5aTG5CArGLF2Ns167SOVOneOI++xRncTGK3Y42MPDoWL74SuU0Pj5ofHzQt2yJqWtX9l3Ym+L13+F31TC0ISEAGNq0Ph5vYGDFfqtH0muMy2AwYDihG7ioqOik9+FJ1/eIYUT0pRy67HIUm42Y/1uAd//+tbq2sMxO15nfYncqWB1ODFpNA0crhBBCiNrw2KxYlV6PMT6e0o2b3McUl4vSTZswdetW43W5CxeS89ZbxCYswNS5U43lND4+aAMDsSUlUb5rF96XDK6xrAKgKCg2GwCm87sDYDuhS9hZUIAzPx9dZFTtbvAcoAsPd+9GkfXyyyguV62u89IfT+RKZS08IYQQotHw6HInQaPvoODjjyn49DOshw6RMWMmrrIy/K+7FoD0xx8na95L7vI5CQlkv/oaEc89hy4qCkd2No7sbFylpe4yRV9/TenmLdhSUij+/nuSx96Jz+DB7i5VW0oKOe8soGzXbuzp6Vi2/0nagw+hNhjwHjgAAEOrVngPHkzm889j2f4n5fv3kz5lKvq4Vnhd2OssvkMNL+ieu1GbzVj3/EPxt9/W6hqtRo1BW/GjU2qVbcmEEEKIxsKjY+x8hw7FkZdP9vzXcGbnYOjQgdiEBe6uWHv6EVAdzz0LVnyIYreT9uCDleoJnjCBkPsnAuDIyiZz9hwcubloQ4Lxu+YaQu67z11WpTdg2fYHecuW4SwqQhsUhLlHD1qsWIH2hIkckXNmkzlrFin33otKpcLcqyexCQmodLqGfEvOOm1AAIFjxpDzxhtkv/oaPkOGoNKe+sfC26DF6rBRKvvNCiGEEI2GR9exa+rOlTV0nCUlHBpyKc6CAiKeexb/kSNPec2AF34kOc/Cqvv6cEGLwLMQpRBCCFF758p3cH2TvWIFGm9vgu65B4Ds19/AZT31VmNehopWvRIZYyeEEEI0GpLYCQACbroRbVgYjiNHKPjoo1OW9zZUTKCQMXZCCCFE4yGJnQBAbTQSPGE8ADlvv4OzpPSk5Y+32EliJ4QQQjQWktgJN/9rr0XXIhZnXh55y5aetOyxxE5a7IQQQojGQxI74abS6Qh54AEA8ha/iyM/v8ay3npJ7IQQQojGRhI7UYnvlVdiaN8eV0kJuQsX1lhOJk8IIYQQjY8kdqISlVpNyEMV6wTmv/8B9sysasvJ5AkhhBCi8ZHETlThPXAgpu7dUaxWct56s9oyMsZOCCGEaHwksRNVqFQqQh+eBEDBJ6uwJSdXKWOWWbFCCCFEoyOJnaiWuWdPvC66CBwOsue/XuX8sa5Yi03G2AkhhBCNhSR2okYhkx4CoOirryjft7/SOS+9tNgJIYQQjY0kdqJGpvh4fK64AhSF7FdfrXTOW8bYCSGEEI2OJHbipEIeuB/Uakp++AHLn3+6j8vkCSGEEKLxkcROnJQhLg6/a0cAkP3yKyiKAsiWYkIIIURjJImdOKWQCRNQ6XRYtmyh9PffgRO6Ym1Od7InhBBCCM+SxE6cki4yEv+bbgSOt9p5HZ0V63QpWB0uT4YnhBBCiKMksRO1EnzPPajMZsp37aJ4/Xr3rFiQ7lghhBCisZDETtSKNiiIwDtuByD71ddQKS7MetlWTAghhGhMJLETtRY0ZgxqPz9shw5R+MWXMoFCCCGEaGQksRO1pvH1JfiucQDkzJ+Pl7vFTnafEEIIIRoDSezEaQm45Ra0ISHY09MxlhYB0hUrhBBCNBaS2InTojaZCB5/HwC6zHRAumKFEEKIxkISO3Ha/EeORBcTg6msBACLTRI7IYQQojGQxE6cNpVeT8j9EzE5rAAUF5R4OCIhhBBCgCR2oo58hw3D22wEIHvjFg9HI4QQQgiQxE7UkUqjIah7ZwBy/96DLTnZwxEJIYQQQhI7UWcBbVoCYFHryJw9x7PBCCGEEALtqYsIUT1vgw6Av0LaMCfrAN5vrUcXEXFadfgYtYzrH0egl74hQhRCCCGaFUnsRJ2F+hoASPUOJdU7FA7b4PDh067H26hl/KA29R2eEEIIcVqWbUzinZ//JbvESocIX2ZeHU+3GP8ayy/6LZEPNh0mraCMQC89V3aK4LEr2mHUac5e0P8hiZ2osys6hfP0NfHk5BaT98EHKGVlePXrh6lbt1pd//uhHLYm5ZNbYmvYQIUQQohT+HJnOs9+9Q/PXtuJ7jH+LN6QyO2LNvPDI4MI9jZUKf/5jjTmfL2XF/+vC+fHBpCYU8ojH+9EpYInr+rogTuoIImdqDODVsPtfVoCUFDegyPTnkSd+jutx6xDGxx8yuv1WjVbk/IpLrc3cKRCCCHEyS38LZEbe8UwqkcMAM+N6MwPe7NY+UdKtb1K2w7n06NFANd0iwIgJtDM1V0j2ZFScDbDrkImT4h64XfddRjj43GVlJD18su1usbbUPF3hexcIYQQoqEUFxdTVFTkflit1iplbA4Xu9IK6dfmeKOEWq2iX5tgth8uqLbeC1oE8HdaoTuRS8618OO+LC5uH9oQt1FrktiJeqFSqwl74gkACletpuzvv095zbHErrhcEjshhBANo2PHjvj5+bkfs2bNqlIm32LD6VKqdLmGeBvILqmaCAJc0y2Khy9ty/Vv/06b/61lwIs/0jsuiAkXe3bMeKPois374APyFi3GkZODoX17wqc9galLl2rL5q9cSeHnX2A9cAAAY3xHQidNqlTekZND1tx5lG7YgLO4GHOPHoRPewJ9y5buMkeemk7pxo04srJQm82Yuncn9JHJGOLi3GX+ad+hyutHzpuL37Bh9XTnTYv5/O74XXM1hZ9/Qeazz9FixXJU6pr/dvAxSmInhBCiYe3Zs4eoqCj3c4Oh6ni5uth4KJc3fjzEM9d0olusP0k5Fp7+cjevfX+ABwafVy+vURceb7ErWruWrNlzCJ4wgVarV2Fs147kcXfhyM2ttrxly1Z8hw2lxdIltPxwBbrwCJLvHIc9MxMARVFInTARW2oK0W++QavVq9FFRnJ47FhcFou7HmN8PJHPP0fcmjXELEwARSH5znEoTmel14t4/nnO+/UX98NnyJCGezOagJCHJ6MymynbuZPCL744aVlvo3TFCiGEaFg+Pj74+vq6H9UldgFmPRq1ipz/tM5ll1gJqWbiBMBL6/dx3flR3NgrlvbhvlzRKZxHr2jHmz8dxOVSGuReasPjiV3ukqX4X389/iOvw9CmDeEzZ6A2GilYtbra8lFzXyTw5psxduiAIS6OiGefAZeL0o0bAbAlJVG2cycR06dj6twZQ1wrwmdMRym3UrhmjbuegBtGYe7ZE310FKb4eEIeehDHkSPY09IqvZ7G1wdtSIj7oa6nTL+p0oWFEnzfvQBkzZuHs6S0xrK+xop18EqkxU4IIYQH6bVqOkX58fvBHPcxl0vh94O5nN/Cv9pryuxOVKrKx9RHD3gurfNwYqfYbJTv3o1X3z7uYyq1Gq8+fSjbsaNWdbjKylEcDjR+fkfrrJhhqTohAVOp1aj0esq2ba++DouFwtWr0UVHowsPr3Qu4+ln2N+7D4nXj6Jg1SoUxZMf17kh8I470LWIxZmdQ+7bb9VY7vgYO5kVK4QQwrPGXdSKFVtT+GRbKgezinnis11YbA6uv6BiluzDH+1gztd73eUHtw/jg03JfLEznZQ8C78eyOal9fsZ3CEMjVpV08s0OI+OsXPkF4DTiSYoqNJxTXAQ1sTEWtWRNW8u2tBQvPr2BcAQ1wptZARZL71MxMwZqE0mcpcuxZGRgSM7u9K1ecuXkzV3HorFgr5VK2IXL0KlP74DQvAD9+PVuzdqo5GSDRvImPk0rlILgbffVm0sVqu10myb4uLiWt1DU6PW6wmbMoXU+8aTu3QZfiNHYmjVqkq5Y12xpTYnTpfi0V8EIYQQzdvwrpHkldp4ef1+soutdIj0ZenYXoT4VDQUpRWUoTqhie7+S9qgUsG8b/eRUVhOkJeewR3CeOTydp66BaCRTJ6oq5wFCRStXUeLZUvdXaQqnY7o1+ZzZNo09l/YGzQavPr0wWtA/ypto37Dh+Pdty+O7GxyF79L2kOTaLFiubuukPHj3WWNHTuilJWRu3hxjYndrFmzmDlzZsPc7DnGe9AgvAb0p/SXX8mcPZvYd96pUubY5AmAUpvD3TUrhBBCeMIdfVtyR9+W1Z776J4+lZ5rNWoeGtKWh4a0PQuR1Z5Hu2K1Af6g0eD8z0QJZ07uKRe4zV20mNyEBGIXLsTYrnJ2bOoUT9xnn9J26xbO+/UXYhcm4CwoRB8TXamcxscHfcuWmHv2JPrVV7AmJlK8/rsaX9PYpQuOjAxctup3Spg6dSqFhYXux549e056D02ZSqUibMpU0Oko/fkXin/6qUoZg1aDXlPxIygzY4UQQogz59HETqXXY4yPp3TjJvcxxeWidNOmk25LlbtwITlvvUVswgJMnTvVWE7j44M2MBBbUhLlu3bhfcngGssqAIqCUkPSBmDduxe1nx9qffUb1hsMhkozb3x8fGqsqzkwxLVyt25mzZpdbULsnhkriZ0QQghxxjzeFRs0+g7Sp0zF2KkTpi6dyVu6DFdZGf7XXQtA+uOPow0NI3TywwDkJCSQ89p8IufORRcV5R43pzabUXt5AVD09ddoAgLRRUZg3b+fzOeex2fwYLwv6geALSWForXr8OrXD21gAPaMTHITElAbDHgPHABA8Q8/4sjNwdS1K2qDgdLffyfnnQUEjRlztt+ic1rwffdR+PkX2A4fJn/ZMoLGjat03seoJa/URolVJlAIIYQQZ8rjiZ3v0KE48vLJnv8azuwcDB06EJuwwN0Va08/AqrjDYsFKz5EsdtJe/DBSvUET5hAyP0TAXBkZZM5ew6O3Fy0IcH4XXMNIffd5y6r0huwbPuDvGXLcBYVoQ0KwtyjBy1WrEB7dCKHSqclf/kKsmbNRgH0sbGEPf44/qOub+B3pGnReHsTOnkyR6ZOJefNt/C9+mp0oce3Wzk2M7ZIWuyEEEKIM6ZSZP2OBpOamkpMTAwpKSlER0ef+oImSnG5SLrpJsp3/oXfNdcQOWe2+9wN72xkc2Ie82/qzvCukR6MUgghRFPSXL+DPb5AsWj6VGo14cf2kf38cyx//uk+53NskWLZfUIIIYQ4Y5LYibPC1KULftddB0Dmc8+juFzAifvFyhg7IYQQ4kxJYifOmtCHJ6H29qZ81y4KP/0UOJ7YyaxYIYQQ4sxJYifOGm1wMMFHF33OmvcSzqKi49uKSVesEEIIccYksRNnVeCtt6Bv1QpnXh45b7zpXsdOFigWQgghzpwkduKsUun1hP1vKgB5H3yAqbgAkK5YIYQQoj5IYifOOu/+/fG++GJwOHCu+wqQWbFCCCFEfZDETnhE2JTHUel0aPb8DcisWCGEEKI+SGInPELfogWBY8bgZS8HJLETQggh6oMkdsJjgu+5Gx8fMwBF+cUejkYIIYQ490liJzxG7eVF7J23A1BsdWLPyPBwREIIIcS5TRI74VERV14GgFWrJ33uSx6ORgghhDi3SWInPMrHpHP/f+Y332HZts2D0QghhBDnNknshEfpNGqMuoofQ4vOSMazz6E4ZOkTIYQQoi60ng5ACG+DjnK7lb9iOpOZncaBt1bgO3ToadVxXpg3wd6GBopQCCGEODdIYic8zteoJafEyksdrq44kAYkbDqtOoK89GycOhi9VhqhhRBCNF+S2AmPG9c/jqW/J+FSFOzpabgsZahNJnRRUbW6/kBWCbmlNvJKbYT7GRs4WiGEEKLxksROeNzNF8Zy84WxANhSUvj36mtQysoIf3omAaNGnfL67k9/S77FTlG5XRI7IYQQzZr0W4lGRR8TQ8gDDwCQ9eJc7JlZp7zG9+jM2qIy2b1CCCFE8yaJnWh0Am+/DWPnzriKi8l45mkURTlpeV/j0cROtiUTQgjRzEliJxodlUZDxLPPgFZLyXffU/zNtyct72uqGFFQVCbLpAghhGjeJLETjZKxXTuC774LgIxnnsFZUFBjWWmxE0IIISpIYicaraB770XfujXO3Fwy57xQYzl3Yidj7IQQQjRzktiJRkut1xPxzDOgUlH46aeUbNhQbbljXbHF5dIVK4QQonmTxE40aubzuxNw880AZDw1HZfFUqWMdMUKIYQQFSSxE41eyKRJaCMisKelkf3qq1XOH1/uRFrshBBCNG+S2IlGT+PtRcTMGQDkLXuPsp07K513z4qVFjshhBDNnCR24pzgPWAAvlcPB0XhyLQnUWw29zmZPCGEEEJUkMROnDPCpk5FExCA9cABchIS3Md93GPspCtWCCFE8yaJnThnaAMCCHviCQBy3n4H68GDwIkLFEuLnRBCiOZNEjtxTvEdNhTvgQPBbufIE9NQnM5Ks2JPtf2YEEII0ZRJYifOKSqVivAZ01F7eVG2cyf5Hyx3z4q1OxXK7S4PRyiEEEJ4jiR24pyji4gg9JHJAGS98gr67AzUqopzMjNWCCFEcyaJnTgn+d9wA6YeF6BYLGTMmCkzY4UQQggaSWKX98EHHLxkMHu7dCVx1A2U/fVXjWXzV64k6ZZb2dfrQvb1upDDY8ZUKe/IySF9ylQO9B/A3m7dSR53F7akpEpljjw1nYOXXsbert3Y36cvKeMnYP3332pf05Gfz4GBg/infQecRUVnfL/izKnUaiKefgaVXk/pb7/h7apY/kRa7IQQQjRnHk/sitauJWv2HIInTKDV6lUY27UjedxdOHJzqy1v2bIV32FDabF0CS0/XIEuPILkO8dhz8wEQFEUUidMxJaaQvSbb9Bq9Wp0kZEcHju20nZUxvh4Ip9/jrg1a4hZmACKQvKd41CcziqveWTakxjatW2YN0DUmSGuFcHjxwNgzMkAZPcJIYQQzZvHE7vcJUvxv/56/Edeh6FNG8JnzkBtNFKwanW15aPmvkjgzTdj7NABQ1wcEc8+Ay4XpRs3AmBLSqJs504ipk/H1LkzhrhWhM+YjlJupXDNGnc9ATeMwtyzJ/roKEzx8YQ89CCOI0ewp6VVer38FStwFRURNHZsw70Jos6C7hyLoX17vMpLAGmxE0II0bx5NLFTbDbKd+/Gq28f9zGVWo1Xnz6U7dhRqzpcZeUoDgcaP7+jdVZ8sasMhkp1qvR6yrZtr74Oi4XC1avRRUejCw93H7cePEj2m28SOWc2qE79VlmtVoqKityP4uLiWt2DqDuVTkfEs8/ibS8HIGvHbg9HJIQQQniORxM7R34BOJ1ogoIqHdcEB+HIyalVHVnz5qINDcWrb1+gontOGxlB1ksv4ywsRLHZyElIwJGRgSM7u9K1ecuXs/f8C9h3/gWU/PIrsYsXodLrAXDZbKRNfoSwRx9FFxlZq1hmzZqFn5+f+9GxY8daXSfOjKlTPIGtogFI//Z7nJJQCyGEaKY83hV7JnIWJFC0dh3Rr89HfbSFTqXTEf3afGxJSey/sDd7u5+PZfMWvAb0B3Xl2/UbPpy41ato8d4y9C1bkvbQJFxWKwDZ817C0DoOv6uvrnU8U6dOpbCw0P3Ys2dP/d2sOKnQ7l0AKLY6yZo7z8PRCCGEEJ6h9eiLB/iDRoPzPxMlnDm5aIODT3pt7qLF5CYkELt4McZ27SqdM3WKJ+6zT3EWF6PY7WgDA0kcdQOmTvGVyml8fND4+KBv2RJT167su7A3xeu/w++qYZRu3ox1/36KvulUUfjojgb7+/Ql+J57CHng/ioxGQwGDCd0ARfJDNqzxs/HBECp1kjBRx/hO3QoXhf28nBUQgghxNnl0cROpddjjI+ndOMmfIYMAUBxuSjdtImAW26p8brchQvJefsdYhcmYOrcqcZyGh8foGJCRfmuXYQ88ECNZRUARUGxVSybEf3aq7jKy93ny//exZEnnqDF+++hj409jbsUZ4OvseJH2RbXFnZC+tQpxH32GRpfXw9HJoQQQpxcud2JUaepl7o8mtgBBI2+g/QpUzF26oSpS2fyli7DVVaG/3XXApD++ONoQ8MInfwwADkJCeS8Np/IuXPRRUW5x82pzWbUXl4AFH39NZqAQHSREVj37yfzuefxGTwY74v6AWBLSaFo7Tq8+vVDGxiAPSOT3IQE1AYD3gMHAFRJ3pz5BQAYWreWZKEROratmKVFa+wt4rCkpXFo5nNEPPcsKpWqVnVo1ap6+8USQgghTsblUnj9x4N8sPkwOSU2fpw8iNggM/O+3Ud0gIkbetatEcnjiZ3v0KE48vLJnv8azuwcDB06EJuwwN0Va08/UmlGasGKD1HsdtIefLBSPcETJhBy/0QAHFnZZM6egyM3F21IMH7XXEPIffe5y6r0Bizb/iBv2TKcRUVog4Iw9+hBixUr0P5nIoc4NxzbeWJjUgFXdx8P3Y+emPFtrevQqFXMurYzo3rGNECEQgghxHHzfzjIqu2pTL2yA1NWH99ooW2YD4s3JJ67iR1A4K23EHhr9V2vLd5bVul5mx++P3V9t99G4O231XheFxZK7IIFpxWj14W96LD3n9O6Rpw9XWP8CfExkF1srXMdTpfCzweyJbETQgjR4Fb/mcqs6zrTr00wT3z6t/t4hwhfDmWV1LneRpHYCXGmQnwMbJo6GLvTVXHA4eDwneMo37EDY9cutFi8GLQ1/7h/sTOdxz75i0KLLHAshBCi4WUUltMiyFzluKIoOFxKnes9p5c7EeJEmqNj5Iw6DUaTgVYvzMZoNuL6czvFCQuOn6vmEexdsX5hYZkkdkIIIRreeWHebE3Kq3J87d8ZxEfWfSy/JHaiydJHRxE+YwYAOW+/jWXbthrL+pkqEruCMtvZCE0IIUQz98Al5/HU57t566dDuBT4evcRpqz6izd+PMgDg8+rc72S2Ikmze+qYfhdczW4XKQ/+liNu1L4mysmXxRIV6wQQoiz4LL4cBbd0ZMNB3Mw6zW8tH4/B7NKWHhHD/qfF1LnemWMnWjywp58Esu27dhTU8mY+TRRc1+sUsb/6HIpxeUOnC4Fjbp2S6QIIYQQddWrVSDvj7uwXuuUFjvR5Gm8vYl88QXQaCj66isKv/iiSplj6+ABFMk4OyGEEA2s/ws/kF9adfhPYZmd/i/8UOd6JbETzYK5e3eCx1esZZgx82lsqamVzus0arwNFQ3YBZLYCSGEaGCp+WU4laqzX20OF5mFdV+6S7piRbMRfM89lG74nbLt20l/5FFavP8eqhOWQPEz6SixOiiw2AAvzwUqhBCiyVq/J9P9/7/sz8bHeLzHyOlS+P1QDtEBpjrXL4mdaDZUWi2RL7xA4ogRlO3YQc5bb7t3K4GKCRRpBWWy5IkQQogGc/d7fwCgAiZ/vLPSOZ1aTXSAiSeGdahz/ZLYiWZFHx1F+PTppD/6KDlvvYVXv36Yz6/Yf8zv6Dg7SeyEEEI0lMRZwwC4aM4PfDHxIgK99PVav4yxE82O3/Cr8L16+NElUB51L4EiS54IIYQ4W357/JJ6T+pAWuxEMxX+5JOUbduOPS2NjKefIerFF9yLFEuLnRBCiLPBYnOw+d880grKjm+JedSYfq3qVKckdqJZ0vj4EPniixy+7TaKvvwS7wH98TdXrPQtLXZCCCEa2q60QsYs2Uq5zYnF7sTfpCPPYsOk0xDkra9zYiddsaLZMp/fneD7ji+B4m2zALKtmBBCiIb3zFd7GNIhlJ3TL8OoVfPp+H5sePwSOkX58cTQuk+ekMRONGvB996DqXt3XCUlKF9+CsgCxUIIIRreniNFjOsfh1qtQq1WYXM6ifQ3MfXK9rzwzb461yuJnWjWVFotkS++gNrbG+PBvYB0xQohhGh4Oo0atapi+8pgbwNpBeUA+Bh1HDn6/3UhY+xEs6ePjiZ8+lP4zHkHgLz8Yg9HJIQQwhOWbUzinZ//JbvESocIX2ZeHU+3GP8ayxeW2Zn7zT6+3p1BocVOVICJp67qyMXtQ0/5WvGRvvyVWkCrYC8ubBXIS+v3k19qY/WfabQN96nzPUiLnRCA3/DhhPXpCUB+biHOkhIPRySEEOJs+nJnOs9+9Q8PDjmPNfdfRMcIH25ftJmckuq397I5XNy2aDOp+RbeuuV8vp88kFnXdSbM11ir13v08naE+BgAeOTydviZdEz7bBd5pVaev7ZTne9DWuyEOKr1Q+Nh/haK1QaOPP000S+84OmQhBBCnCULf0vkxl4xjOoRA8BzIzrzw94sVv6RwvhBbaqUX/lHCgUWO6vu64tOU9FOFhNorvXrdYn2d/9/sLeBZWN7ndkNHCUtdkIcFRQSAIBDoyV7zTcUfvmVhyMSQghxNtgcLnalFdKvTbD7mFqtol+bYLYfLqj2mu/+yeT8WH+e+nwXPZ5dz2Uv/8wbPx7E6VLOKJZdaYWMXbK1ztdLi50QR5l0GnQaFXanQrHeRMbMmZg6d0LfsqWnQxNCCFFHxcXFFBUVuZ8bDAYMBkOlMvkWG06XQrB35eMh3gYOZZdWW29ynoXf88sY0S2Sd0f3Iim3lCc/34Xd6eKhIW1PGtPP+7P57UA2Oo2aG3vGEhtk5mBWCXO+3sv3/2QyoG1IHe9WWuyEcFOpVO7dJ+xdLsBVUkLq/Q/gslg8HJkQQoi66tixI35+fu7HrFmz6qVeRYFgLz2zrutC52g/hneNZOLFbfhgc/JJr/toazKj393CJ9tSefvnQ1z75gY+/TOV697cQIiPgW8nDWDJmLp3y0qLnRAn8DfryCmxYrh/Epp//8J64ABHpj1J5Ly5qI5OSxdCCHHu2LNnD1FRUe7n/22tAwgw69GoVVUmSmSXWAnxrloeIMTHgE6jQqM+/t3QOtSb7GIrNocLvbb6trN3NyQx5Yr23DOwNev+PsL45dt5b+Nhvpk0gAg/U11usRJJ7IQ4gb9JB8DLW7MIGjWd0j/+gGwF4/Ofom/RolZ1tAn15uFL20oiKIQQjYCPjw++vr4nLaPXqukU5cfvB3O4PD4cAJdL4feDudzet/p/+3u0CODzHem4XArqo8ldYnYpoT6GGpM6gMO5FoZ2jgDgik7haNUq/je0Q70kdSCJnRCVxAaa+eNwPtsO51cciOhc8d9iYFdGreu5slMEHSNP/g+JEEKIxmPcRa2Y/PFOOkf70y3Gj0W/JWGxObj+gopZsg9/tIMwPyOPX9EegFt7t2DZxsPM/HI3d/RtSVJuKW/+dJDRfVue9HXKHU5Meg1QMQRIr1ET6lO7JVJqQxI7IU7wxLAO9GoViP3YrCZFofDTTyn762/U3l4E3X03mpP85ffWjwdJLywnu4Z1j4QQQjROw7tGkldq4+X1+8kuttIh0pelY3u515pLKyir1BMT6W9i6dhePPPVHq549VfCfY2M6deKewe2PuVrfbQ1BfPR5M7hUvhkWwoBXvpKZcb0a1Wn+1ApinJm83JFjVJTU4mJiSElJYXo6GhPhyPqyFVWRtKNN2Hdtw9T167EvrcMtV5fbdmbEzbx+6FcXr2xG9d0i6q2jBBCiIbXWL+D+83+gVON1FGp4NfHLqlT/dJiJ8QpqE0moue/RuL/XU/Zzp1kzppFxPTp1ZY99hdXXqntbIYohBDiHLFhSt0SttqS5U6EqAV9bCxRL74AKhUFKz6kYPWn1ZYLMFdMvsiXxE4IIYQHSGInRC15DxxI8MQJAGTMmEHZ7t1VygSaK1rs8i32sxqbEEIIAZLYCXFagu+7D+9Bg1BsNtLufwBHfn6l8+6uWIu02AkhhDj7JLET4jSo1GoiX5iDrkUs9vR00ic/guJ0us8HHGuxk65YIYQQHlCnxM5+5Aj2jONrepX99RcZzz9P/kcr6y0wIRorja8v0a/NR2UyUfr772S/+pr73LEWO+mKFUII4Ql1SuzSHnkUy+bNADiys0keeyflf/1N9iuvkP3GG/UaoBCNkbFdWyKefQaA3AULKFq/HjhhjJ202AkhhDiJ4nJ7tY8SqwObw1Xneuu03In1wAGMnbsAULTuawznnUfLFcsp+W0DGTNmEDJhwmnVl/fBB+QtWowjJwdD+/aET3sCU5cu1ZbNX7mSws+/wHrgAADG+I6ETppUqbwjJ4esufMo3bABZ3Ex5h49CJ/2BPqWLd1ljjw1ndKNG3FkZaE2mzF1707oI5MxxMVV1JGfT/qjj2Hdtw9nQQGaoCB8LrmEkIcnofH2Pq37E02T37BhlP/1N3lLl3JkylQMrVvj71+xFU2exYaiKLKtmBBCiGp1mfktJ/uGiPAzMfKCaB4afJ57y7LaqFOLneJwoDq6QGvpxo14X3IxAIa4Vjiys0+rrqK1a8maPYfgCRNotXoVxnbtSB53F47c3GrLW7ZsxXfYUFosXULLD1egC48g+c5x2DMzK2JTFFInTMSWmkL0m2/QavVqdJGRHB47FpfF4q7HGB9P5PPPEbdmDTELE0BRSL5znHu8lEqtxmfwJUS/+Satv15H5KznKd24kYzpM0737RJNWOgjkzH36IGrtJTU+x/Aj4ouWJvDRZndeYqrhRBCNFdz/68rYb5GJlzchgW39WDBbT2YcHEbwn2NPDuiMzf1imHJhkTe+vnQadVbp8TO0KYNBR99iOWPPyj9/Xe8+/cHwJGVhcbf/7Tqyl2yFP/rr8d/5HUY2rQhfOYM1EYjBatWV1s+au6LBN58M8YOHTDExVV0h7lclG7cCIAtKYmynTuJmD4dU+fOGOJaET5jOkq5lcI1a9z1BNwwCnPPnuijozDFxxPy0IM4jhzBnpYGgMbPj4CbbsLUuRO6qCi8+vQh4KabsGzbVod3TDRVKp2OqFdeRhsaiu3QIQpnPOXe/FkWKRZCCFGTVdtTeWJYByZf1o4hHcMY0jGMyZe143/DOvDVX+lMvOQ8Zlwdz6rtqadVb50Su9DJk8n/aCWHb78D32HDMLav2BC3+IcfMXXpXOt6FJuN8t278erbx31MpVbj1acPZTt21KoOV1k5isOBxs/vaJ0VLSYqg6FSnSq9nrJt26uvw2KhcPVqdNHR6MLDqy1jz8yieP16zD171hiL1WqlqKjI/SguLq7VPYhzmzY4mOjXXgWdjpJvv8VfqfgZzC+VCRRCCCGqt+1wPvGRflWOx0f6sT25Yimtni0DSS8oO61665TYeV3Yi7Ybf6ftxt+JfP4593H/UaMInzGj1vU48gvA6UQTFFTpuCY4CEdOTq3qyJo3F21oKF59+wIV3cHayAiyXnoZZ2Ehis1GTkICjoyMKt3EecuXs/f8C9h3/gWU/PIrsYsXubuYj0l7eDJ7u3Xn4MCBqL293QPmqzNr1iz8/Pzcj44dO9bqHsS5z9StG+FP/A8Ar7yKYQGylp0QQoiaRPqb+GhrSpXjH21NIdLPBEC+xYafSXda9dYpsXOVl6PYbO5WMntaGnlLl2JLTET7nyStIeUsSKBo7TqiX5+P+mgLnUqnI/q1+diSkth/YW/2dj8fy+YteA3oD+rKt+s3fDhxq1fR4r1l6Fu2JO2hSbis1kplwqZOodXqVUS/+Qa2lGQyZ8+uMZ6pU6dSWFjofuzZs6f+b1o0Wv433IDftdfiaysFICct08MRCSGEaKz+N7QDi39L5IpXfuHxT/7i8U/+4spXf2XxhkSeGNYBgJ2phVzVJfK06q3TrNjU8RPwuexSAm68EWdREYk33IhKq8WZn0/YlMcJuOmm2r14gD9oNDj/M1HCmZOLNjj4pNfmLlpMbkICsYsXY2zXrtI5U6d44j77FGdxMYrdjjYwkMRRN2DqFF+pnMbHB42PD/qWLTF17cq+C3tTvP47/K4adjzGkBC0ISEY4uLQ+Plx+JZbCb7vPnShoVViMhgMGE7oAi4qKqrV+yCaBpVKRfj0pwiYnABA4vsrcfU9z/1HhxBCCHHMpR3D+H7yQD7YnExiTgkAg9qFsOC2C4gJNANwW+8Wp11vnVrsyvfswXzBBQAUffMN2qAg2vzwPZFzZpP33vu1rkel12OMj6d04yb3McXlonTTJkzdutV4Xe7CheS89RaxCQswde5UYzmNjw/awEBsSUmU79qF9yWDayyrACgKiu0k3WeuinVljo3jE+K/1EYjkX0rxmHm5haR8UzNXfdCCCGat5hAM1OubM87t/Xgndt68PgV7d1JXV3VqcXOVV6O2ssLgNINv+Nz6aWo1GpMXbtiT08/rbqCRt9B+pSpGDt1wtSlM3lLl+EqK8P/umsBSH/8cbShYYROfhiAnIQEcl6bT+Tcueiiotzj5tRmszumoq+/RhMQiC4yAuv+/WQ+9zw+gwfjfVE/AGwpKRStXYdXv35oAwOwZ2SSm5CA2mDAe+AAAEp+/hlHTi7Gzp1Qm72wHjxA1otzMZ1/PvroqLq8baKZCA4JAHIpNnhR+MkqTJ06E3DjDZ4OSwghRCNTWGZnZ0oBuaXWY21HbiMviK5TnXVK7PSxsRR/9z0+lw6h9LffCLzjdgAcuXmoT3PxXt+hQ3Hk5ZM9/zWc2TkYOnQgNmGBuyvWnn4EVMcbFgtWfIhit5P24IOV6gmeMIGQ+ydWxJGVTebsOThyc9GGBON3zTWE3Hefu6xKb8Cy7Q/yli3DWVSENigIc48etFixwj1GUGUwUvDxx1hnz0ax2dCFh+Nz2aUE3XXX6b9holk5tq2YtVN32LmajGeeQRcVhXf/izwcmRBCiMbiuz2ZPPTRDkptDrwN2kqLFatUqjondipFUZTTvajo629Ie/RRcDrx6n0hsYsXA5DzzgIsf/xBbMKCOgXT1KSmphITE0NKSgrR0XX7gMS557M/03joox30bR3E3IOfUvj5F6i9vGjxwfvupYGEEEI0rMb+HXzx3J8Y1C6Exy5vj0mvqbd669Ri53vF5ZgvOB9HdjaGE76ovPr0xufSIfUWnBDnomMtdvkWOxHPPIM9IxPL5s2k3HMvLT/6sMa1EoUQQjQfGYXljOnbql6TOqhjYgfHZ4vaMzIA0IWH17i/qxDNSaC5IrE7mFXMZa9vhM53YAsYjGKzoZrzHfqoqCpL7/yXRq1i/MVtuLrr6U1zF0IIcW4Y0DaYv9IKiA06s8kS/1WnxE5xuch56y3y3l3i3n9V7eVF4JjRBN97L6pTfGkJ0ZTFBpkx6TSU2Z0cyKqYwo4xEIxHC+RYarz2RO9uSJTETgghmqhL2ocya+1eDmSW0D7cB62mcu50acewOtVbp8Qu++VXKFi1itDJD2M6/3wALNu2kfP6GyhWG6GTHqpTMEI0BX4mHT8+MojEnNJKx22JiWQ8/zzYbHgPHEjg2DFQabhshYNZxTz5+W5yS2TnCiGEaKqmrP4bgNd+OFDlnAr4d9awKsdro06JXeFnnxHx7DP4XHKJ+5ixXTt0YWFkzHxaEjvR7IX7GQn3M1Y+2DqIYvVEUidMhFWHCGnhT/DdVWdZRxy9LrfEWuWcEEKIpiGxjonbqdSpz9RZWIi+Vasqx/Wt4nAWFp5xUEI0VT6XXELY/yr2lM1+6SUK16ypUibIu2KMXqnNSbndeVbjE0IIcW6rU4udoX178j9YTvi0Jyodz//gAwz/2d5LCFFZ4G23Yk9NJW/pUo5MmYouLAxzjx7u894GLXqNGpvTRW6pjSh/kwejFUIIUV/e3ZDITb1iMeo0vLsh8aRlx/Sr2oBWG3VK7EIfmUzKvfdRunEjpm5dASjbsRPHkSPELHinToEI0ZyEPvYo9vQ0itd/R+qEibRYsQJDXMUvsUqlIshbz5HCcnJLrJLYCSFEE7Hot0RGdIvCqNOw6LeaEzuV6iwndl69etF63Tryly/H9u+/APhcOoSAUaPIeevtSq0PQoiqVBoNkS+8wOHRoynf+Rcp99xDy48+RBsYCHBCYicTKIQQoqn47fFLqv3/+lTndex0YaFVJkmU791LwapVRDzz9JnGJUSTpzaZiHnzTZJuuBF7Sgqp940ndukS1EYjQV4GAHJkAoUQQojTUOfETghx5rRBQcQseIekm26mbOdO0h99jKhXX3FPoMgtlRY7IYRoipwuhU+2pbDhYC65pVZcrsrnV9zdu071ykrCQniYIS6OmNfno9LpKF6/nqwX5xLsXdFiJ0ueCCFE0zTzy93M/HIPTkWhbZgPHSJ8Kz3qSlrshGgEzD17EvH886Q/+ih5776L8d44wCRj7IQQoon6cmc6b9x8Phe3D63Xek8rsUu9//6TnncWFZ9RMEI0Z37Dr8Kelkb2K6+gXfcFdL+BHOmKFUKIJkmnUdOinveJhdNM7NTePqc873fNNWcUkBDNWdA9d2NPS8Xvl10A5OTIgt9CCNEU3dU/jnc3JPH0NfGoVFW3l6yr00rsImc9X28vLISoSqVSEf7UU0RMnApA1pEc7Glp6KKiPByZEEKI+rQ1KY+N/+by0/4s2ob6oNVUTu7eua1uS8fJ5AkhGhmVTkeHp6YAUKA1c/iee3AWFXk4KiGEEPXJ16Tj8vhwLmwVRICXHh+jrtKjrmTyhBCNUEhoAAAOjZaCpDRSH3iQmAXvoNbrPRyZEEKIM+VwuugTF0T/tsGE+hjrtW5psROiETLqNHjpNQAU+Qdj2bSJ9MmTURwOD0cmhBDiTGk1ap747G9sDtepC58mSeyEaKSCjq5lp3v8yaNr3H1H+tT/ofx3FUshhBDnnK7R/uxOr/9hNtIVK0QjFeStJznPQmmrtnR79VVSH3iAoi+/RG0yET5zRr3OohJCCHF23danBc+t+YeMwnI6RflhPtpLc0xdFymWxE6IRurYfrFbEvMwt+uEZcpschYkwI878NG+gf8No06Z3IX5GmkXfvJlioQQQpx996/4E4AZX+52H1MBytH//jtrWJ3qlcROiEYqxKdiosTiDYks3pBYcbDvXRX/tQDvbq1VPV9M7EeXaP/6D1AIIUSd/frYxQ1SryR2QjRSN/SMZX9mCWU2Z6Xjzvw87BmZAOhCQ9EEBVV7fUq+heJyB/8cKZLETgghGpnogPrfdQIksROi0eoW48+q+/pWey5nQQLZL70EQNhTTxJ4881Vyjz2yU5W/pFKdrG1QeMUQghRdwcyi0krKMPuVCodv7RjWJ3qk8ROiHNQ8N134bKUkvv2O2Q+/Qxqkxn/a0dUKhPiUzFGL0sSOyGEaHSScy3c/d4f7Mssdo+tg4rxdVD3MXay3IkQ56iQBx8k4PbbADjyxBMUff1NpfPHFr2UFjshhGh8Zn65m5hAM9umXYpJp2H9pAGsvKcPnaP9+fDuPnWuVxI7Ic5RKpWKsKlT8b/+/8DlIu2RRyj+6Sf3+WMtdpLYCSFE47M9OZ+HL21LoJcetUqFSqWiZ8tAHr+8HTO+2H3qCmogiZ0Q5zCVSkX4jBn4DhsGDgdpDzxI6aZNwAmJXYkkdkII0dg4XQrehooRcQFeejKLygGICjDxb05JneuVxE6Ic5xKoyFy9iy8Bw9GsdlIGT8By59/EnpsjF2RFUVRTlGLEEKIs6lduA97jlTsPNEtxp93fv6XP5LyePX7A8QG1n3GrCR2QjQBKp2OqJdfwqtfPxSLhZS778Er5V8AyuxOSv+zZIoQQgjPmnjJee4/uh++tC0p+Rauf2cjP+3LZsbw+DrXK7NihWgi1Ho90a/PJ/muuyj7Yxt5992DeciTWOwusout7iZ/IYQQnjewbYj7/1sGe/HD5EEUWGz4mXRntGWktNgJ0YSoTSZi3n4bY6dOOPPzCSjKASDr6NgNIYQQjUtSTik/78+m3O7E36w/4/oaxZ/weR98QN6ixThycjC0b0/4tCcwdelSbdn8lSsp/PwLrAcOAGCM70jopEmVyjtycsiaO4/SDRtwFhdj7tGD8GlPoG/Z0l3myFPTKd24EUdWFmqzGVP37oQ+MhlDXBwA5Xv3krsgAcv27Tjz89FFRRFw4w0E3n57w70RQtQDjbc3MQkLSL79dgJKC0gzBZKRmgVx1e9QIYQQ4uzLL7UxYfl2Nv6biwr46ZGLiQ0y89gnf+Fn0jHtqo51qtfjLXZFa9eSNXsOwRMm0Gr1Kozt2pE87i4cubnVlrds2YrvsKG0WLqElh+uQBceQfKd47BnVmyxpCgKqRMmYktNIfrNN2i1ejW6yEgOjx2Ly2Jx12OMjyfy+eeIW7OGmIUJoCgk3zkOxVkxFql89240QUFEvjCHuK++JPjee8h66WXy3v+g4d8UIc6QNiCAmEWLCNRU/DzvT1iKPTPLw1EJIYQ45pmv9qDVqPl9yiWYdBr38au6RvLz/uw61+vxxC53yVL8r78e/5HXYWjThvCZM1AbjRSsWl1t+ai5LxJ4880YO3TAEBdHxLPPgMtF6caNANiSkijbuZOI6dMxde6MIa4V4TOmo5RbKVyzxl1PwA2jMPfsiT46ClN8PCEPPYjjyBHsaWkA+I8cSfgT/8OrVy/0MTH4XX01/tddS/H69Q3/pghRD3ShobQcVLHIZXapjcO33ootNdXDUQkhhAD45UAOU65oT4SfqdLxVkFepBWU1blejyZ2is1G+e7dePU9vsKySq3Gq08fynbsqFUdrrJyFIcDjZ/f0TrtFfUYDJXqVOn1lG3bXn0dFguFq1eji45GFx5e42s5i0vcryPEuSAsvKL7tTAwAntKCodvvgXroUMejkoIIUSZzYFJr6lyvKDMhl5b9/TMo4mdI78AnE40QZXH/miCg3Dk5NSqjqx5c9GGhuLVt2KzdENcK7SREWS99DLOwkIUm42chAQcGRk4sis3beYtX87e8y9g3/kXUPLLr8QuXoRKX/3ARcv2Pylatw7/UaNqjMVqtVJUVOR+FBcX1+oehGgoxxYpLuvRB8N5bXBkZXH41tso2133Vc2FEEKcuZ6tAlm9/XgvikoFLpfCOz//S58zGBPt8a7YM5GzIIGiteuIfn0+6qMtdCqdjujX5mNLSmL/hb3Z2/18LJu34DWgP6gr367f8OHErV5Fi/eWoW/ZkrSHJuGyVl2lv3z/flInTCBkwni8L+pXYzyzZs3Cz8/P/ejYsW4DH4WoL8cWKc62KsQuW+aeLZt8x2gs26tvwRZCCNHwpl7ZgRVbkrlj8RbsToVZ6/7hsld+YXNiHlOubF/nej2a2GkD/EGjwfmfiRLOnFy0wcEnvTZ30WJyExKIXbgQY7t2lc6ZOsUT99mntN26hfN+/YXYhQk4CwrRx0RXKqfx8UHfsiXmnj2JfvUVrImJFK//rlIZ68GDJI8Zi/+oUQTfd99JY5o6dSqFhYXux549e07xDgjRsE7cL1YbEEDskncx9+iBq6SE5DvHUfLbBg9HKIQQzVO7cB9+eGQQPVsGcGnHMCw2J1fEh7P2gYtoEeRV53o9utyJSq/HGB9P6cZN+AwZAoDiclG6aRMBt9xS43W5CxeS8/Y7xC5MwNS5U43lND4+QMWEivJduwh54IEayyoAioJis7mPWQ8c4PDoMfiNuIbQSQ+d8n4MBgOGE8b2FRUVnfIaIRrSscQut9TKdW8eTeJ634017DJcRUXw3k70vxaedOyoSqXi/y6I5qZesWcjZCGEaDZ8jTomXnJepWNHCsuYuvovZl1X/bJvp+LxdeyCRt9B+pSpGDt1wtSlM3lLl+EqK8P/umsBSH/8cbShYYROfhiAnIQEcl6bT+Tcueiiotzj5tRmM2qvigy36Ouv0QQEoouMwLp/P5nPPY/P4MHublRbSgpFa9fh1a8f2sAA7BmZ5CYkoDYY8B44AKjofk0ePQavi/oRNHr08fF5Gg3awMCz+RYJUWdBXgaCvQ3klFjZnlxw/IQuEIKO/hwXKlBYUN3lbsl5FknshBDiLMgvtfPR1pRzN7HzHToUR14+2fNfw5mdg6FDB2ITFri7Yu3pR0B1vMe4YMWHKHY7aQ8+WKme4AkTCLl/IgCOrGwyZ8/BkZuLNiQYv2uuIeSEblSV3oBl2x/kLVuGs6gIbVAQ5h49aLFiBdqjEzmKv/kWZ14eRV98SdEXX7qv1UVG0uaH7xvs/RCiPmnUKr6Y2I9daYVVzikuF/kfLMeyaRMA/jeMwnvAgEplLDYnD320g5wSK3anC53mnB6WK4QQTZ5KObYDrah3qampxMTEkJKSQnR09KkvEOIsU1wuMmfNJv+99wAIefhhgu++y33e5VJo9+Q67E6FDVMuIcrfVFNVQgjRqJyr38F70ou4av6v/DtrWJ2ulz+/hWjGVGo1Yf+bSvD4ihbt7JdeImveSxz7e0+tVhHqYwQgo1D2mxVCiMbO412xQgjPUqlUhDzwAGovL7JenEtuQgKu0hLCpk1DpVYT7mckraCMzCJJ7IQQ4kzd894fJz1fVOY4o/olsRNCABB0552ovbzJmDmT/OUrcJWWEvHcc4T7SoudEELUFx+j7pTnrwuoe9exJHZCCLeAG29A7eVF+pQpFH7+BS6LhdAhdwNIi50QQtSDudd3bdD6JbETQlTiN/wq1GYTaQ9Nonj9dxiVKPDuTIYkdkII0ejJ5AkhRBU+gwcT887bqEwmfP/ZCUBGXqmHoxJCiIa1bGMS/Wb/QNtp67jmjQ3sSCmo1XVf7Eyn5ZQ13LXs5OPnzgZJ7IQQ1fLq25fYxYsI0VQM5E05mIIjL8/DUQkhRMP4cmc6z371Dw8OOY81919Exwgfbl+0mZySqnvInyglz8Lza/6hV8vGsXmBJHZCiBqZu3en67NPApCjMZF0623YMzM9HJUQQtS/hb8lcmOvGEb1iOG8MB+eG9EZk17Dyj9SarzG6VJ46KMdTLr0PGICzWcx2ppJYieEOKmY7vEA2DQ68lKOcPjmW7AlJXk2KCGEqKXi4mKKiorcD6u1aguczeFiV1oh/doEu4+p1Sr6tQlm++GCGut+9fsDBHnpuaFn49lyURI7IcRJGXUaAswV0/MLWrXHnpZG0g03Ytm61cORCSHEqXXs2BE/Pz/3Y9asWVXK5FtsOF0Kwd6GSsdDvA1k19AVuzUpj5VbU5g9sm57ujYUSeyEEKcUdnQtO82TT2Ps0gVnYSGHx95JwWefeTYwIYQ4hT179lBYWOh+TJ069YzrLLE6mPTRDmaN7Eygl74eoqw/styJEOKUwv2M7M0oJgc9Fy9dQvqUqRR/8w1HpkzFnpxM8P33o1KpPB2mEEJU4ePjg6+v70nLBJj1aNSqKhMlskushPynFQ/gcG4pqflljFt6fBas6+hWjK3/t5YfJg+kRZBXPUR/+iSxE0Kc0rHdJw5mlZBeHozy1HPYouLIX/Ehme9+iM/hTEIfexSVvua/XL0NWvzNjesvWyGEANBr1XSK8uP3gzlcHh8OgMul8PvBXG7v26JK+dYh3nzz0IBKx+Z+u49Sq4Ppw+OJ8DOdlbirI4mdEOKUjnXFJvyaSMKviUePtobLnzhe6OUNJ61DrYJlYy/kovOCT1pOCCE8YdxFrZj88U46R/vTLcaPRb8lYbE5uP6CGAAe/mgHYX5GHr+iPUadhnbhPpWu9z26Vdh/j59tktgJIU5pSIcwPtyaTGGZvepJlwvFZgdFAbUKlU5fkcWdwO5UcLoUNv2bK4mdEKJRGt41krxSGy+v3092sZUOkb4sHduLEJ+Krti0grJzYsiJSlGOdgqLepeamkpMTAwpKSlER9d9Q18hGjvrv/+Scs+92FNSUPv6Ev3aq3j17u0+/9ZPh5jz9V6u6x7FSzd081ygQohmo7l+B8usWCHEGTPExdHyow8xde+Oq6iI5HF3UbBqlft8pH9FV25aQZmnQhRCiGZBEjshRL3QBgYSu+RdfIcOBYeDI09MI2veSyguF1H+FQOJ0wslsRNCiIYkiZ0Qot6oDQYi580lePx4AHITEkib9DDhpop/ajIKy3G6ZPSHEEI0FEnshBD1SqVSEfLA/UTMngU6HcXffEP5/feiUVVMojjVhtpCCCHqThI7IUSD8B8xghaLF6Hx88P+106CyosAGWcnhBANSRI7IUSDMffsScuPPkTfogUhxTkA/Lt5h2eDEkKIJkwSOyFEg9K3bEmLD1cQYa745+afZR+T/9FKD0clhBBNkyR2QogGpw0IoM3lgwDINvqSMX06mbNmozgcng1MCCGaGEnshBBnRVSQNwCFnS4AIG/pUpJHj8GeleXJsIQQokmRxE4IcVZEHV2kOCcgnKhXX0Xt5YXljz9IHDmS0i1bPBydEEI0DZLYCSHOishjixQXlOF7+WW0/ORjDOedhzM7h+QxY8ldtAjZ4VAIIc6M1tMBCCGah2OJXb7Fzv7MYgy+oajeepei116l5LsfSH/jXbx27CP00UfQeHnVWE+Enwm9Vv4mFUKI6khiJ4Q4K3yNOnwMWoqtDi57+ZfjJ9QXwmUXHn/+5taT1tM2zJtvHhqASqVqoEiFEOLcJYmdEOKsuenCWFZsTqa6DlfF6USxlqO4FFQqUOkNqHS6SmVKrA72Z5aQU2IjxMdwdoIWQohziCR2Qoiz5n9DO/C/oR1qPO/Izyf9sccp/fVXAPyvv56waU+gNlQkcf1m/0BaQRnJeRZJ7IQQohoyUEUI0WhoAwKIeedtgh+4H1QqCj7+mMM33YwtNRWA6ICKcXqp+RZPhimEEI2WJHZCiEZFpVYTMn48MQkJaPz9Kd+zh8TrRlL800/EBJoBSMmTxE4IIaojiZ0QolHyvqgfrVavwti1C66iIlLvvY+gvTsBSJbETgghquXxxC7vgw84eMlg9nbpSuKoGyj7668ay+avXEnSLbeyr9eF7Ot1IYfHjKlS3pGTQ/qUqRzoP4C93bqTPO4ubElJlcoceWo6By+9jL1du7G/T19Sxk/A+u+/lcpkPPscideNZG/nLvw74tp6u18hRO3pIiNp+d57BNxyCwC+P38DQHJWkSfDEkKIRsujiV3R2rVkzZ5D8IQJFX+Zt2tH8ri7cOTmVlvesmUrvsOG0mLpElp+uAJdeATJd47DnpkJgKIopE6YiC01heg336DV6tXoIiM5PHYsLsvxv/CN8fFEPv8ccWvWELMwARSF5DvHoTidlV7Pb+R1+A69suHeACHEKan0esKfnEbk3LmEO0sBSNqfjGX7dg9HJoQQjY9HE7vcJUvxv/56/Edeh6FNG8JnzkBtNFKwanW15aPmvkjgzTdj7NABQ1wcEc8+Ay4XpRs3AmBLSqJs504ipk/H1LkzhrhWhM+YjlJupXDNGnc9ATeMwtyzJ/roKEzx8YQ89CCOI0ewp6W5y4RPe4LAW25BFx3TsG+CEKJW/K4aRs9XZgOQZfDl0B1jyFu6VHarEEKIE3gssVNsNsp378arbx/3MZVajVefPpTt2FGrOlxl5SgOBxo/v6N12ivqMRxfBkGlVqPS6ynbVv1f9y6LhcLVq9FFR6MLD6/j3VSwWq0UFRW5H8XFxWdUnxCisujO7TBo1bhUarJ13mTOmk3q+Ak1tvILIURz47HEzpFfAE4nmqCgSsc1wUE4cnJqVUfWvLloQ0Px6tsXAENcK7SREWS99DLOwkIUm42chAQcGRk4srMrXZu3fDl7z7+AfedfQMkvvxK7eBEqvf6M7mnWrFn4+fm5Hx07djyj+oQQlanVKveSJ9ZxE0Gno+THH/l3+NUU//Cjh6MTQgjP8/jkibrKWZBA0dp1RL8+3714qUqnI/q1+diSkth/YW/2dj8fy+YteA3oD+rKt+o3fDhxq1fR4r1l6Fu2JO2hSbis1jOKaerUqRQWFrofe/bsOaP6hBBVHVvypKBHP1p9vBLDeefhzMsjdfx4jjz5FK7SUg9HKIQQnuOxxE4b4A8aDc7/dKE4c3LRBgef9NrcRYvJTUggduFCjO3aVTpn6hRP3Gef0nbrFs779RdiFybgLChEHxNdqZzGxwd9y5aYe/Yk+tVXsCYmUrz+uzO6J4PBgK+vr/vh4+NzRvUJIaqKPWEtO2P79rT85GMCR48GoODjj/n32uuw/PmnByMUQgjP8diWYiq9HmN8PKUbN+EzZAgAistF6aZN7qUNqpO7cCE5b79D7MIETJ071VhOczSpsiUlUb5rFyEPPFBjWQVAUVBstjrdixDi7IkJqEjsvvwrndT8soqDLS7DMfF8ynbsRCkrg3lrMJy3D0Ob86q01gOYdBrGX9yaFkFeZzN0IYRocB7dKzZo9B2kT5mKsVMnTF06k7d0Ga6yMvyvq1g3Lv3xx9GGhhE6+WEAchISyHltPpFz56KLinKPm1Obzai9Kv6BLvr6azQBgegiI7Du30/mc8/jM3gw3hf1A8CWkkLR2nV49euHNjAAe0YmuQkJqA0GvAcOcMdmO3wYl8WCIycHpbyc8n/+AcDQuvUZj8UTQtRdu/CKP9pS8spIySurfDL4hH1oy4C/M2qsR6dV8eyIzg0QoRBCeI5HEzvfoUNx5OWTPf81nNk5GDp0IDZhgbsr1p5+BFTH/9ouWPEhit1O2oMPVqoneMIEQu6fCIAjK5vM2XNw5OaiDQnG75prCLnvPndZld6AZdsf5C1bhrOoCG1QEOYePWixYgXaEyZyHJn2JJatW93PE6+9DoDW332HPjqq/t8MIUSt9D8vmPk3dSe7uOYxseX/7KFo3dco5eWodDq8B1+C+fzzARW704tYtT2VQ1kyFk8I0fSoFFkEqsGkpqYSExNDSkoK0dHRp75ACFFv7JmZHJk6ldLfK9a59Orfn4jnnuWvMh0j3/qdCD8jG6cO9nCUQoiG0ly/g8/ZWbFCCHEyurAwYhYuJOx//0NlMFD6668kXn0NwX9vAeBIYTllNucpahFCiHOLJHZCiCZLpVYTePtttFr1CYaOHXAWFFD6yEP44ADgcJ50xwohmhZJ7IQQTZ6hTRtaffghQXffjUqtJiI/HYB9m//ycGRCCFG/JLETQjQLKr2e0Icn0eK9ZUS7LADsWLicrHnzcMlSR0KIJkISOyFEs2K+4AI6jbgcgHSvYHITFpJ0/SjK/v7bw5EJIcSZk8ROCNHsxEUGAJDTrTeagACs+/aRdMONZDz3PM4SGXcnhDh3SWInhGh2WgZXLGie4tQTt+YrfK8eDi4X+e+9x79XXUXxDz94OEIhhKgbSeyEEM1Oq6NbiWUVW7F6+RL1wgvELFqILiYGR0YGqeMnkHr/A9gzMz0cqRBCnB6P7jwhhBCe4GfWEWDWkW+xM2vdPwSY9UAwykMvY9n2B2U7dkKqC9X98zBfeCHG+HhUalWVejpE+DK0c8TZvwEhhKiBJHZCiGbpvDAftiTm8f6m5P+cCYa2J+xIkQ38dKjGen597GJiAs0NEqMQQpwuSeyEEM3S9OEd+WRbKi5X9bsqKoqC9cAByv7cgeKwg0qNsUMHTF06o9JoWLsrg+xiK3sziiWxE0I0GpLYCSGapfhIP+Ij/U5RqjP2zH5kPvssxeu/g52g2xBD+Izp5MUF8eXOdA5mlXBpx7CzErMQQpyKTJ4QQoiT0IWFET1/PtGvz0cbFoY9JYWUO8cR+ufvABzMKvFwhEIIcZwkdkIIUQs+Q4YQt+YrAm69FVQqwv74BYB9+5JRlOq7c4UQ4myTxE4IIWpJ4+1N+LQnaPnhCloHVYyrO1Rg4/DoMVgTEz0cnRBCSGInhBCnzdS1KxctexsNCmU6Iyk7/yHxmhFkv/YarlLZuUII4TmS2AkhRB0YTAZaBHsDkN37EhSbjZw33+LQlUMp+OwzFJfLwxEKIZojSeyEEKKOWodWJHaFt91N1CuvoIuOxpGVxZEpU0kadQOW7ds9HKEQormRxE4IIerovKOJ3aHsEnyvuJy4NV8RMvlh1F5elO/axeGbbyF10iRsqWkejlQI0VzIOnZCCFFHbY4mdj/uzWbaZ39XHAzpjeuRbpT//TfWQ4cgDVSPvo2hfXuMHTui0lX+Z1erVnPzhbG0DfM52+ELIZogSeyEEKKOOkb6ApBWUFbN1mRh0OqEhYvLgG3p1dZzOLeUd8f0apgghRDNiiR2QghRR+3DfXn1xm4k5pxkJqwCtsRESn77DVdhIQDakBC8+ven0C+I9zclszu96CxFLIRo6iSxE0KIM3BNt6halGqLa/TF5L//ATlvvolrXwn8thzNZVfyvnkwWcVW8kptBHrpGzxeIUTTJpMnhBDiLFDr9QSNHUPrb7/B/6YbQa3G+e06IkpzAdiTmOnhCIUQTYEkdkIIcRZpAwOJmD6dVp99ilffvrQsrBh3t2HmPPI//hjF6fRwhEKIc5kkdkII4QHGtm2JWbSQrv3PB+CQ1peMJ58i8bqRFP/4o+w/K4SoE0nshBDCQ1QqFV17dwYgtd0FqH19se7bR+p940m68UZKf/9dEjwhxGmRxE4IITyoXXjF+nWHHHpaff01QXfdhcpkonznXySPvZPk2+/Asm2bh6MUQpwrJLETQggPahHkhVGnxupwkerUETr5Ydp8+w0Bt9+GSqfDsnUrh2+5leS77qbs712eDlcI0cjJcidCCOFBGrWKdmE+7EwtZPwH2/E16SpOBF2Mcnc/7OnpOHJyQFHg1R/QBPyJLjIKtdlUqZ4ofxOzruuMUafxwF0IIRoLSeyEEMLDerQMZGdqIXsziqs56wtBvpUPZZZRsZVFZZd1DOPKzhENEqMQ4twgiZ0QQnjYI5e1o09cEDan66Tl7BkZFH39NWV/7qg4oFJh7tWLb2N68EtyMX+nFUpiJ0QzJ4mdEEJ4mEmvYUjHsFMX7BwBl3an/J9/yH71NUp++gk+3UlG6z380vla/krMBto3dLhCiEasUUyeyPvgAw5eMpi9XbqSOOoGyv76q8ay+StXknTLrezrdSH7el3I4TFjqpR35OSQPmUqB/oPYG+37iSPuwtbUlKlMkeems7BSy9jb9du7O/Tl5TxE7D++2+lMvb0dJLvuYe93bqzv28/Ml94EcXhqLf7FkKIujB26EDM22/R8sMVmHv3pk1uMgB/HzhCxuwXsGdmeThCIYSneDyxK1q7lqzZcwieMIFWq1dhbNeO5HF34cjNrba8ZctWfIcNpcXSJbT8cAW68AiS7xyHPbNiOx5FUUidMBFbagrRb75Bq9Wr0UVGcnjsWFwWi7seY3w8kc8/R9yaNcQsTABFIfnOce5V3xWnk5R77gW7nZYrlhM5exaFn35K9mvzG/5NEUKIWjB160aLJe8yYN5MNIqLQr0X+z76lENDhnDkySexJiZ6OkQhxFnm8cQud8lS/K+/Hv+R12Fo04bwmTNQG40UrFpdbfmouS8SePPNGDt0wBAXR8Szz4DLRenGjQDYkpIo27mTiOnTMXXujCGuFeEzpqOUWylcs8ZdT8ANozD37Ik+OgpTfDwhDz2I48gR7GlpAJRu2ID10CEiX3gBY4cOeA8YQMiDD5C/fDmKzdbwb4wQQtRSYL8+tI30AyD5goEodjsFH3/Cv0OHkfrgQ7JMihDNiEcTO8Vmo3z3brz69nEfU6nVePXpQ9mOHbWqw1VWjuJwoPHzO1qnvaIeg6FSnSq9nrJt26uvw2KhcPVqdNHR6MLDASjbsQND27Zog4Pd5bwuughXSQnWgwdP6z6FEKKhdY6q+Dcw8/oxtPjgfbwHDQJFofibb0i6/noOjxkjO1kI0Qx4dPKEI78AnE40QUGVjmuCg2rdhZA1by7a0FC8+vYFwBDXCm1kBFkvvUzEzBmoTSZyly7FkZGBIzu70rV5y5eTNXceisWCvlUrYhcvQqXXV8SWnYP2P3Ede+7Iyak2FqvVitVqdT8vLq5u6QIhhKh/naP8WPlHKn+nFWK+vBfmCy6gfP9+8hYtovCrNVg2biJ54yaM8fEE3XUXPpcOQaWRNe+EONGyjUm88/O/ZJdY6RDhy8yr4+kW419t2RVbklm9PZV9R5cp6hztx6OXt6+x/NlyTs+KzVmQQNHadbRYthT10RY6lU5H9GvzOTJtGvsv7A0aDV59+uA1oD/85w9Vv+HD8e7bF0d2NrmL3yXtoUm0WLHcXdfpmjVrFjNnzjzT2xJCiNMWf7TF7reDOfR87rvjJ3wvhRsuwVVWhqusHFDg6zxU61ehNplQGY2gUgGgVsEdfVsyflAbD9yBEJ715c50nv3qH569thPdY/xZvCGR2xdt5odHBhHsXTUv2PRvLld3jeT8qwMwaDW8/fMhblu0mfWTBhLuZ/TAHVTwaFesNsAfNBqc/5ko4czJrdQFWp3cRYvJTUggduFCjO3aVTpn6hRP3Gef0nbrFs779RdiFybgLChEHxNdqZzGxwd9y5aYe/Yk+tVXsCYmUry+4h9EbUhwlQkcx57XFNvUqVMpLCx0P/bs2XPK90AIIepDxwhfQn0MOF0K2cXWyg+Lg1xFR77Rh3yjL/lGX/J0XuQ41GSX2NzlMousLPjlX+muFc3Swt8SubFXDKN6xHBemA/PjeiMSa9h5R8p1ZZ/9cbu3NanJfGRfrQJ9WbOyC4oCmw4WH2v3tni0RY7lV6PMT6e0o2b8BkyBADF5aJ00yYCbrmlxutyFy4k5+13iF2YgKlzpxrLaXwqNte2JSVRvmsXIQ88UGNZBUBR3BMjTN26kfP2Ozhyc91dsKUbfkft7Y2+TfV/zRoMBgwntPYVFRXV+HpCCFGfjDoNPzwyiJQ8yynLusrKKF6/nsLPP8eZc/QPWJOZSX3uocBiJzGnlLgQ7waOWIizo7i4uNL38X+/qwFsDhe70goZP6i1+5haraJfm2C2Hy6o1euU2Z3YnS78zbp6ibuuPN4VGzT6DtKnTMXYqROmLp3JW7oMV1kZ/tddC0D644+jDQ0jdPLDAOQkJJDz2nwi585FFxXlHjenNptRe3kBUPT112gCAtFFRmDdv5/M557HZ/BgvC/qB4AtJYWitevw6tcPbWAA9oxMchMSUBsMeA8cAIBXv34YWrcm/bHHCX30ERzZOWS/+ioBN9+M+ug4PCGEaEy8DVo6RPieuiC+cM+tKGNGUbRuHbkLF2E9cIDWuYfZE9SKH+YuIPLOqzC2bdvgMQvR0Dp27Fjp+fTp05kxY0alY/kWG06XUqXLNcTbwKHs0lq9zux1/xDma6Rfm5P3ODY0jyd2vkOH4sjLJ3v+azizczB06EBswgJ3d6c9/QiojvcYF6z4EMVuJ+3BByvVEzxhAiH3TwTAkZVN5uw5Fa1tIcH4XXMNIffd5y6r0huwbPuDvGXLcBYVoQ0KwtyjBy1WrHC3zqk0GmLefosjM2eSdONNqE0m/EaMIOSB+xv6LRFCiLNCpdfjd801+F59NaW//krnlX+wB9ielEu/q6/Ba0B/Am+5Ba+LLpKJFuKctWfPHqKiotzP/9taVx/e/OkgX+48wod398ao8+zvikqRwRQNJjU1lZiYGFJSUoiOjj71BUII4UHr/j7CfR9s5zxXEa99+Qwc/XrQRUfjf8Mo/EeORBsY6OEohaid0/kOtjlcdHjqa9685Xwujw93H3945Q6KyhwsvKNHjdcu+OUQ8384yAfjLqRLtH99hV9nHl+gWAghROPQPTYAgEMaX8K/+JLAO25H7euLPTWV7HkvcXDgINIeeRTLtm0ywUI0KXqtmk5Rfvx+wsQHl0vh94O5nN/Cv8br3v75EPO/P8jSsb0aRVIHktgJIYQ4KtzPSISfEZcCe9X+hE2dynk//0TEc89i7NQJxW6n6KuvOHzLrSReM4L8FStwltRu/JEQjd24i1qxYmsKn2xL5WBWMU98tguLzcH1F8QA8PBHO5jz9V53+bd+OsRL3+7nhf/rQnSAiazicrKKyym1enZPeY+PsRNCCNF4nB8bwJq/jzD63S3oNcf+9veG+HEoHZwodjuK3QEo8Afwx9eodFpUOj0qdUV5P7OOJWN60SZUZtaKc8fwrpHkldp4ef1+soutdIj0ZenYXoT4VIzJSysoQ3V0zUeA9zcdxuZ0cd8HlXe1enDweUy61HMTj2SMXQOSMXZCiHPN5zvSePDDHWdcz8SL2/DI5e1OXVCIBtJcv4OlxU4IIYTbNd2i6BMXRKnNecqyiqJQvnMnhV+toXTj7+Bw8ntEJxZ3uopff/2LBzqa0cfEnIWohRDHSGInhBCiklDf09gOaUg/GNIPe1YWBZ98guaL9SwGdlv17LliGIH9ehNw4014DxwgS6YIcRbI5AkhhBBnTBcaSsj48Qz8ciUhenBotOwLiKX0l19JHT+eQ5deVrGbT45nt1sSoqmTxE4IIUS9Uet09O4QCUDqQ9MJHDsWjZ8f9vR0sl95hQODLiZl4kSKv/8exW73cLRCND2S2AkhhKhXF7aqWMR4W76TsMcepc0vPxM5Zzambt3A4aDku+9JnTCRAwMHkfH885T/849nAxaiCZExdkIIIerVscRua1Ie17254ejRYBgwEaVXOY68PJx5eRXLpiQCL/2AyrQRbVAgmoAAVNqKr6bL4sO5d2Dr6l9ECFEtSeyEEELUqzah3sQEmkjJK2N7ckE1Jczga656uAwoK3E/3ZFSwE09Y/Ez6xoqVCGaHEnshBBC1CuVSsUn9/ZlR0pBrcq7LBbKtm2ndPMmbElJACyMH84R72DWznmbEddfgjG+Y6XFYYUQ1ZPETgghRL0L8zVW2kz9lHrGwb3/h/Xffyn89DP+3pnEZ97B/Lo3k27/938YzmuD34hr8R1+FbrQ0IYLXIhznEyeEEII0WgY4uIInfwwwx+/G4AdLbuhMhiwHjhI1osvcnDQxRy+YzT5H36EIy/Pw9EK0fhIYieEEKLR6d0mBJ1GRbrKhP7Lbwl/eiam7t3B5cKyeTMZM2Zw4KL+JI8dS/7KlTjy8z0dshCNgnTFCiGEaHS8DFrOjw1gc2Iey3Zk07tjf+jYH3tuHuU7dmD580/shw9DYjG89TG8swpD23aYz++GsXMXNN5eAJj0Wvq2DkKnkXYM0TxIYieEEKJRGtA2hM2JeSz5PYklvyedcMYfwi+G6obwHQIO7at0aMqV7WXZFNFsSGInhBCiUbqhZww7UgoosNhOWdZVbsWZn48zPx+XxQJAid7MYd9wPv1yEzfm/Y3P4EvQ+Po2dNhCeJQkdkIIIRqlYG8DCbf3OO3rrImJFH/zDUnffsf1PjezT+vP3zOfJvipp/Du1w/fK6/A++KLJckTTZIMOhBCCNGkGFq1Ivjee+mxegVdwyoWQt7eZSDY7ZT89BPpj09hf99+HL5jNLnvLnGvnSdEUyCJnRBCiCbr0u4tANh5yfXEffkFwRMmoG/TGhwOLJs3kzVnDoeuuJJDV1xJ5uw5lG7egmK3ezhqIepOumKFEEI0WUM6hPHiN/v47WAOr0X4oGp7KbS9FGdRIbbDydgOJ2FPPwIuF2zOgM0rUBlWo4+JQd+iBbrYGNQGI52j/U5vwWUhPEQSOyGEEE1W2zBvYgPNJOdZeOPHQ/85awKvDnBeh+ovTgVSUwFQobD+hta07tZetjYTjZokdkIIIZoslUrFqzd248udR3ApyqkvUBQcOTnYU1Oxp6biLChgW2g7Un1CWf7ka9xsPYT3xYPwGTQIc48eqPT6Br8HIU6HJHZCCCGatO6xAXSPDajTtfa0NJas/p3n0uDX6G5c/9NP5C97j/xl76H28sLroovwHjQI74ED0AYG1nPkQpw+laLU5k8YURepqanExMSQkpJCdHS0p8MRQghRB7klVno9/z1Ol8Lavnr8N/9Eyc+/4MzJOV5IpcLYpTPeF/XHu/9FGDt3RqXReC5o0Wy/g6XFTgghhDiJIG8DfVsH8euBHD5whjPktgdRbr0fW9Jhyv/+G8vff2FPToEMG3zyPXzyPWqzF8aO7TF27IQxviNaf390GjU9WgZg1EnCJxqOJHZCCCHEKQztHFGR2G1O5oPNySeciYCoCIiq4cIDwIED7qc3tDQwa+wA1DI2TzQQSeyEEEKIU7i6ayQ/78smvbDs1IUVBZelDGdJMa7iElxlZfx/e/ceFWW57wH8OzeGmeHOMDCkIAhxEeGYIpu8dIGtoKej5d6ZsVvYNknDMivzuNPEzulY1ra1dRvuLNPO8VjZyjRLW947IuIl7xcSozBhGC4hM9xn5jl/oLP2KAQaMDB8P2vNknmf5334Pb/1+s6P9zZWqRQ/eN+FbZeuYdq9Y+AXPwTqxESoExPhHh/PQo+6DAs7IiKiDmiUcqx5YvgdrWv55ReYDx7CxLwGXFWocNA3AimH8lF3KB8AIFEqoUpIgHrECKhHJkKVkACpStWV4VM/wsKOiIioG8l9feHz0ERMVV/Cil3f4+C/zsDj2gmoP3oM9UePwlpVhfojR1B/5AjwLgCFAqqhQ1uP6I0YAfU9wyDVaJw9DeojeFdsN+qvd+QQEdGtfv6lHqPf3AeJBHgsMQQyKQABWE21sBgrYDEaYTEaYau/6XSvVAKZrx8UugDIdTqERQ7E07+P4YOSO9BfP4N5xI6IiKgHDPBVY1SEP/KKqrDpSMlNrQpAehcQ1N5dGACaAFyxAFeKofnv9zAuNhDqxESohg+H3PfOntNHroeFHRERUQ95c0o8tp4sRYvV1ul1bCYTWkpL0XL1Kk7V2HDUKxSfK0IwYsNaVG/4CACgjIy8fjPGCKgSEiDX63lEr59y+qnY6o0bUf3BOlgqK6GMjkbQolegio9vs+8vn36Ka1u3oen6rePuQ2KhmzfPob+lshLGt/+Kurw8WE0mqEeMQNCiV+A2aBAAwFpTg4pVf0ddXh5aysog8/ODZ0oKAuY+B5mnp32cuvx8VPxtJZq+/x4StRo+kych4PnnIZF3vhbur4eBiYioe1yprsfY5fsgAHyiPAPt8YNoLrr5O3ABWYAWqvgEqOLjoUpIgHtcHGQe/es6vf76GezUI3a1X38N4xtvIignB6qEeFRv+AglT83E4B1fQ+7vf0v/+iNH4TVxAtTDhkGiVKJq7fsomfEUwrd/CUVgIIQQ+Dl7DqCQY8C7qyHVeKB6/Xr89Oc/Y/D27ZCq1Wi5fg2D7uWXoYwYjJbSUhiW5MBiNGLAyr8BABovXsSVrKfhP+tpBL/5BlrKy2HIWQphtSFwwcs9nSYiIiIAwEA/NR6I1mHvRSM23P17jJv8BKxmM5qLi9H0ww9o/vFHtJSVAVYrUFgNFO4HNu8HJFIoAnVwCw2BYmAIlKGhuO/eGAR4q509JepiTj1iV/zoVKji4hD06mIAgLDZUHT/A/D905+gzZrZ4frCasX3I5MQuHgRfCZPRlNxMX5In4DwL7dBGRlpH/PS6DEImPc8fP/4xzbHqd25E6XzX0bUie8gkcthXPEO6g4dQthnm+19THv34eq8eYjMy+v0Xz399a8FIiLqPvsuGvHk+qO/eZyYmivIbTgMdXw8VP/SenRPHhDQBRH2Dv31M9hpR+xEczMaz51zKOAkUik0ycloOHmyU2PYGhohLBbIvL2vj9nSOo5S6TCmxM0NDce/a7ews5pMkHp42E+ziuZmhzEAQOquhGhqQuO5c9AkjWxznKamJjQ1Ndnfm0ymTs2DiIios+67OwAzx4ThoqHznzG25ubWhyWbTLCaTTgl98cFn4EoOLsd8QVr7f3kwfrWU7gJCVAlxMM9NhZSd/fumAZ1E6cVdpZfagCrFbKbTrnKtP5oKi7u1BjGv74NuU4Hzb33AgCU4WGQB+thXPEO9EtzIFWpULVhAywGAywVFe3E8Qsqc3Ph8+ij9mWa0aNR/dFHuLb9K3ilp8FSWYmKd99t7d/OOACwbNkyLF26tFOxExER3QmpVIJXJsb+pjEWbTmD/ykowbYJWRjbcBQNJ0+hqagIltIymErLYNq5s7WjXA73qKjWIi9uKNxjY6AMD4eE35TRa/XZu2Ir31uL2q93IPSjDZBeP7omUSgwYOUqlC1ahO+TfgfIZNAkJ0MzdgzQxglnq9mMK0/PgnJwBALmZNuXe4weBd38+TDk5KB0wQJI3NygnT0bDceOQyJt/y6jhQsX4oUXXrC/v3r1KmJjf9t/PiIioq42c2w4/vdICfJqZViTPBVuv5sGW0sLrJVVrc/Tq6yAxVgBW8P1Z+qdMgGnDgE4BIlMCqmPL+R+ftDqfDFj9CB4xsZA5uHh1DlRK6cVdnJfH0Amg7WqymG5tbIKcq32V9et+mAdqtauRci6dXCPinJoU8UNQfgXW2A1mSBaWiD387t+Ld8Qx99jrsOVp2ZCqlFjwN9XQaJQOLT7PzkdftMzYTFWQObthZarV1GxYgUUAwe2G5dSqYTyn07h1tbW/uo8iIiInCHUX4P0OD2+OlOGDfk/3dTqCbh5AgPCOx7ICJj/40M8emkfFCEhcI+JgXtMNNxjYqCMjoFcF8DHrvQwpxV2Ejc3uA8Zgrr8w/BMTQXQeqND3eHD8M3IaHe9qvffR+WafyDk/bVQDY1rt9+NR5c0//gjGs+eRcBzz9nbrGYzrsx4ChI3Nwx89137Eb9bYpRIoAjUAQBqv/oKcr0e7jwCR0RELmDJv8VicIAGTZbOP1NPoPW5epaqKpRVXMM3DZ747O4HMbH4EDQlJWgpKYHpm2/s/WX+/nCPjm49hRsdDfeYWLiFhkAik3XDjAhw8qlY/+mZKP33hXCPi4MqfiiqN3wEW0MDfB55GABQumAB5LpA6F5sPb1ZuXYtKleuQvDbb0Nx1132692karX9e/Rqd+5s/eqVYD2avv8e5a//FzxTUuAxehSA1qKuZMYMiIZGDHhrOWxmM2xmMwBA5udn39iqPvgAmtFjIJFKULtrFyrXvo8B76zgxkhERC5B5+mOF8ZFddyxHVabwO/fOYAfKoDd/7keUzzMaCoqan1dLkJLyRWg3gp8d671dZ3E3R3K8HC4RURAGRkBZUQEVOFhCNb5dMGsyKmFndeECbBU/4KKVSthraiEMiYGIWvfs5+KbSktAyRSe/+aTR9DtLTg6ty5DuNos7MR8OwcAIDFWIHyN96EpaoK8gAtvCdNQsDs2fa+jefOo/HUaQDA5XHjHcYZvHs33Aa0fp2L+dv/Q+Waf0A0N0MZHYWBq/8Oj7Fjuz4JREREfZBMKsHzqXfjuU0nsObwVawBAAQA8gAgKhnoqGZsAnAWwNlS+DVexPG3/3hbXwJAbXP6N0+4sv76DB0iIuofbDaBpz46hryiys6vJETry2aDuP6vv7UB+SumdWls/fUzmKUxERER3RGpVIJ10xN/0xhCCNjq6rooIpJ23IWIiIioe0gkEj4qpQuxsCMiIiJyESzsiIiIiFwECzsiIiIiF8HCjoiIiMhFsLAjIiIichEs7IiIiIhcBAs7IiIiIhfBwo6IiIjIRbCwIyIiInIRLOyIiIiIXAQLOyIiIiIXwcKOiIiIyEWwsCMiIiJyESzsiIiIiFyE3NkBuDKbzQYAKCsrc3IkRERE/cuNz94bn8X9BQu7blReXg4AGDlypJMjISIi6p/Ky8sREhLi7DB6jEQIIZwdhKuyWCw4ceIEAgMDIZV23Vlvk8mE2NhYnD9/Hp6enl02LjG33Y357V7Mb/difrtXV+fXZrOhvLwcw4YNg1zef45jsbDrg2pra+Ht7Y1r167By8vL2eG4FOa2ezG/3Yv57V7Mb/difrsGb54gIiIichEs7IiIiIhcBAu7PkipVGLJkiVQKpXODsXlMLfdi/ntXsxv92J+uxfz2zV4jR0RERGRi+AROyIiIiIXwcKOiIiIyEWwsCMiIiJyESzsiIiIiFwEC7s+ZvXq1Rg0aBDc3d2RlJSEI0eOODukPiknJwcSicThFR0dbW9vbGxEdnY2/P394eHhgSlTpti/Io5u9e233+Khhx5CcHAwJBIJvvjiC4d2IQReffVV6PV6qFQqpKam4tKlSw59qqurkZGRAS8vL/j4+GDGjBkwm809OIveqaPcTp8+/ZZtOS0tzaEPc9u+ZcuWITExEZ6entDpdJg8eTIKCwsd+nRmf1BSUoKJEydCrVZDp9Nh/vz5sFgsPTmVXqczub3//vtv2X5nzZrl0Ie5vT0s7PqQTz75BC+88AKWLFmC7777DgkJCRg/fjyMRqOzQ+uThgwZgrKyMvvr4MGD9rZ58+bhyy+/xObNm3HgwAGUlpbikUcecWK0vVtdXR0SEhKwevXqNtuXL1+OlStXYs2aNSgoKIBGo8H48ePR2Nho75ORkYFz585h165d2L59O7799ltkZWX11BR6rY5yCwBpaWkO2/KmTZsc2pnb9h04cADZ2dk4fPgwdu3ahZaWFowbNw51dXX2Ph3tD6xWKyZOnIjm5mYcOnQIGzZswPr16/Hqq686Y0q9RmdyCwAzZ8502H6XL19ub2Nu74CgPmPkyJEiOzvb/t5qtYrg4GCxbNkyJ0bVNy1ZskQkJCS02VZTUyMUCoXYvHmzfdmFCxcEAJGfn99DEfZdAMSWLVvs7202mwgKChJvvfWWfVlNTY1QKpVi06ZNQgghzp8/LwCIo0eP2vvs2LFDSCQScfXq1R6Lvbe7ObdCCJGZmSkmTZrU7jrM7e0xGo0CgDhw4IAQonP7g6+//lpIpVJhMBjsfXJzc4WXl5doamrq2Qn0YjfnVggh7rvvPjF37tx212Fubx+P2PURzc3NOH78OFJTU+3LpFIpUlNTkZ+f78TI+q5Lly4hODgY4eHhyMjIQElJCQDg+PHjaGlpcch1dHQ0QkJCmOs7UFxcDIPB4JBPb29vJCUl2fOZn58PHx8fjBgxwt4nNTUVUqkUBQUFPR5zX7N//37odDpERUVh9uzZqKqqsrcxt7fn2rVrAAA/Pz8Andsf5OfnY+jQoQgMDLT3GT9+PGpra3Hu3LkejL53uzm3N2zcuBFarRZxcXFYuHAh6uvr7W3M7e2TOzsA6pzKykpYrVaHjRsAAgMDcfHiRSdF1XclJSVh/fr1iIqKQllZGZYuXYoxY8bg7NmzMBgMcHNzg4+Pj8M6gYGBMBgMzgm4D7uRs7a23RttBoMBOp3OoV0ul8PPz48570BaWhoeeeQRhIWF4fLly/jLX/6C9PR05OfnQyaTMbe3wWaz4fnnn8eoUaMQFxcHAJ3aHxgMhja37xtt1HZuAeDxxx9HaGgogoODcfr0aSxYsACFhYX4/PPPATC3d4KFHfVL6enp9p/j4+ORlJSE0NBQfPrpp1CpVE6MjOj2PPbYY/afhw4divj4eAwePBj79+9HSkqKEyPre7Kzs3H27FmH622pa7SX23++1nPo0KHQ6/VISUnB5cuXMXjw4J4O0yXwVGwfodVqIZPJbrkTq7y8HEFBQU6KynX4+Pjg7rvvRlFREYKCgtDc3IyamhqHPsz1nbmRs1/bdoOCgm65CchisaC6upo5v03h4eHQarUoKioCwNx21pw5c7B9+3bs27cPAwYMsC/vzP4gKCioze37Rlt/115u25KUlAQADtsvc3t7WNj1EW5ubhg+fDj27NljX2az2bBnzx4kJyc7MTLXYDabcfnyZej1egwfPhwKhcIh14WFhSgpKWGu70BYWBiCgoIc8llbW4uCggJ7PpOTk1FTU4Pjx4/b++zduxc2m82+o6fO+fnnn1FVVQW9Xg+Aue2IEAJz5szBli1bsHfvXoSFhTm0d2Z/kJycjDNnzjgU0Lt27YKXlxdiY2N7ZiK9UEe5bcvJkycBwGH7ZW5vk7Pv3qDO+/jjj4VSqRTr168X58+fF1lZWcLHx8fhbiHqnBdffFHs379fFBcXi7y8PJGamiq0Wq0wGo1CCCFmzZolQkJCxN69e8WxY8dEcnKySE5OdnLUvZfJZBInTpwQJ06cEADEihUrxIkTJ8RPP/0khBDijTfeED4+PmLr1q3i9OnTYtKkSSIsLEw0NDTYx0hLSxPDhg0TBQUF4uDBgyIyMlJMmzbNWVPqNX4ttyaTSbz00ksiPz9fFBcXi927d4t77rlHREZGisbGRvsYzG37Zs+eLby9vcX+/ftFWVmZ/VVfX2/v09H+wGKxiLi4ODFu3Dhx8uRJsXPnThEQECAWLlzojCn1Gh3ltqioSLz22mvi2LFjori4WGzdulWEh4eLsWPH2sdgbm8fC7s+ZtWqVSIkJES4ubmJkSNHisOHDzs7pD5p6tSpQq/XCzc3N3HXXXeJqVOniqKiInt7Q0ODeOaZZ4Svr69Qq9Xi4YcfFmVlZU6MuHfbt2+fAHDLKzMzUwjR+siTxYsXi8DAQKFUKkVKSoooLCx0GKOqqkpMmzZNeHh4CC8vL/Hkk08Kk8nkhNn0Lr+W2/r6ejFu3DgREBAgFAqFCA0NFTNnzrzljz3mtn1t5RaA+PDDD+19OrM/+PHHH0V6erpQqVRCq9WKF198UbS0tPTwbHqXjnJbUlIixo4dK/z8/IRSqRQRERFi/vz54tq1aw7jMLe3RyKEED13fJCIiIiIuguvsSMiIiJyESzsiIiIiFwECzsiIiIiF8HCjoiIiMhFsLAjIiIichEs7IiIiIhcBAs7IiIiIhfBwo6IqAtJJBJ88cUXzg6DiPopFnZE5DKmT58OiURyyystLc3ZoRER9Qi5swMgIupKaWlp+PDDDx2WKZVKJ0VDRNSzeMSOiFyKUqlEUFCQw8vX1xdA62nS3NxcpKenQ6VSITw8HJ999pnD+mfOnMGDDz4IlUoFf39/ZGVlwWw2O/RZt24dhgwZAqVSCb1ejzlz5ji0V1ZW4uGHH4ZarUZkZCS2bdvWvZMmIrqOhR0R9SuLFy/GlClTcOrUKWRkZOCxxx7DhQsXAAB1dXUYP348fH19cfToUWzevBm7d+92KNxyc3ORnZ2NrKwsnDlzBtu2bUNERITD71i6dCkeffRRnD59GhMmTEBGRgaqq6t7dJ5E1E8JIiIXkZmZKWQymdBoNA6v119/XQghBAAxa9Ysh3WSkpLE7NmzhRBCvPfee8LX11eYzWZ7+1dffSWkUqkwGAxCCCGCg4PFK6+80m4MAMSiRYvs781mswAgduzY0WXzJCJqD6+xIyKX8sADDyA3N9dhmZ+fn/3n5ORkh7bk5GScPHkSAHDhwgUkJCRAo9HY20eNGgWbzYbCwkJIJBKUlpYiJSXlV2OIj4+3/6zRaODl5QWj0XinUyIi6jQWdkTkUjQazS2nRruKSqXqVD+FQuHwXiKRwGazdUdIREQOeI0dEfUrhw8fvuV9TEwMACAmJganTp1CXV2dvT0vLw9SqRRRUVHw9PTEoEGDsGfPnh6NmYios3jEjohcSlNTEwwGg8MyuVwOrVYLANi8eTNGjBiB0aNHY+PGjThy5Ag++OADAEBGRgaWLFmCzMxM5OTkoKKiAs8++yyeeOIJBAYGAgBycnIwa9Ys6HQ6pKenw2QyIS8vD88++2zPTpSIqA0s7IjIpezcuRN6vd5hWVRUFC5evAig9Y7Vjz/+GM888wz0ej02bdqE2NhYAIBarcY333yDuXPnIjExEWq1GlOmTMGKFSvsY2VmZqKxsRHvvPMOXnrpJWi1WvzhD3/ouQkSEf0KiRBCODsIIqKeIJFIsGXLFkyePNnZoRARdQteY0dERETkIljYEREREbkIXmNHRP0GrzwhIlfHI3ZERERELoKFHREREZGLYGFHRERE5CJY2BERERG5CBZ2RERERC6ChR0RERGRi2BhR0REROQiWNgRERERuQgWdkREREQu4v8BOyvsY2Ju/q4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.metrics import CategoricalCrossentropy\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.config['num_epochs']):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(self.config['num_epochs'])\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.Huber())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=1, batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "NtqOnH-s3X9q",
        "outputId": "66d1695d-66b8-490c-9a7d-a584c93b090a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2452 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.metrics import CategoricalCrossentropy\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.config['num_epochs']):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(self.config['num_epochs'])\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.Huber())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rvf7gLHxj4J9",
        "outputId": "abe38869-b2b6-435c-c869-6d3dd48cfc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3429 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3428 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3427 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3427 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3426 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3426 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3425 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3425 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3425 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3425 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3424 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3424 - lr: 6.5610e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.metrics import CategoricalCrossentropy\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 200)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.Huber())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=200, batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(200):  # Or any other number of epochs you want to experiment with\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8bInN4-rmBnq",
        "outputId": "a7410c3f-e917-49cc-9aa3-e8c6a88d6324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3925 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3924 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3923 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.999999772640877e-06.\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3923 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3922 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3922 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.999999408842996e-06.\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3922 - lr: 9.0000e-06\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 8.099999467958696e-06.\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3922 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3921 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3921 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3921 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 8.099999831756577e-06.\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3921 - lr: 8.1000e-06\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.28999984858092e-06.\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3921 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3920 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3920 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3920 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 7.289999757631449e-06.\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3920 - lr: 7.2900e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.560999781868304e-06.\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3920 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3919 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.560999736393569e-06.\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3919 - lr: 6.5610e-06\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 5.904899762754212e-06.\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 5.904899808228947e-06.\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3919 - lr: 5.9049e-06\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 5.314409827406053e-06.\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 5.314409918355523e-06.\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 5.3144e-06\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 4.782968926519971e-06.\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3918 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3918 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3918 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3918 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3917 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3917 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 4.7829689719947055e-06.\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3917 - lr: 4.7830e-06\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 4.304672074795235e-06.\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3917 - lr: 4.3047e-06\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 3.874204867315711e-06.\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3917 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 3.874205049214652e-06.\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.8742e-06\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 3.4867845442931865e-06.\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 3.486784635242657e-06.\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3916 - lr: 3.4868e-06\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 3.138106171718391e-06.\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3916 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3916 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3916 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3916 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3916 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3915 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3915 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 3.1381061944557587e-06.\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3915 - lr: 3.1381e-06\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 2.824295575010183e-06.\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 2.82429550679808e-06.\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 2.8243e-06\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 2.5418659561182724e-06.\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 2.5418660243303748e-06.\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3915 - lr: 2.5419e-06\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 2.2876794218973373e-06.\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3915 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3915 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3915 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 2.2876793082104996e-06.\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 2.2877e-06\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 2.0589113773894496e-06.\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3914 - lr: 2.0589e-06\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 1.8530202396505047e-06.\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 1.8530201941757696e-06.\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.8530e-06\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 1.6677181747581927e-06.\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 1.667718152020825e-06.\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3914 - lr: 1.6677e-06\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 1.5009463368187425e-06.\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3914 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3914 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 1.5009463822934777e-06.\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3913 - lr: 1.5009e-06\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 1.3508517440641298e-06.\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3913 - lr: 1.3509e-06\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 1.350851789538865e-06.\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3913 - lr: 1.3509e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.information_rates = []\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        results = self.result()\n",
        "        self.capacity_estimates.append(results[0].numpy())\n",
        "        self.dine_estimates.append(results[2].numpy())\n",
        "        self.information_rates.append(results[3].numpy())\n",
        "\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        epochs = range(len(self.capacity_estimates))\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(epochs, self.capacity_estimates, label='Capacity Estimate')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Capacity Estimate')\n",
        "        plt.title('Capacity Estimate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(epochs, self.dine_estimates, label='DINE Estimate', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('DINE Estimate')\n",
        "        plt.title('DINE Estimate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(epochs, self.information_rates, label='Information Rate', color='green')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Information Rate')\n",
        "        plt.title('Information Rate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        results = self.result()\n",
        "        self.capacity_estimates.append(results[0].numpy())\n",
        "        self.dine_estimates.append(results[2].numpy())\n",
        "        self.information_rates.append(results[4].numpy())\n",
        "\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        epochs = range(len(self.capacity_estimates))\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(epochs, self.capacity_estimates, label='Capacity Estimate')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Capacity Estimate')\n",
        "        plt.title('Capacity Estimate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(epochs, self.dine_estimates, label='DINE Estimate', color='orange')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('DINE Estimate')\n",
        "        plt.title('DINE Estimate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(epochs, self.information_rates, label='Information Rate', color='green')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Information Rate')\n",
        "        plt.title('Information Rate over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 200)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.Huber())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=200, batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(200):  # Or any other number of epochs you want to experiment with\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting Capacity Estimate, DINE Estimate, and Information Rate\n",
        "metrics.plot_metrics()\n"
      ],
      "metadata": {
        "id": "ZJ6Vnd_qpcd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data integrity\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9AAVo-9QqS3",
        "outputId": "d4e7f2d4-93ce-4783-c295-6617654d48bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class GridWorldMDP:\n",
        "    def __init__(self, grid_size, start_state, goal_state):\n",
        "        self.grid_size = grid_size\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "        self.state = start_state\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start_state\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        # Define possible actions: 0=up, 1=right, 2=down, 3=left\n",
        "        if action == 0 and self.state[0] > 0:\n",
        "            self.state = (self.state[0] - 1, self.state[1])\n",
        "        elif action == 1 and self.state[1] < self.grid_size[1] - 1:\n",
        "            self.state = (self.state[0], self.state[1] + 1)\n",
        "        elif action == 2 and self.state[0] < self.grid_size[0] - 1:\n",
        "            self.state = (self.state[0] + 1, self.state[1])\n",
        "        elif action == 3 and self.state[1] > 0:\n",
        "            self.state = (self.state[0], self.state[1] - 1)\n",
        "\n",
        "        reward = -1  # default reward for non-terminal states\n",
        "        done = False\n",
        "        if self.state == self.goal_state:\n",
        "            reward = 0  # reward for reaching the goal\n",
        "            done = True\n",
        "\n",
        "        return self.state, reward, done\n",
        "\n",
        "class PolicyNetwork(tf.keras.Model):\n",
        "    def __init__(self, action_size):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(24, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
        "        self.logits = tf.keras.layers.Dense(action_size)\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        x = self.dense2(x)\n",
        "        return self.logits(x)\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        T_value = self.T / self.global_counter\n",
        "        exp_T_bar_value = self.exp_T_bar / self.global_counter_ref\n",
        "\n",
        "        # Ensure exp_T_bar_value is not zero to avoid log(0)\n",
        "        exp_T_bar_value = tf.maximum(exp_T_bar_value, 1e-10)\n",
        "\n",
        "        loss = T_value - K.log(exp_T_bar_value)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='di_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        # Check for NaNs before computing the loss\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='di_bits_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        # Check for NaNs before computing the loss\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI_bits result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='pmf_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "\n",
        "        # Check for NaNs before returning the result\n",
        "        if tf.math.is_nan(result):\n",
        "            tf.print(\"NaN detected in PMF result calculation\")\n",
        "            tf.print(\"result:\", result)\n",
        "\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = negative_log_likelihood\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config, mdp, policy_network):\n",
        "        self.config = config\n",
        "        self.mdp = mdp  # Add MDP environment\n",
        "        self.policy_network = policy_network\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
        "        self.gamma = 0.99  # Discount factor for rewards\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.initialize_channel()\n",
        "        self.y = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        self.state = self.mdp.reset()\n",
        "        self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "        self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        self.s = self.s_past  # Initialize self.s\n",
        "\n",
        "    def gen_data(self):\n",
        "        x_l, y_l = [], []\n",
        "        states, actions, rewards = [], [], []\n",
        "        done = False\n",
        "        self.state = self.mdp.reset()\n",
        "\n",
        "        for _ in range(self.config['bptt']):\n",
        "            # Convert state to TensorFlow tensor\n",
        "            state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "            state_tensor = tf.expand_dims(state_tensor, axis=0)  # Add batch dimension\n",
        "\n",
        "            # Get policy network logits and probabilities\n",
        "            logits = self.policy_network(state_tensor)\n",
        "            action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "            # Sample action\n",
        "            action = tf.random.categorical(logits, 1)[0, 0]\n",
        "            action_int = int(action.numpy())\n",
        "\n",
        "            # Take a step in the MDP environment\n",
        "            new_state, reward, done = self.mdp.step(action_int)\n",
        "\n",
        "            # Store data for training\n",
        "            states.append(state_tensor)\n",
        "            actions.append(action_int)  # Store the action taken\n",
        "            rewards.append(reward)\n",
        "            x_l.append(self.x)  # Assuming self.x is already a TensorFlow tensor\n",
        "            y_l.append(self.y)  # Assuming self.y is already a TensorFlow tensor\n",
        "\n",
        "            # Update state based on done flag\n",
        "            if done:\n",
        "                self.state = self.mdp.reset()  # Reset the MDP if done\n",
        "            else:\n",
        "                self.state = new_state\n",
        "\n",
        "        # Concatenate data for training\n",
        "        x = tf.concat(x_l, axis=0)  # Concatenate along the batch axis (assuming x_l are batched tensors)\n",
        "        y = tf.concat(y_l, axis=0)  # Concatenate along the batch axis (assuming y_l are batched tensors)\n",
        "\n",
        "        # Perform policy gradient update (assumed to be in a separate function)\n",
        "        self.update_policy(states, actions, rewards)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    # def update_policy(self, states, actions, rewards):\n",
        "    #     G = 0\n",
        "    #     returns = []\n",
        "    #     for r in rewards[::-1]:\n",
        "    #         G = r + self.gamma * G\n",
        "    #         returns.insert(0, G)\n",
        "    #     returns = tf.convert_to_tensor(returns, dtype=tf.float32)\n",
        "\n",
        "    #     with tf.GradientTape() as tape:\n",
        "    #         loss = 0\n",
        "    #         for state, action, G in zip(states, actions, returns):\n",
        "    #             logits = self.policy_network(state, training=True)\n",
        "    #             action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "    #             action = tf.expand_dims(action, axis=-1)  # Ensure action has correct shape\n",
        "    #             action_prob = tf.gather_nd(action_probs, action, batch_dims=1)  # Correctly gather the action probability\n",
        "\n",
        "    #             loss -= tf.math.log(action_prob + 1e-10) * G  # Policy gradient loss\n",
        "\n",
        "    #         gradients = tape.gradient(loss, self.policy_network.trainable_variables)\n",
        "    #         self.optimizer.apply_gradients(zip(gradients, self.policy_network.trainable_variables))\n",
        "\n",
        "    def update_policy(self, states, actions, rewards):\n",
        "\n",
        "      G = 0\n",
        "      returns = []\n",
        "      for r in rewards[::-1]:\n",
        "          G = r + self.gamma * G\n",
        "          returns.insert(0, G)\n",
        "      returns = tf.convert_to_tensor(returns, dtype=tf.float32)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          loss = 0\n",
        "          for state, action, G in zip(states, actions, returns):\n",
        "              logits = self.policy_network(state, training=True)\n",
        "              action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "              # Ensure action is a 2D tensor\n",
        "              action = tf.convert_to_tensor([action], dtype=tf.int32)\n",
        "              action_prob = tf.reduce_sum(action_probs * tf.one_hot(action, depth=4), axis=-1)\n",
        "\n",
        "              loss -= tf.math.log(action_prob + 1e-10) * G  # Policy gradient loss\n",
        "\n",
        "          gradients = tape.gradient(loss, self.policy_network.trainable_variables)\n",
        "          self.optimizer.apply_gradients(zip(gradients, self.policy_network.trainable_variables))\n",
        "\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.state = self.mdp.reset()\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "            self.s = self.s_past  # Initialize self.s\n",
        "        else:\n",
        "            state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "            state_tensor = tf.expand_dims(state_tensor, axis=0)  # Add batch dimension\n",
        "            logits = self.policy_network(state_tensor)\n",
        "            action_probs = tf.nn.softmax(logits)\n",
        "            action = np.random.choice(4, p=action_probs.numpy().flatten())  # Sample action from policy\n",
        "            new_state, reward, done = self.mdp.step(action)\n",
        "\n",
        "            z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Negative Log-Likelihood Loss Function\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'ising',  # Updated from 'trapdoor' to 'ising'\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the MDP environment\n",
        "mdp = GridWorldMDP(grid_size=(5, 5), start_state=(0, 0), goal_state=(4, 4))\n",
        "\n",
        "# Initialize the policy network\n",
        "policy_network = PolicyNetwork(action_size=4)\n",
        "\n",
        "# Initialize the data generator with the MDP and policy network\n",
        "ising_data = Ising_Data(config, mdp, policy_network)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yWhb2FrvHvCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "138cd971-ef52-4daa-ff48-fce510672e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7c52d436ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7c52d436ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 6, 2), found shape=(100, 1, 2)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d31c53d5346a>\u001b[0m in \u001b[0;36m<cell line: 586>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;31m# Train the model to capture the loss history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m \u001b[0mcomplex_model_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_y_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;31m# Initialize metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 6, 2), found shape=(100, 1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class GridWorldMDP:\n",
        "    def __init__(self, grid_size, start_state, goal_state):\n",
        "        self.grid_size = grid_size\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "        self.state = start_state\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start_state\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        # Define possible actions: 0=up, 1=right, 2=down, 3=left\n",
        "        if action == 0 and self.state[0] > 0:\n",
        "            self.state = (self.state[0] - 1, self.state[1])\n",
        "        elif action == 1 and self.state[1] < self.grid_size[1] - 1:\n",
        "            self.state = (self.state[0], self.state[1] + 1)\n",
        "        elif action == 2 and self.state[0] < self.grid_size[0] - 1:\n",
        "            self.state = (self.state[0] + 1, self.state[1])\n",
        "        elif action == 3 and self.state[1] > 0:\n",
        "            self.state = (self.state[0], self.state[1] - 1)\n",
        "\n",
        "        reward = -1  # default reward for non-terminal states\n",
        "        done = False\n",
        "        if self.state == self.goal_state:\n",
        "            reward = 0  # reward for reaching the goal\n",
        "            done = True\n",
        "\n",
        "        return self.state, reward, done\n",
        "\n",
        "class PolicyNetwork(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, action_size):\n",
        "          super(PolicyNetwork, self).__init__()\n",
        "          self.dense1 = tf.keras.layers.Dense(24, activation='relu')\n",
        "          self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
        "          self.logits = tf.keras.layers.Dense(action_size)  # Ensure action_size = 4\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        x = self.dense2(x)\n",
        "        return self.logits(x)  # Output shape [batch_size, action_size]\n",
        "    # def __init__(self, action_size):\n",
        "    #     super(PolicyNetwork, self).__init__()\n",
        "    #     self.dense1 = tf.keras.layers.Dense(24, activation='relu')\n",
        "    #     self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
        "    #     self.logits = tf.keras.layers.Dense(action_size)\n",
        "\n",
        "    # def call(self, state):\n",
        "    #     x = self.dense1(state)\n",
        "    #     x = self.dense2(x)\n",
        "    #     return self.logits(x)\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        T_value = self.T / self.global_counter\n",
        "        exp_T_bar_value = self.exp_T_bar / self.global_counter_ref\n",
        "\n",
        "        # Ensure exp_T_bar_value is not zero to avoid log(0)\n",
        "        exp_T_bar_value = tf.maximum(exp_T_bar_value, 1e-10)\n",
        "\n",
        "        loss = T_value - K.log(exp_T_bar_value)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        # Check for NaNs before computing the loss\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        # Check for NaNs before computing the loss\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI_bits result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "\n",
        "        # Check for NaNs before returning the result\n",
        "        if tf.math.is_nan(result):\n",
        "            tf.print(\"NaN detected in PMF result calculation\")\n",
        "            tf.print(\"result:\", result)\n",
        "\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = negative_log_likelihood\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config, mdp, policy_network):\n",
        "        self.config = config\n",
        "        self.mdp = mdp  # Add MDP environment\n",
        "        self.policy_network = policy_network\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
        "        self.gamma = 0.99  # Discount factor for rewards\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.initialize_channel()\n",
        "        self.y = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        self.state = self.mdp.reset()\n",
        "        self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "        self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        self.s = self.s_past  # Initialize self.s\n",
        "\n",
        "    # def gen_data(self):\n",
        "    #     x_l, y_l = [], []\n",
        "    #     states, actions, rewards = [], [], []\n",
        "    #     done = False\n",
        "    #     self.state = self.mdp.reset()\n",
        "\n",
        "    #     for _ in range(self.config['bptt']):\n",
        "    #         # Convert state to TensorFlow tensor\n",
        "    #         state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "    #         state_tensor = tf.expand_dims(state_tensor, axis=0)  # Add batch dimension\n",
        "\n",
        "    #         # Get policy network logits and probabilities\n",
        "    #         logits = self.policy_network(state_tensor)\n",
        "    #         action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "    #         # Sample action\n",
        "    #         action = tf.random.categorical(logits, 1)[0, 0]\n",
        "    #         action_int = int(action.numpy())\n",
        "\n",
        "    #         # Take a step in the MDP environment\n",
        "    #         new_state, reward, done = self.mdp.step(action_int)\n",
        "\n",
        "    #         # Store data for training\n",
        "    #         states.append(state_tensor)\n",
        "    #         actions.append(action_int)  # Store the action taken\n",
        "    #         rewards.append(reward)\n",
        "    #         x_l.append(self.x)  # Assuming self.x is already a TensorFlow tensor\n",
        "    #         y_l.append(self.y)  # Assuming self.y is already a TensorFlow tensor\n",
        "\n",
        "    #         # Update state based on done flag\n",
        "    #         if done:\n",
        "    #             self.state = self.mdp.reset()  # Reset the MDP if done\n",
        "    #         else:\n",
        "    #             self.state = new_state\n",
        "\n",
        "    #     # Concatenate data for training\n",
        "    #     x = tf.concat(x_l, axis=0)  # Concatenate along the batch axis (assuming x_l are batched tensors)\n",
        "    #     y = tf.concat(y_l, axis=0)  # Concatenate along the batch axis (assuming y_l are batched tensors)\n",
        "\n",
        "    #     # Perform policy gradient update (assumed to be in a separate function)\n",
        "    #     self.update_policy(states, actions, rewards)\n",
        "\n",
        "    #     return x, y\n",
        "\n",
        "\n",
        "    def gen_data(self):\n",
        "      x_l, y_l = [], []  # Correct initialization of two empty lists\n",
        "      states, actions, rewards = [], [], []\n",
        "      done = False\n",
        "      self.state = self.mdp.reset()\n",
        "\n",
        "      for _ in range(self.config['bptt']):\n",
        "          state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "          state_tensor = tf.expand_dims(state_tensor, axis=0)  # Add batch dimension\n",
        "\n",
        "          logits = self.policy_network(state_tensor)\n",
        "          action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "          action = tf.random.categorical(logits, 1)[0, 0]\n",
        "          action_int = int(action.numpy())\n",
        "\n",
        "          new_state, reward, done = self.mdp.step(action_int)\n",
        "\n",
        "          states.append(logits)\n",
        "          actions.append(action_int)\n",
        "          rewards.append(reward)\n",
        "          x_l.append(state_tensor)\n",
        "          y_l.append(tf.convert_to_tensor(reward, dtype=tf.float32))\n",
        "\n",
        "          if done:\n",
        "              self.state = self.mdp.reset()\n",
        "          else:\n",
        "              self.state = new_state\n",
        "\n",
        "      x = tf.concat(x_l, axis=0)\n",
        "      y = tf.stack(y_l, axis=0)\n",
        "\n",
        "      self.update_policy(states, actions, rewards)\n",
        "\n",
        "      return x, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def update_policy(self, states, actions, rewards):\n",
        "      G = 0\n",
        "      returns = []\n",
        "      for r in rewards[::-1]:\n",
        "          G = r + self.gamma * G\n",
        "          returns.insert(0, G)\n",
        "      returns = tf.convert_to_tensor(returns, dtype=tf.float32)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          loss = 0\n",
        "          for logit, action, G in zip(states, actions, returns):\n",
        "              logit = tf.expand_dims(logit, axis=0)  # Ensure batch dimension\n",
        "\n",
        "              action_prob = tf.nn.softmax(logit)  # Output shape [1, action_size]\n",
        "\n",
        "              # Create one-hot encoding for the action\n",
        "              one_hot_action = tf.one_hot(action, depth=4)  # Shape [4]\n",
        "              one_hot_action = tf.expand_dims(one_hot_action, axis=0)  # Shape [1, 4]\n",
        "\n",
        "              # Debugging: Print shapes to check compatibility\n",
        "              print(\"action_prob shape:\", action_prob.shape)\n",
        "              print(\"one_hot_action shape:\", one_hot_action.shape)\n",
        "\n",
        "              # Compute the selected action probability\n",
        "              selected_action_prob = tf.reduce_sum(action_prob * one_hot_action, axis=-1)  # Shape [1]\n",
        "\n",
        "              # Compute the policy gradient loss\n",
        "              loss -= tf.reduce_sum(tf.math.log(selected_action_prob + 1e-10) * G)\n",
        "\n",
        "          gradients = tape.gradient(loss, self.policy_network.trainable_variables)\n",
        "          self.optimizer.apply_gradients(zip(gradients, self.policy_network.trainable_variables))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.state = self.mdp.reset()\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "            self.s = self.s_past  # Initialize self.s\n",
        "        else:\n",
        "            state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "            state_tensor = tf.expand_dims(state_tensor, axis=0)  # Add batch dimension\n",
        "            logits = self.policy_network(state_tensor)\n",
        "            action_probs = tf.nn.softmax(logits)\n",
        "            action = np.random.choice(4, p=action_probs.numpy().flatten())  # Sample action from policy\n",
        "            new_state, reward, done = self.mdp.step(action)\n",
        "\n",
        "            z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "# Negative Log-Likelihood Loss Function\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'ising',  # Updated from 'trapdoor' to 'ising'\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the MDP environment\n",
        "mdp = GridWorldMDP(grid_size=(5, 5), start_state=(0, 0), goal_state=(4, 4))\n",
        "\n",
        "# Initialize the policy network\n",
        "policy_network = PolicyNetwork(action_size=4)\n",
        "\n",
        "# Initialize the data generator with the MDP and policy network\n",
        "ising_data = Ising_Data(config, mdp, policy_network)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "cap_est = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Train the model and evaluate\n",
        "cap_est.train()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(loss_history.losses, label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(loss_history.lr, label='Learning Rate')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(cap_est.capacity_estimates, label='Capacity Estimate')\n",
        "plt.plot(cap_est.dine_estimates, label='DINE Estimate')\n",
        "plt.plot(cap_est.info_rates, label='Information Rate')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Estimate Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G5pC6s2FrYVh",
        "outputId": "21002e96-c84c-427e-c469-59d6452ffbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No gradients provided for any variable: (['policy_network_18/dense_60/kernel:0', 'policy_network_18/dense_60/bias:0', 'policy_network_18/dense_61/kernel:0', 'policy_network_18/dense_61/bias:0', 'policy_network_18/dense_62/kernel:0', 'policy_network_18/dense_62/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'policy_network_18/dense_60/kernel:0' shape=(2, 24) dtype=float32, numpy=\narray([[ 0.19772297,  0.16391057, -0.4354878 , -0.26920357, -0.08627912,\n        -0.2127468 , -0.36556247, -0.25025576,  0.0199492 , -0.36509082,\n        -0.41536754, -0.09583846, -0.20232937, -0.46553233,  0.33525163,\n         0.22814226,  0.27558017, -0.4760502 , -0.05653453, -0.21421865,\n        -0.04016429,  0.13629788,  0.30385554,  0.08088315],\n       [ 0.44552648,  0.2851953 , -0.35981488, -0.3823621 ,  0.15523553,\n         0.37473184, -0.3963881 , -0.00318608,  0.01908273, -0.0777187 ,\n         0.11437511,  0.17452383, -0.23193318,  0.06176972,  0.16178608,\n         0.33903718, -0.0317916 , -0.2086102 , -0.12215507, -0.04659301,\n        -0.2603786 , -0.29596674, -0.19402987, -0.16435322]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_60/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_61/kernel:0' shape=(24, 24) dtype=float32, numpy=\narray([[ 0.18646863, -0.23797442,  0.2387962 , -0.3279072 , -0.20933665,\n         0.15025231,  0.30740854,  0.21738872, -0.07141876,  0.1913484 ,\n        -0.26960227,  0.08953795,  0.03639373, -0.08234972,  0.17490056,\n         0.33271185, -0.23513372,  0.0153062 , -0.000893  , -0.27217346,\n         0.02968529,  0.21039537,  0.2131925 , -0.12304848],\n       [-0.09896857, -0.3222649 ,  0.31906292,  0.107557  ,  0.2826908 ,\n         0.10983166,  0.09859717, -0.02100161, -0.3073945 ,  0.34991613,\n         0.08243233,  0.02511218,  0.20785007, -0.10177234,  0.25024614,\n        -0.15612027,  0.02372918,  0.08226448,  0.11318427, -0.22821894,\n        -0.12424655,  0.1345737 ,  0.11159566, -0.27160752],\n       [ 0.21405879,  0.06017828, -0.15200108,  0.18950209, -0.0740892 ,\n        -0.19009729,  0.23969004,  0.05128303,  0.11111149, -0.23026323,\n         0.2313343 , -0.10830526, -0.0143826 ,  0.2999234 ,  0.08144212,\n         0.1375764 ,  0.21113005, -0.2528075 , -0.24162096,  0.0814411 ,\n        -0.09783211,  0.25251207, -0.20317343,  0.13841093],\n       [ 0.11331457, -0.18177716,  0.226634  ,  0.23625055,  0.33247277,\n        -0.28853437, -0.05459392,  0.29430172, -0.18630475, -0.24049127,\n        -0.06550312,  0.32625607,  0.27666798,  0.03794134, -0.20064715,\n        -0.20846194, -0.03999105, -0.15565783, -0.31159568,  0.31517962,\n         0.21718934,  0.02713826, -0.3412615 ,  0.27988544],\n       [ 0.12247393, -0.19691066, -0.03605175,  0.25203303, -0.32917035,\n        -0.22816205,  0.15962169,  0.11822984,  0.3293316 , -0.1345174 ,\n        -0.04139555,  0.04732156, -0.12490766,  0.08094698,  0.11230281,\n         0.27682093, -0.27932817, -0.30049026, -0.03065374, -0.31669107,\n         0.19866213,  0.01129544, -0.04518986,  0.14290345],\n       [-0.08522001,  0.08308703,  0.35056683,  0.29698458, -0.0845733 ,\n        -0.01160556, -0.02110797,  0.16248122, -0.29288435, -0.03114542,\n        -0.21836197,  0.27457592, -0.11307156,  0.21166071,  0.33149996,\n        -0.12851551, -0.16334103, -0.23985341, -0.06829011, -0.07881588,\n        -0.3309604 ,  0.07298908,  0.16959098,  0.14352426],\n       [-0.18496616, -0.03449264,  0.3112764 , -0.17096068, -0.00459197,\n        -0.13524106,  0.19768164,  0.21879068, -0.2657577 , -0.1884683 ,\n        -0.02367422,  0.04107091, -0.12034568,  0.26111218,  0.21402505,\n         0.20999762,  0.3361645 ,  0.04592311, -0.20833322, -0.2388488 ,\n        -0.07854941,  0.09521511,  0.31349894,  0.22327486],\n       [-0.09230953, -0.07594618, -0.23215225,  0.0922704 ,  0.16785899,\n        -0.15346915, -0.01791164,  0.15163216, -0.3457112 , -0.0354594 ,\n         0.06894946,  0.34284928, -0.27600715,  0.11770543, -0.09918493,\n        -0.31942168, -0.14921114,  0.29858866,  0.29220417, -0.1797536 ,\n         0.19522312, -0.27679572, -0.0233244 , -0.1666381 ],\n       [-0.21938244, -0.26812282,  0.29120603, -0.13302532,  0.09983671,\n        -0.07164231,  0.16623971,  0.28091028, -0.20936835, -0.25674048,\n        -0.0362381 ,  0.15459666, -0.03687453, -0.16790275,  0.10826918,\n         0.1938385 , -0.19747889, -0.07239076, -0.22208767,  0.23777238,\n        -0.29254448, -0.1487755 ,  0.06041238,  0.1028828 ],\n       [-0.14266674, -0.04467979,  0.06919721, -0.01895496, -0.04450235,\n        -0.20351928, -0.26340348,  0.19835666, -0.30360827,  0.11936492,\n         0.22164735,  0.17820647,  0.02866128,  0.01480097, -0.00687501,\n        -0.12028348,  0.13905045, -0.01278651, -0.09972847,  0.20128068,\n         0.02679807,  0.02260715, -0.32713187, -0.1885553 ],\n       [-0.34510875, -0.13358848,  0.2367867 ,  0.211732  ,  0.24803081,\n        -0.09513217,  0.1279585 ,  0.05940127,  0.07194003, -0.29756197,\n         0.32209036,  0.23121211,  0.24562481,  0.27676418,  0.05046201,\n         0.3178744 ,  0.02746162,  0.03293902,  0.17159417, -0.31026065,\n         0.25135496,  0.24852899, -0.22143549, -0.14767076],\n       [-0.06905213,  0.00392017,  0.13229492, -0.10830374,  0.31786916,\n        -0.25472763,  0.2328277 ,  0.18121347, -0.30121696, -0.29393566,\n         0.09653735, -0.02665105, -0.28053457,  0.05603492,  0.0808309 ,\n        -0.02046433, -0.11509317,  0.23188052,  0.2629359 ,  0.05137053,\n         0.08622992,  0.03491327, -0.09308502, -0.0877907 ],\n       [-0.2843357 ,  0.23045668,  0.02149937, -0.15048465,  0.1882483 ,\n        -0.07747331, -0.13365625, -0.3454804 , -0.12779118, -0.2314237 ,\n        -0.1253347 ,  0.1410585 ,  0.3225697 ,  0.2895364 ,  0.26271662,\n         0.06072924, -0.21437505, -0.33449164,  0.10882661, -0.00695929,\n        -0.11498031, -0.03992924,  0.1282123 ,  0.09236413],\n       [ 0.0574035 ,  0.0464443 , -0.22757308, -0.21443717,  0.25955835,\n        -0.26863506,  0.2627807 ,  0.34047326,  0.07137239,  0.19317493,\n         0.24777219, -0.13518795, -0.34979725,  0.26800933,  0.35122922,\n         0.20053068,  0.08304217,  0.2999594 , -0.22044817,  0.0622896 ,\n        -0.2177038 , -0.02186301, -0.20992376,  0.00951457],\n       [-0.01220125,  0.3014336 ,  0.31622317, -0.24455792,  0.31382427,\n        -0.10827053,  0.28641203,  0.2100533 ,  0.06112304,  0.26042226,\n         0.28574768,  0.02124387,  0.16716132, -0.27170604, -0.2814058 ,\n        -0.05355877, -0.28775844, -0.01668459, -0.29938346, -0.04036093,\n         0.27390024, -0.2931379 , -0.16390091, -0.03324771],\n       [ 0.22075573, -0.31892148,  0.21477947,  0.12461844,  0.33316275,\n         0.27608934,  0.12112111,  0.03797489,  0.19855049, -0.17950991,\n        -0.00886795, -0.27076423, -0.08090138,  0.05134994, -0.27806103,\n        -0.00811604, -0.11230786, -0.271707  , -0.25723234,  0.09446678,\n        -0.20865555, -0.14452298,  0.11922896, -0.18775038],\n       [ 0.03985238, -0.04332012,  0.12369519,  0.25269744, -0.18133429,\n         0.15783235, -0.21996643,  0.104873  ,  0.04667526, -0.31472072,\n         0.08362162, -0.25499037,  0.21976843, -0.09340146, -0.25705785,\n        -0.02607557, -0.14309528,  0.02666259, -0.30909336, -0.11057605,\n         0.2397807 ,  0.17624125,  0.2792183 , -0.14233842],\n       [ 0.02503413,  0.19904843, -0.1717516 , -0.00558707, -0.31953   ,\n        -0.07258546,  0.28592566, -0.1536497 ,  0.25317243, -0.23349926,\n        -0.09572408, -0.27030265,  0.20357141, -0.14049357, -0.30573636,\n        -0.30866075,  0.12979838,  0.17591318,  0.00961295, -0.07751742,\n        -0.24733397,  0.30321   , -0.34409225,  0.2548848 ],\n       [-0.24113813, -0.11487646, -0.09808549,  0.20698765,  0.05000412,\n        -0.00434777,  0.06335109, -0.01965535, -0.01956406,  0.14439857,\n         0.29709223,  0.16887954, -0.19850129,  0.04871678, -0.08018902,\n        -0.13608113,  0.23657474,  0.10780573,  0.18933621, -0.33052436,\n        -0.20302095,  0.21480158,  0.28553352, -0.32309705],\n       [-0.1989338 ,  0.04422149,  0.27267972, -0.10930869,  0.18014356,\n        -0.08557892,  0.03317648, -0.18327093, -0.2527265 ,  0.0463022 ,\n        -0.12949619, -0.30432746, -0.15480386,  0.2732542 , -0.06227112,\n         0.16644362,  0.2798011 ,  0.0732621 ,  0.34460196,  0.293986  ,\n         0.23586562,  0.07284123,  0.18864211, -0.2226344 ],\n       [ 0.30948433, -0.11560434, -0.27955523, -0.01668644,  0.32861587,\n        -0.15525112,  0.16649553,  0.17273018, -0.34646708,  0.27665594,\n         0.1670408 , -0.14017949, -0.13053714,  0.14518821,  0.1945925 ,\n        -0.28801706,  0.03096774, -0.27979404, -0.21980247, -0.18703136,\n        -0.2560218 ,  0.01107493, -0.10115749,  0.32770357],\n       [-0.05131209,  0.08067656, -0.10280839, -0.11370806,  0.13609067,\n         0.01463592,  0.055318  ,  0.0330883 ,  0.00542125,  0.07465294,\n        -0.13333973, -0.1330882 , -0.11590013, -0.34664804, -0.05291697,\n        -0.28102735, -0.16253552, -0.12015502,  0.23048863,  0.24682191,\n        -0.02985209, -0.09166089, -0.18509573,  0.22615579],\n       [ 0.17306307,  0.06749749,  0.27066275, -0.1693242 ,  0.14010319,\n         0.0053378 , -0.32535502,  0.08616349,  0.3282092 , -0.17629841,\n        -0.01645091, -0.10461067, -0.05019158,  0.12688637, -0.04635412,\n         0.04581514, -0.14814566,  0.34153178,  0.09350345, -0.20381355,\n         0.22632012, -0.21770474, -0.29780617, -0.24019969],\n       [ 0.25134233, -0.2287119 , -0.14694549, -0.28296643,  0.32408836,\n        -0.08084044, -0.20932552, -0.31434298,  0.12886524, -0.13325013,\n        -0.33129242, -0.10539384, -0.25932232,  0.16061625, -0.20785207,\n        -0.28641826,  0.13477904, -0.15905984, -0.3140634 ,  0.01030153,\n         0.34889933,  0.19750592, -0.13467772, -0.12345216]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_61/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_62/kernel:0' shape=(24, 4) dtype=float32, numpy=\narray([[ 0.40529817,  0.41296077,  0.07118267, -0.44995436],\n       [-0.24593234,  0.34680176,  0.16797209,  0.3995493 ],\n       [ 0.10814989,  0.32899463, -0.45870465,  0.10060829],\n       [-0.3592777 ,  0.25602126,  0.270997  ,  0.06891042],\n       [ 0.34091747, -0.24486542,  0.2295512 ,  0.27432674],\n       [-0.3627016 ,  0.30270058,  0.38455534,  0.2040748 ],\n       [ 0.29192817,  0.28738517, -0.35092342,  0.09037042],\n       [-0.08837089, -0.2422409 , -0.4109787 ,  0.3456725 ],\n       [ 0.14344472,  0.40351576,  0.3594097 ,  0.19018185],\n       [-0.36615175,  0.01803595, -0.23412026, -0.23549268],\n       [-0.00055292, -0.05350617,  0.28275055,  0.19153088],\n       [-0.24765284, -0.06314445, -0.32442057,  0.02489975],\n       [-0.3198099 ,  0.32908392,  0.45890588, -0.35120517],\n       [ 0.07073289, -0.03630379, -0.06536812,  0.40999502],\n       [-0.16390485,  0.45785517,  0.36029923, -0.1073271 ],\n       [-0.41507196,  0.15896136,  0.31574655, -0.23124069],\n       [-0.02672201, -0.20862618, -0.29498863, -0.17899635],\n       [ 0.33703887,  0.02991822,  0.33909833,  0.15734029],\n       [-0.36428964, -0.19811466, -0.34644276,  0.1137026 ],\n       [ 0.06362796,  0.2762909 , -0.15502632, -0.2779759 ],\n       [ 0.25143522, -0.45224446, -0.35116148,  0.12841898],\n       [-0.14044428, -0.21667576, -0.34718564, -0.30057693],\n       [ 0.13534415,  0.3306297 , -0.01858029,  0.34699404],\n       [-0.12647885,  0.22316748,  0.18153566,  0.27119708]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_62/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8bacdf08afde>\u001b[0m in \u001b[0;36m<cell line: 601>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;31m# Initialize the data generator with the MDP and policy network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0mising_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsing_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mising_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x data check:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-8bacdf08afde>\u001b[0m in \u001b[0;36mgen_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-8bacdf08afde>\u001b[0m in \u001b[0;36mupdate_policy\u001b[0;34m(self, states, actions, rewards)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m           \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         )\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36maggregate_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def apply_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/utils.py\u001b[0m in \u001b[0;36mall_reduce_sum_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mfiltered_grads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;34mf\"No gradients provided for any variable: {variable}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;34mf\"Provided `grads_and_vars` is {grads_and_vars}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['policy_network_18/dense_60/kernel:0', 'policy_network_18/dense_60/bias:0', 'policy_network_18/dense_61/kernel:0', 'policy_network_18/dense_61/bias:0', 'policy_network_18/dense_62/kernel:0', 'policy_network_18/dense_62/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'policy_network_18/dense_60/kernel:0' shape=(2, 24) dtype=float32, numpy=\narray([[ 0.19772297,  0.16391057, -0.4354878 , -0.26920357, -0.08627912,\n        -0.2127468 , -0.36556247, -0.25025576,  0.0199492 , -0.36509082,\n        -0.41536754, -0.09583846, -0.20232937, -0.46553233,  0.33525163,\n         0.22814226,  0.27558017, -0.4760502 , -0.05653453, -0.21421865,\n        -0.04016429,  0.13629788,  0.30385554,  0.08088315],\n       [ 0.44552648,  0.2851953 , -0.35981488, -0.3823621 ,  0.15523553,\n         0.37473184, -0.3963881 , -0.00318608,  0.01908273, -0.0777187 ,\n         0.11437511,  0.17452383, -0.23193318,  0.06176972,  0.16178608,\n         0.33903718, -0.0317916 , -0.2086102 , -0.12215507, -0.04659301,\n        -0.2603786 , -0.29596674, -0.19402987, -0.16435322]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_60/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_61/kernel:0' shape=(24, 24) dtype=float32, numpy=\narray([[ 0.18646863, -0.23797442,  0.2387962 , -0.3279072 , -0.20933665,\n         0.15025231,  0.30740854,  0.21738872, -0.07141876,  0.1913484 ,\n        -0.26960227,  0.08953795,  0.03639373, -0.08234972,  0.17490056,\n         0.33271185, -0.23513372,  0.0153062 , -0.000893  , -0.27217346,\n         0.02968529,  0.21039537,  0.2131925 , -0.12304848],\n       [-0.09896857, -0.3222649 ,  0.31906292,  0.107557  ,  0.2826908 ,\n         0.10983166,  0.09859717, -0.02100161, -0.3073945 ,  0.34991613,\n         0.08243233,  0.02511218,  0.20785007, -0.10177234,  0.25024614,\n        -0.15612027,  0.02372918,  0.08226448,  0.11318427, -0.22821894,\n        -0.12424655,  0.1345737 ,  0.11159566, -0.27160752],\n       [ 0.21405879,  0.06017828, -0.15200108,  0.18950209, -0.0740892 ,\n        -0.19009729,  0.23969004,  0.05128303,  0.11111149, -0.23026323,\n         0.2313343 , -0.10830526, -0.0143826 ,  0.2999234 ,  0.08144212,\n         0.1375764 ,  0.21113005, -0.2528075 , -0.24162096,  0.0814411 ,\n        -0.09783211,  0.25251207, -0.20317343,  0.13841093],\n       [ 0.11331457, -0.18177716,  0.226634  ,  0.23625055,  0.33247277,\n        -0.28853437, -0.05459392,  0.29430172, -0.18630475, -0.24049127,\n        -0.06550312,  0.32625607,  0.27666798,  0.03794134, -0.20064715,\n        -0.20846194, -0.03999105, -0.15565783, -0.31159568,  0.31517962,\n         0.21718934,  0.02713826, -0.3412615 ,  0.27988544],\n       [ 0.12247393, -0.19691066, -0.03605175,  0.25203303, -0.32917035,\n        -0.22816205,  0.15962169,  0.11822984,  0.3293316 , -0.1345174 ,\n        -0.04139555,  0.04732156, -0.12490766,  0.08094698,  0.11230281,\n         0.27682093, -0.27932817, -0.30049026, -0.03065374, -0.31669107,\n         0.19866213,  0.01129544, -0.04518986,  0.14290345],\n       [-0.08522001,  0.08308703,  0.35056683,  0.29698458, -0.0845733 ,\n        -0.01160556, -0.02110797,  0.16248122, -0.29288435, -0.03114542,\n        -0.21836197,  0.27457592, -0.11307156,  0.21166071,  0.33149996,\n        -0.12851551, -0.16334103, -0.23985341, -0.06829011, -0.07881588,\n        -0.3309604 ,  0.07298908,  0.16959098,  0.14352426],\n       [-0.18496616, -0.03449264,  0.3112764 , -0.17096068, -0.00459197,\n        -0.13524106,  0.19768164,  0.21879068, -0.2657577 , -0.1884683 ,\n        -0.02367422,  0.04107091, -0.12034568,  0.26111218,  0.21402505,\n         0.20999762,  0.3361645 ,  0.04592311, -0.20833322, -0.2388488 ,\n        -0.07854941,  0.09521511,  0.31349894,  0.22327486],\n       [-0.09230953, -0.07594618, -0.23215225,  0.0922704 ,  0.16785899,\n        -0.15346915, -0.01791164,  0.15163216, -0.3457112 , -0.0354594 ,\n         0.06894946,  0.34284928, -0.27600715,  0.11770543, -0.09918493,\n        -0.31942168, -0.14921114,  0.29858866,  0.29220417, -0.1797536 ,\n         0.19522312, -0.27679572, -0.0233244 , -0.1666381 ],\n       [-0.21938244, -0.26812282,  0.29120603, -0.13302532,  0.09983671,\n        -0.07164231,  0.16623971,  0.28091028, -0.20936835, -0.25674048,\n        -0.0362381 ,  0.15459666, -0.03687453, -0.16790275,  0.10826918,\n         0.1938385 , -0.19747889, -0.07239076, -0.22208767,  0.23777238,\n        -0.29254448, -0.1487755 ,  0.06041238,  0.1028828 ],\n       [-0.14266674, -0.04467979,  0.06919721, -0.01895496, -0.04450235,\n        -0.20351928, -0.26340348,  0.19835666, -0.30360827,  0.11936492,\n         0.22164735,  0.17820647,  0.02866128,  0.01480097, -0.00687501,\n        -0.12028348,  0.13905045, -0.01278651, -0.09972847,  0.20128068,\n         0.02679807,  0.02260715, -0.32713187, -0.1885553 ],\n       [-0.34510875, -0.13358848,  0.2367867 ,  0.211732  ,  0.24803081,\n        -0.09513217,  0.1279585 ,  0.05940127,  0.07194003, -0.29756197,\n         0.32209036,  0.23121211,  0.24562481,  0.27676418,  0.05046201,\n         0.3178744 ,  0.02746162,  0.03293902,  0.17159417, -0.31026065,\n         0.25135496,  0.24852899, -0.22143549, -0.14767076],\n       [-0.06905213,  0.00392017,  0.13229492, -0.10830374,  0.31786916,\n        -0.25472763,  0.2328277 ,  0.18121347, -0.30121696, -0.29393566,\n         0.09653735, -0.02665105, -0.28053457,  0.05603492,  0.0808309 ,\n        -0.02046433, -0.11509317,  0.23188052,  0.2629359 ,  0.05137053,\n         0.08622992,  0.03491327, -0.09308502, -0.0877907 ],\n       [-0.2843357 ,  0.23045668,  0.02149937, -0.15048465,  0.1882483 ,\n        -0.07747331, -0.13365625, -0.3454804 , -0.12779118, -0.2314237 ,\n        -0.1253347 ,  0.1410585 ,  0.3225697 ,  0.2895364 ,  0.26271662,\n         0.06072924, -0.21437505, -0.33449164,  0.10882661, -0.00695929,\n        -0.11498031, -0.03992924,  0.1282123 ,  0.09236413],\n       [ 0.0574035 ,  0.0464443 , -0.22757308, -0.21443717,  0.25955835,\n        -0.26863506,  0.2627807 ,  0.34047326,  0.07137239,  0.19317493,\n         0.24777219, -0.13518795, -0.34979725,  0.26800933,  0.35122922,\n         0.20053068,  0.08304217,  0.2999594 , -0.22044817,  0.0622896 ,\n        -0.2177038 , -0.02186301, -0.20992376,  0.00951457],\n       [-0.01220125,  0.3014336 ,  0.31622317, -0.24455792,  0.31382427,\n        -0.10827053,  0.28641203,  0.2100533 ,  0.06112304,  0.26042226,\n         0.28574768,  0.02124387,  0.16716132, -0.27170604, -0.2814058 ,\n        -0.05355877, -0.28775844, -0.01668459, -0.29938346, -0.04036093,\n         0.27390024, -0.2931379 , -0.16390091, -0.03324771],\n       [ 0.22075573, -0.31892148,  0.21477947,  0.12461844,  0.33316275,\n         0.27608934,  0.12112111,  0.03797489,  0.19855049, -0.17950991,\n        -0.00886795, -0.27076423, -0.08090138,  0.05134994, -0.27806103,\n        -0.00811604, -0.11230786, -0.271707  , -0.25723234,  0.09446678,\n        -0.20865555, -0.14452298,  0.11922896, -0.18775038],\n       [ 0.03985238, -0.04332012,  0.12369519,  0.25269744, -0.18133429,\n         0.15783235, -0.21996643,  0.104873  ,  0.04667526, -0.31472072,\n         0.08362162, -0.25499037,  0.21976843, -0.09340146, -0.25705785,\n        -0.02607557, -0.14309528,  0.02666259, -0.30909336, -0.11057605,\n         0.2397807 ,  0.17624125,  0.2792183 , -0.14233842],\n       [ 0.02503413,  0.19904843, -0.1717516 , -0.00558707, -0.31953   ,\n        -0.07258546,  0.28592566, -0.1536497 ,  0.25317243, -0.23349926,\n        -0.09572408, -0.27030265,  0.20357141, -0.14049357, -0.30573636,\n        -0.30866075,  0.12979838,  0.17591318,  0.00961295, -0.07751742,\n        -0.24733397,  0.30321   , -0.34409225,  0.2548848 ],\n       [-0.24113813, -0.11487646, -0.09808549,  0.20698765,  0.05000412,\n        -0.00434777,  0.06335109, -0.01965535, -0.01956406,  0.14439857,\n         0.29709223,  0.16887954, -0.19850129,  0.04871678, -0.08018902,\n        -0.13608113,  0.23657474,  0.10780573,  0.18933621, -0.33052436,\n        -0.20302095,  0.21480158,  0.28553352, -0.32309705],\n       [-0.1989338 ,  0.04422149,  0.27267972, -0.10930869,  0.18014356,\n        -0.08557892,  0.03317648, -0.18327093, -0.2527265 ,  0.0463022 ,\n        -0.12949619, -0.30432746, -0.15480386,  0.2732542 , -0.06227112,\n         0.16644362,  0.2798011 ,  0.0732621 ,  0.34460196,  0.293986  ,\n         0.23586562,  0.07284123,  0.18864211, -0.2226344 ],\n       [ 0.30948433, -0.11560434, -0.27955523, -0.01668644,  0.32861587,\n        -0.15525112,  0.16649553,  0.17273018, -0.34646708,  0.27665594,\n         0.1670408 , -0.14017949, -0.13053714,  0.14518821,  0.1945925 ,\n        -0.28801706,  0.03096774, -0.27979404, -0.21980247, -0.18703136,\n        -0.2560218 ,  0.01107493, -0.10115749,  0.32770357],\n       [-0.05131209,  0.08067656, -0.10280839, -0.11370806,  0.13609067,\n         0.01463592,  0.055318  ,  0.0330883 ,  0.00542125,  0.07465294,\n        -0.13333973, -0.1330882 , -0.11590013, -0.34664804, -0.05291697,\n        -0.28102735, -0.16253552, -0.12015502,  0.23048863,  0.24682191,\n        -0.02985209, -0.09166089, -0.18509573,  0.22615579],\n       [ 0.17306307,  0.06749749,  0.27066275, -0.1693242 ,  0.14010319,\n         0.0053378 , -0.32535502,  0.08616349,  0.3282092 , -0.17629841,\n        -0.01645091, -0.10461067, -0.05019158,  0.12688637, -0.04635412,\n         0.04581514, -0.14814566,  0.34153178,  0.09350345, -0.20381355,\n         0.22632012, -0.21770474, -0.29780617, -0.24019969],\n       [ 0.25134233, -0.2287119 , -0.14694549, -0.28296643,  0.32408836,\n        -0.08084044, -0.20932552, -0.31434298,  0.12886524, -0.13325013,\n        -0.33129242, -0.10539384, -0.25932232,  0.16061625, -0.20785207,\n        -0.28641826,  0.13477904, -0.15905984, -0.3140634 ,  0.01030153,\n         0.34889933,  0.19750592, -0.13467772, -0.12345216]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_61/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_62/kernel:0' shape=(24, 4) dtype=float32, numpy=\narray([[ 0.40529817,  0.41296077,  0.07118267, -0.44995436],\n       [-0.24593234,  0.34680176,  0.16797209,  0.3995493 ],\n       [ 0.10814989,  0.32899463, -0.45870465,  0.10060829],\n       [-0.3592777 ,  0.25602126,  0.270997  ,  0.06891042],\n       [ 0.34091747, -0.24486542,  0.2295512 ,  0.27432674],\n       [-0.3627016 ,  0.30270058,  0.38455534,  0.2040748 ],\n       [ 0.29192817,  0.28738517, -0.35092342,  0.09037042],\n       [-0.08837089, -0.2422409 , -0.4109787 ,  0.3456725 ],\n       [ 0.14344472,  0.40351576,  0.3594097 ,  0.19018185],\n       [-0.36615175,  0.01803595, -0.23412026, -0.23549268],\n       [-0.00055292, -0.05350617,  0.28275055,  0.19153088],\n       [-0.24765284, -0.06314445, -0.32442057,  0.02489975],\n       [-0.3198099 ,  0.32908392,  0.45890588, -0.35120517],\n       [ 0.07073289, -0.03630379, -0.06536812,  0.40999502],\n       [-0.16390485,  0.45785517,  0.36029923, -0.1073271 ],\n       [-0.41507196,  0.15896136,  0.31574655, -0.23124069],\n       [-0.02672201, -0.20862618, -0.29498863, -0.17899635],\n       [ 0.33703887,  0.02991822,  0.33909833,  0.15734029],\n       [-0.36428964, -0.19811466, -0.34644276,  0.1137026 ],\n       [ 0.06362796,  0.2762909 , -0.15502632, -0.2779759 ],\n       [ 0.25143522, -0.45224446, -0.35116148,  0.12841898],\n       [-0.14044428, -0.21667576, -0.34718564, -0.30057693],\n       [ 0.13534415,  0.3306297 , -0.01858029,  0.34699404],\n       [-0.12647885,  0.22316748,  0.18153566,  0.27119708]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_18/dense_62/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class GridWorldMDP:\n",
        "    def __init__(self, grid_size, start_state, goal_state):\n",
        "        self.grid_size = grid_size\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "        self.state = start_state\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start_state\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0 and self.state[0] > 0:\n",
        "            self.state = (self.state[0] - 1, self.state[1])\n",
        "        elif action == 1 and self.state[1] < self.grid_size[1] - 1:\n",
        "            self.state = (self.state[0], self.state[1] + 1)\n",
        "        elif action == 2 and self.state[0] < self.grid_size[0] - 1:\n",
        "            self.state = (self.state[0] + 1, self.state[1])\n",
        "        elif action == 3 and self.state[1] > 0:\n",
        "            self.state = (self.state[0], self.state[1] - 1)\n",
        "\n",
        "        reward = -1\n",
        "        done = False\n",
        "        if self.state == self.goal_state:\n",
        "            reward = 0\n",
        "            done = True\n",
        "\n",
        "        return self.state, reward, done\n",
        "\n",
        "class PolicyNetwork(tf.keras.Model):\n",
        "    def __init__(self, action_size):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(24, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
        "        self.logits = tf.keras.layers.Dense(action_size)  # Ensure action_size = 4\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        x = self.dense2(x)\n",
        "        return self.logits(x)  # Output shape [batch_size, action_size]\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        T_value = self.T / self.global_counter\n",
        "        exp_T_bar_value = self.exp_T_bar / self.global_counter_ref\n",
        "\n",
        "        exp_T_bar_value = tf.maximum(exp_T_bar_value, 1e-10)\n",
        "\n",
        "        loss = T_value - K.log(exp_T_bar_value)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(tf.maximum(self.c_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(tf.maximum(self.xc_exp_T_bar / self.global_counter_ref, 1e-10))\n",
        "\n",
        "        if tf.math.is_nan(loss_y) or tf.math.is_nan(loss_xy):\n",
        "            tf.print(\"NaN detected in DI_bits result calculation\")\n",
        "            tf.print(\"loss_y:\", loss_y)\n",
        "            tf.print(\"loss_xy:\", loss_xy)\n",
        "\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "\n",
        "        if tf.math.is_nan(result):\n",
        "            tf.print(\"NaN detected in PMF result calculation\")\n",
        "            tf.print(\"result:\", result)\n",
        "\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = negative_log_likelihood\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.zeros_like(loss)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config, mdp, policy_network):\n",
        "        self.config = config\n",
        "        self.mdp = mdp\n",
        "        self.policy_network = policy_network\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
        "        self.gamma = 0.99\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.initialize_channel()\n",
        "        self.y = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        self.state = self.mdp.reset()\n",
        "        self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "        self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        self.s = self.s_past\n",
        "\n",
        "    def gen_data(self):\n",
        "        x_l, y_l = [], []\n",
        "        states, actions, rewards = [], [], []\n",
        "        done = False\n",
        "        self.state = self.mdp.reset()\n",
        "\n",
        "        for _ in range(self.config['bptt']):\n",
        "            state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "            state_tensor = tf.expand_dims(state_tensor, axis=0)\n",
        "\n",
        "            logits = self.policy_network(state_tensor)\n",
        "            action_probs = tf.nn.softmax(logits)\n",
        "\n",
        "            action = tf.random.categorical(logits, 1)[0, 0]\n",
        "            action_int = int(action.numpy())\n",
        "\n",
        "            new_state, reward, done = self.mdp.step(action_int)\n",
        "\n",
        "            states.append(logits)\n",
        "            actions.append(action_int)\n",
        "            rewards.append(reward)\n",
        "            x_l.append(state_tensor)\n",
        "            y_l.append(tf.convert_to_tensor(reward, dtype=tf.float32))\n",
        "\n",
        "            if done:\n",
        "                self.state = self.mdp.reset()\n",
        "            else:\n",
        "                self.state = new_state\n",
        "\n",
        "        x = tf.concat(x_l, axis=0)\n",
        "        y = tf.stack(y_l, axis=0)\n",
        "\n",
        "        self.update_policy(states, actions, rewards)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def update_policy(self, states, actions, rewards):\n",
        "        G = 0\n",
        "        returns = []\n",
        "        for r in rewards[::-1]:\n",
        "            G = r + self.gamma * G\n",
        "            returns.insert(0, G)\n",
        "        returns = tf.convert_to_tensor(returns, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = 0\n",
        "            for logit, action, G in zip(states, actions, returns):\n",
        "                logit = tf.expand_dims(logit, axis=0)\n",
        "\n",
        "                action_prob = tf.nn.softmax(logit)\n",
        "\n",
        "                one_hot_action = tf.one_hot(action, depth=4)\n",
        "                one_hot_action = tf.expand_dims(one_hot_action, axis=0)\n",
        "\n",
        "                print(\"action_prob shape:\", action_prob.shape)\n",
        "                print(\"one_hot_action shape:\", one_hot_action.shape)\n",
        "\n",
        "                selected_action_prob = tf.reduce_sum(action_prob * one_hot_action, axis=-1)\n",
        "\n",
        "                loss -= tf.reduce_sum(tf.math.log(selected_action_prob + 1e-10) * G)\n",
        "\n",
        "            gradients = tape.gradient(loss, self.policy_network.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.policy_network.trainable_variables))\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.state = self.mdp.reset()\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "            self.s = self.s_past\n",
        "        else:\n",
        "            state_tensor = tf.convert_to_tensor(self.state, dtype=tf.float32)\n",
        "            state_tensor = tf.expand_dims(state_tensor, axis=0)\n",
        "            logits = self.policy_network(state_tensor)\n",
        "            action_probs = tf.nn.softmax(logits)\n",
        "            action = np.random.choice(4, p=action_probs.numpy().flatten())\n",
        "            new_state, reward, done = self.mdp.step(action)\n",
        "\n",
        "            z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.gen_logits(0.5), num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'ising',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "mdp = GridWorldMDP(grid_size=(5, 5), start_state=(0, 0), goal_state=(4, 4))\n",
        "policy_network = PolicyNetwork(action_size=4)\n",
        "ising_data = Ising_Data(config, mdp, policy_network)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data shape:\", x.shape)\n",
        "print(\"y data shape:\", y.shape)\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "print(\"x_y_combined shape:\", x_y_combined.shape)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "if x_y_combined.shape[0] == y.shape[0]:\n",
        "    print(\"Shapes are compatible for model training.\")\n",
        "else:\n",
        "    print(\"Shapes are not compatible for model training.\")\n",
        "    raise ValueError(\"Incompatible shapes: x_y_combined shape {}, y shape {}\".format(x_y_combined.shape, y.shape))\n",
        "\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "cap_est = CapEstDI(complex_model_v3, ising_data, config)\n",
        "cap_est.train()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(loss_history.losses, label='Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(loss_history.lr, label='Learning Rate')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(cap_est.capacity_estimates, label='Capacity Estimate')\n",
        "plt.plot(cap_est.dine_estimates, label='DINE Estimate')\n",
        "plt.plot(cap_est.info_rates, label='Information Rate')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Estimate Value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JhFXh8YNwyDN",
        "outputId": "11e89b51-67dc-4f11-d8d3-8ec65c2c55ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n",
            "action_prob shape: (1, 1, 4)\n",
            "one_hot_action shape: (1, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No gradients provided for any variable: (['policy_network_19/dense_63/kernel:0', 'policy_network_19/dense_63/bias:0', 'policy_network_19/dense_64/kernel:0', 'policy_network_19/dense_64/bias:0', 'policy_network_19/dense_65/kernel:0', 'policy_network_19/dense_65/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'policy_network_19/dense_63/kernel:0' shape=(2, 24) dtype=float32, numpy=\narray([[ 0.36757272, -0.04873282, -0.11618173, -0.3911929 ,  0.2914396 ,\n        -0.15846625,  0.11488628,  0.12776029, -0.2980753 ,  0.34182364,\n        -0.4560542 ,  0.24873257,  0.3024984 , -0.39475247, -0.15156144,\n        -0.1233106 ,  0.43871295,  0.10416764, -0.05787814,  0.469657  ,\n        -0.39736953,  0.2700882 , -0.3087269 , -0.11737493],\n       [ 0.42029917, -0.32160497, -0.05316591,  0.16306347, -0.2981922 ,\n        -0.32110858, -0.31503022, -0.24122933,  0.17498034, -0.15059441,\n         0.16683447, -0.23797546,  0.2636389 ,  0.42623097, -0.2704151 ,\n        -0.01578465, -0.3592548 ,  0.10931104,  0.14881253, -0.14213023,\n        -0.40472686, -0.15509841,  0.35274285,  0.25219053]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_63/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_64/kernel:0' shape=(24, 24) dtype=float32, numpy=\narray([[-2.37000242e-01,  2.28497475e-01, -6.60421848e-02,\n        -2.15190947e-02,  8.93682539e-02,  2.34275252e-01,\n         6.85871542e-02, -2.68849105e-01,  2.38285571e-01,\n        -1.06273279e-01, -1.96002990e-01,  2.65209824e-01,\n         3.18863899e-01, -2.96395928e-01, -5.24674356e-02,\n        -1.70949221e-01,  2.09065974e-02,  1.47083402e-03,\n        -3.25661600e-01, -2.78547257e-01, -3.18463266e-01,\n         4.14242744e-02, -2.07378164e-01,  1.32573068e-01],\n       [-3.00063640e-01, -1.83514535e-01,  2.26181149e-02,\n         2.07070142e-01,  6.93060160e-02,  8.28672647e-02,\n         5.15452623e-02, -9.84434187e-02,  1.39278740e-01,\n         1.83747262e-01, -4.63236868e-02, -3.36278826e-01,\n        -1.10670030e-01, -9.46983099e-02, -1.40741810e-01,\n        -2.34178901e-02, -8.81400108e-02, -2.28346646e-01,\n         1.00422621e-01,  2.91403025e-01, -1.76114738e-02,\n        -2.80865163e-01,  5.25185168e-02,  3.06853145e-01],\n       [ 2.13591129e-01,  2.23445565e-01,  1.96723431e-01,\n         1.78761780e-02, -1.17188469e-01,  2.72291750e-01,\n         3.39937538e-01, -2.25942761e-01,  1.63626224e-01,\n        -2.13839203e-01, -2.27267519e-01,  7.49243796e-02,\n         5.52262664e-02, -1.99758947e-01, -1.74145967e-01,\n        -3.13937187e-01,  1.18650198e-02,  1.14325881e-02,\n         3.51950258e-01,  1.46543473e-01,  1.42120689e-01,\n         2.50606090e-01, -1.10771522e-01, -1.09236121e-01],\n       [ 3.26163471e-02,  4.44225371e-02,  5.85406125e-02,\n         1.38895601e-01, -6.35385513e-02,  3.50767165e-01,\n        -1.76699758e-02, -1.21584639e-01,  2.10658520e-01,\n         3.42385143e-01, -8.18173885e-02, -2.01223046e-01,\n         1.24896288e-01,  5.85387647e-02, -1.83537886e-01,\n         4.45800722e-02, -1.15559995e-01,  8.49978030e-02,\n        -1.09500378e-01,  2.04720050e-01,  3.17259282e-01,\n        -3.09947759e-01, -2.54750252e-04,  2.75622278e-01],\n       [-3.43260527e-01,  2.02407688e-01, -2.50404358e-01,\n         3.24542552e-01,  2.53724962e-01,  3.03428769e-02,\n        -2.13550746e-01, -1.11950964e-01,  1.30792290e-01,\n         1.78000540e-01, -2.41658986e-01,  8.73621404e-02,\n        -4.01310623e-02,  2.10946798e-02,  2.45392174e-01,\n         7.45451450e-03, -2.16123641e-01,  1.61099404e-01,\n         2.59996206e-01, -8.63854289e-02,  2.98082501e-01,\n        -2.29638457e-01, -5.39620519e-02,  1.53432757e-01],\n       [-4.14815247e-02,  3.42273206e-01, -6.78751469e-02,\n         2.50010043e-01, -3.75261903e-02,  1.08157247e-01,\n        -3.98077965e-02,  2.04221100e-01, -3.00073087e-01,\n        -4.75150943e-02, -3.24953794e-02, -2.72650301e-01,\n        -3.06246996e-01, -2.40040213e-01,  2.10797876e-01,\n         5.71517944e-02,  6.80386722e-02,  1.92205459e-01,\n        -2.15478703e-01, -5.57314456e-02,  3.11073214e-01,\n        -2.76342809e-01,  2.14186996e-01,  3.22777063e-01],\n       [-3.35969120e-01,  2.72213012e-01, -8.55665207e-02,\n         2.36249357e-01, -1.12519562e-02, -6.81265891e-02,\n         2.76375264e-01,  1.69396549e-01,  3.47157449e-01,\n         6.95718825e-02,  3.02747697e-01, -5.75365126e-02,\n         2.55080372e-01, -2.38760203e-01, -3.14574391e-01,\n         1.39180094e-01, -9.12755728e-02, -1.25404820e-01,\n        -2.11261153e-01,  2.81398207e-01,  5.25147319e-02,\n        -1.50341004e-01,  3.05129498e-01, -2.56480694e-01],\n       [ 1.74578339e-01, -1.44612998e-01, -1.56785011e-01,\n         3.14969420e-02,  5.71815670e-02, -1.04570121e-01,\n        -2.95194328e-01, -4.80110645e-02,  2.53077239e-01,\n        -2.78191358e-01,  3.32802206e-01, -2.59734750e-01,\n         1.35148585e-01, -2.54090965e-01,  2.30719239e-01,\n         2.03275830e-01, -1.31253794e-01,  9.23401117e-02,\n        -2.61039376e-01, -2.98151851e-01, -3.18703771e-01,\n        -3.40460479e-01, -3.27955425e-01,  8.22440088e-02],\n       [-1.17491752e-01,  3.48533362e-01,  8.63094926e-02,\n        -3.51705581e-01,  4.95782495e-03,  5.03870547e-02,\n        -1.44381702e-01, -1.19952291e-01, -4.63326275e-02,\n        -1.65994689e-01,  3.02940339e-01,  1.07110828e-01,\n        -2.93217808e-01, -5.00211418e-02,  5.15336394e-02,\n        -3.21357667e-01,  2.25995213e-01, -2.93521285e-01,\n        -2.57753670e-01,  3.47422689e-01, -9.55821276e-02,\n         1.12767607e-01,  2.81868190e-01, -8.58017802e-03],\n       [ 2.61622697e-01, -1.84976026e-01,  4.59736884e-02,\n        -9.63616967e-02, -2.89831221e-01, -3.03084135e-01,\n        -2.32952803e-01,  2.36382693e-01,  1.26905680e-01,\n        -8.58344138e-02,  3.26334387e-01, -2.08826840e-01,\n        -1.56316414e-01, -1.85638830e-01, -2.63619244e-01,\n        -4.40931320e-03, -5.70854545e-02, -2.41204470e-01,\n         2.34948009e-01,  1.96883112e-01,  2.12658972e-01,\n        -3.13351035e-01,  2.34661430e-01,  2.18337685e-01],\n       [-3.34171832e-01,  2.37239867e-01,  3.12883943e-01,\n         3.03611070e-01,  3.31813127e-01,  3.18515271e-01,\n        -1.38060600e-01,  1.86555117e-01,  1.49922758e-01,\n        -8.80834460e-02,  2.80310243e-01,  1.56420022e-01,\n         8.99375081e-02,  1.42372817e-01,  3.16294402e-01,\n         2.17530996e-01,  1.33062571e-01, -1.86612010e-02,\n        -1.26456901e-01,  3.39040548e-01,  1.78367764e-01,\n         5.29951155e-02, -1.48770958e-01,  2.28095382e-01],\n       [ 2.31813580e-01,  5.36391139e-02, -3.36934030e-01,\n         1.30463451e-01, -1.08510554e-02, -1.52397528e-01,\n        -9.53957736e-02,  2.18039364e-01,  2.52915114e-01,\n         1.15840793e-01, -8.78053010e-02, -1.51782691e-01,\n        -2.94506997e-01,  3.42001528e-01, -1.70590296e-01,\n        -2.81523168e-01, -2.79484868e-01, -1.24582127e-01,\n         1.68911606e-01, -3.15503478e-01, -2.32293278e-01,\n         1.73179120e-01, -2.43788064e-01, -3.19569618e-01],\n       [-1.26172066e-01, -1.75687283e-01, -6.73918724e-02,\n        -6.13789558e-02,  3.02419990e-01,  3.77070010e-02,\n         1.78533524e-01, -2.88127065e-01, -2.82049745e-01,\n        -1.00557476e-01,  1.26769453e-01,  7.36209452e-02,\n         3.42923671e-01, -2.20874101e-01, -3.29478443e-01,\n         2.61381358e-01,  1.81275278e-01, -3.41936797e-01,\n         2.47613817e-01, -1.90893859e-01, -6.59191012e-02,\n        -1.78572237e-01,  3.04299921e-01,  4.33994532e-02],\n       [ 4.43808138e-02,  3.99500132e-03, -1.80347621e-01,\n         1.85773045e-01, -2.13627622e-01,  1.18882775e-01,\n         3.31914455e-01,  2.04884261e-01,  3.33813041e-01,\n         3.41421336e-01, -3.47029060e-01, -2.20463276e-02,\n         2.75879174e-01, -3.41501325e-01, -1.29386187e-01,\n        -8.64082873e-02, -2.74218351e-01, -1.62065163e-01,\n         5.13116717e-02,  3.38328689e-01, -7.20911622e-02,\n         3.70099843e-02, -1.77962109e-01, -2.49047831e-01],\n       [-6.48662746e-02,  3.20481151e-01, -1.36365876e-01,\n         2.93693036e-01,  1.07125908e-01, -1.08914703e-01,\n        -2.97641873e-01,  3.38963479e-01,  1.74271166e-02,\n         8.94053578e-02,  3.16336304e-01,  6.62846863e-02,\n        -7.24560022e-02, -9.71758068e-02,  2.80269355e-01,\n        -2.65209466e-01,  3.11863124e-02, -1.05550796e-01,\n         1.63530082e-01, -1.63235843e-01, -5.79845309e-02,\n         5.53600490e-02,  2.41564065e-01,  3.51293892e-01],\n       [-5.99926710e-02, -2.99474269e-01,  2.59357780e-01,\n         1.22749478e-01,  2.71549970e-01, -8.29260349e-02,\n         2.37493962e-01,  1.98788315e-01, -2.61851698e-01,\n         3.32593769e-01, -2.85216063e-01,  3.01644832e-01,\n        -7.08749890e-02,  3.24235171e-01,  3.06141406e-01,\n         3.02246422e-01, -3.19641113e-01,  2.90179938e-01,\n        -3.44806552e-01,  3.29677433e-01,  3.57868969e-02,\n        -2.96617806e-01,  2.32955426e-01,  1.39090002e-01],\n       [-7.62439966e-02,  3.09344620e-01,  2.31108636e-01,\n        -2.64932126e-01, -1.94627151e-01, -9.42838490e-02,\n         1.67420805e-02,  1.79550856e-01, -9.27484334e-02,\n         2.33082175e-02,  1.50486857e-01, -2.97598809e-01,\n         9.34302807e-04,  1.90984756e-01, -1.55371144e-01,\n         1.36079431e-01, -2.11238235e-01, -9.68559086e-02,\n         3.12958568e-01, -1.72788337e-01,  2.22465664e-01,\n        -2.85845309e-01, -2.55024076e-01,  2.96719462e-01],\n       [ 1.99767798e-01, -2.42863953e-01,  3.50551695e-01,\n        -7.31854737e-02, -3.93591821e-02, -2.27831781e-01,\n         1.44674689e-01,  2.64292032e-01,  1.24907583e-01,\n         8.12422633e-02,  3.28544885e-01,  1.99084491e-01,\n        -3.09346139e-01,  6.45959377e-02,  1.78401381e-01,\n         3.42782408e-01,  1.02955490e-01,  2.05068886e-02,\n         3.19102138e-01, -3.33489388e-01,  1.43406153e-01,\n         2.82489866e-01, -3.47688556e-01,  1.94488376e-01],\n       [-2.57780910e-01, -8.47013295e-02, -2.39464641e-01,\n        -1.65008456e-01, -3.14498425e-01,  2.49412626e-01,\n        -1.87281534e-01,  1.58576161e-01,  2.26825327e-01,\n         5.05886972e-02, -1.25491649e-01, -1.80718273e-01,\n         8.65601003e-02,  1.17273510e-01,  2.59034187e-01,\n         9.08396840e-02,  3.29933167e-02,  1.52660578e-01,\n        -1.42189816e-01,  3.89407277e-02,  3.25619370e-01,\n        -1.11255035e-01, -1.42130718e-01, -1.99040174e-01],\n       [ 2.39037126e-01,  1.09141022e-01,  7.21911490e-02,\n         2.01587766e-01, -2.72524208e-01, -1.92912444e-01,\n         4.20461893e-02,  1.01599604e-01, -3.20348233e-01,\n        -1.16330028e-01,  1.43635094e-01,  2.80508965e-01,\n         3.70856822e-02,  1.83600694e-01,  2.62638241e-01,\n         2.90303439e-01,  1.55043989e-01, -2.29949832e-01,\n         2.17387766e-01,  2.25584209e-02,  2.29687840e-01,\n        -1.17094561e-01,  1.28028721e-01,  1.01773351e-01],\n       [ 2.20347255e-01,  1.25896752e-01, -1.89725548e-01,\n        -3.00822705e-01,  4.20476198e-02, -2.13661790e-02,\n        -1.05814219e-01,  1.95859075e-02, -8.27440321e-02,\n         1.03424221e-01,  8.91851783e-02, -3.23803961e-01,\n         1.86009616e-01,  7.25042224e-02,  1.91919059e-01,\n        -3.99452448e-03, -1.81716129e-01, -2.94895470e-02,\n         1.73260957e-01,  2.96669006e-02, -1.61099434e-02,\n        -3.01803201e-01,  2.11545736e-01,  3.02223265e-02],\n       [-7.71180987e-02,  2.41716713e-01, -8.05872977e-02,\n         7.44897425e-02,  2.70001620e-01, -2.03752950e-01,\n         4.83959615e-02, -5.72658479e-02, -1.86348915e-01,\n        -1.77036405e-01,  1.11126661e-01, -5.11053205e-02,\n         1.50249690e-01,  1.80866420e-02,  1.23103201e-01,\n         2.27875501e-01,  8.65254700e-02,  1.44528210e-01,\n         1.15903914e-02,  1.97304577e-01, -3.42234761e-01,\n         1.40916049e-01, -3.48031819e-02,  3.32977802e-01],\n       [ 9.61515307e-02, -3.21163118e-01, -1.48233160e-01,\n        -2.31093764e-02,  9.74151194e-02, -1.80686235e-01,\n         2.24931091e-01,  2.03618437e-01,  9.31446254e-02,\n        -4.51138616e-03, -2.91858733e-01,  2.05938011e-01,\n        -1.46037981e-01,  2.16877311e-01,  9.15828943e-02,\n        -2.36156628e-01, -1.21395230e-01, -1.33773670e-01,\n        -2.10615382e-01, -1.76014170e-01, -7.20541775e-02,\n         2.26716131e-01, -3.14759403e-01, -2.11096793e-01],\n       [-1.10837534e-01, -1.87264264e-01, -1.04712069e-01,\n         3.29725057e-01, -3.33012521e-01, -1.10599905e-01,\n         1.96262807e-01,  1.78117484e-01, -2.30087996e-01,\n         3.11283976e-01, -1.33775443e-01,  7.84854293e-02,\n        -2.14216247e-01, -1.03812158e-01, -2.79525578e-01,\n         3.09877783e-01,  1.43689990e-01,  8.81973505e-02,\n         9.64766741e-03,  1.84037417e-01, -2.54454941e-01,\n        -2.77116358e-01, -3.08812559e-02, -2.87762761e-01]], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_64/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_65/kernel:0' shape=(24, 4) dtype=float32, numpy=\narray([[ 0.17717075,  0.19217223,  0.10382867, -0.30977255],\n       [ 0.05576956, -0.01819324,  0.2647009 , -0.37693003],\n       [ 0.15541756,  0.40690213, -0.12179613,  0.05719978],\n       [-0.4074706 , -0.4616447 ,  0.3620556 ,  0.08520925],\n       [-0.39488718,  0.02066445,  0.10020936,  0.01235971],\n       [-0.24468674, -0.05921364, -0.14317948,  0.0900104 ],\n       [-0.20092142, -0.14295512,  0.14316016, -0.1472219 ],\n       [ 0.35434276, -0.3533496 ,  0.18013722, -0.16426522],\n       [-0.09107146, -0.4597377 , -0.15649584,  0.188106  ],\n       [ 0.2818982 ,  0.00193793,  0.4061482 , -0.37473893],\n       [ 0.3366986 , -0.3294052 ,  0.3174044 , -0.00839832],\n       [ 0.14527291, -0.00091803, -0.01594937, -0.20620078],\n       [ 0.35587817,  0.1782974 , -0.32286972,  0.12324733],\n       [-0.38380706,  0.23575658, -0.00120211, -0.23461658],\n       [-0.4596442 , -0.13692856,  0.2936306 ,  0.2215085 ],\n       [ 0.3125615 ,  0.4136235 , -0.0320048 , -0.07149819],\n       [ 0.39992952,  0.06765592,  0.21445376, -0.2865541 ],\n       [ 0.09647453,  0.15749258, -0.27587485,  0.14043874],\n       [ 0.2409184 ,  0.26793796,  0.0563575 , -0.05462781],\n       [-0.10471705,  0.37063318, -0.29537326, -0.36840522],\n       [ 0.37996697,  0.20155913, -0.01237637,  0.34857208],\n       [ 0.30499983,  0.12110466,  0.29371113, -0.21986546],\n       [-0.41969633, -0.42436713, -0.2902856 ,  0.3767007 ],\n       [-0.22308551,  0.4605158 , -0.27953237,  0.36899227]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_65/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4d0ff3330d43>\u001b[0m in \u001b[0;36m<cell line: 521>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0mpolicy_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicyNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0mising_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsing_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mising_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x data shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4d0ff3330d43>\u001b[0m in \u001b[0;36mgen_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4d0ff3330d43>\u001b[0m in \u001b[0;36mupdate_policy\u001b[0;34m(self, states, actions, rewards)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgen_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         )\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36maggregate_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def apply_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/utils.py\u001b[0m in \u001b[0;36mall_reduce_sum_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mfiltered_grads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;34mf\"No gradients provided for any variable: {variable}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;34mf\"Provided `grads_and_vars` is {grads_and_vars}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['policy_network_19/dense_63/kernel:0', 'policy_network_19/dense_63/bias:0', 'policy_network_19/dense_64/kernel:0', 'policy_network_19/dense_64/bias:0', 'policy_network_19/dense_65/kernel:0', 'policy_network_19/dense_65/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'policy_network_19/dense_63/kernel:0' shape=(2, 24) dtype=float32, numpy=\narray([[ 0.36757272, -0.04873282, -0.11618173, -0.3911929 ,  0.2914396 ,\n        -0.15846625,  0.11488628,  0.12776029, -0.2980753 ,  0.34182364,\n        -0.4560542 ,  0.24873257,  0.3024984 , -0.39475247, -0.15156144,\n        -0.1233106 ,  0.43871295,  0.10416764, -0.05787814,  0.469657  ,\n        -0.39736953,  0.2700882 , -0.3087269 , -0.11737493],\n       [ 0.42029917, -0.32160497, -0.05316591,  0.16306347, -0.2981922 ,\n        -0.32110858, -0.31503022, -0.24122933,  0.17498034, -0.15059441,\n         0.16683447, -0.23797546,  0.2636389 ,  0.42623097, -0.2704151 ,\n        -0.01578465, -0.3592548 ,  0.10931104,  0.14881253, -0.14213023,\n        -0.40472686, -0.15509841,  0.35274285,  0.25219053]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_63/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_64/kernel:0' shape=(24, 24) dtype=float32, numpy=\narray([[-2.37000242e-01,  2.28497475e-01, -6.60421848e-02,\n        -2.15190947e-02,  8.93682539e-02,  2.34275252e-01,\n         6.85871542e-02, -2.68849105e-01,  2.38285571e-01,\n        -1.06273279e-01, -1.96002990e-01,  2.65209824e-01,\n         3.18863899e-01, -2.96395928e-01, -5.24674356e-02,\n        -1.70949221e-01,  2.09065974e-02,  1.47083402e-03,\n        -3.25661600e-01, -2.78547257e-01, -3.18463266e-01,\n         4.14242744e-02, -2.07378164e-01,  1.32573068e-01],\n       [-3.00063640e-01, -1.83514535e-01,  2.26181149e-02,\n         2.07070142e-01,  6.93060160e-02,  8.28672647e-02,\n         5.15452623e-02, -9.84434187e-02,  1.39278740e-01,\n         1.83747262e-01, -4.63236868e-02, -3.36278826e-01,\n        -1.10670030e-01, -9.46983099e-02, -1.40741810e-01,\n        -2.34178901e-02, -8.81400108e-02, -2.28346646e-01,\n         1.00422621e-01,  2.91403025e-01, -1.76114738e-02,\n        -2.80865163e-01,  5.25185168e-02,  3.06853145e-01],\n       [ 2.13591129e-01,  2.23445565e-01,  1.96723431e-01,\n         1.78761780e-02, -1.17188469e-01,  2.72291750e-01,\n         3.39937538e-01, -2.25942761e-01,  1.63626224e-01,\n        -2.13839203e-01, -2.27267519e-01,  7.49243796e-02,\n         5.52262664e-02, -1.99758947e-01, -1.74145967e-01,\n        -3.13937187e-01,  1.18650198e-02,  1.14325881e-02,\n         3.51950258e-01,  1.46543473e-01,  1.42120689e-01,\n         2.50606090e-01, -1.10771522e-01, -1.09236121e-01],\n       [ 3.26163471e-02,  4.44225371e-02,  5.85406125e-02,\n         1.38895601e-01, -6.35385513e-02,  3.50767165e-01,\n        -1.76699758e-02, -1.21584639e-01,  2.10658520e-01,\n         3.42385143e-01, -8.18173885e-02, -2.01223046e-01,\n         1.24896288e-01,  5.85387647e-02, -1.83537886e-01,\n         4.45800722e-02, -1.15559995e-01,  8.49978030e-02,\n        -1.09500378e-01,  2.04720050e-01,  3.17259282e-01,\n        -3.09947759e-01, -2.54750252e-04,  2.75622278e-01],\n       [-3.43260527e-01,  2.02407688e-01, -2.50404358e-01,\n         3.24542552e-01,  2.53724962e-01,  3.03428769e-02,\n        -2.13550746e-01, -1.11950964e-01,  1.30792290e-01,\n         1.78000540e-01, -2.41658986e-01,  8.73621404e-02,\n        -4.01310623e-02,  2.10946798e-02,  2.45392174e-01,\n         7.45451450e-03, -2.16123641e-01,  1.61099404e-01,\n         2.59996206e-01, -8.63854289e-02,  2.98082501e-01,\n        -2.29638457e-01, -5.39620519e-02,  1.53432757e-01],\n       [-4.14815247e-02,  3.42273206e-01, -6.78751469e-02,\n         2.50010043e-01, -3.75261903e-02,  1.08157247e-01,\n        -3.98077965e-02,  2.04221100e-01, -3.00073087e-01,\n        -4.75150943e-02, -3.24953794e-02, -2.72650301e-01,\n        -3.06246996e-01, -2.40040213e-01,  2.10797876e-01,\n         5.71517944e-02,  6.80386722e-02,  1.92205459e-01,\n        -2.15478703e-01, -5.57314456e-02,  3.11073214e-01,\n        -2.76342809e-01,  2.14186996e-01,  3.22777063e-01],\n       [-3.35969120e-01,  2.72213012e-01, -8.55665207e-02,\n         2.36249357e-01, -1.12519562e-02, -6.81265891e-02,\n         2.76375264e-01,  1.69396549e-01,  3.47157449e-01,\n         6.95718825e-02,  3.02747697e-01, -5.75365126e-02,\n         2.55080372e-01, -2.38760203e-01, -3.14574391e-01,\n         1.39180094e-01, -9.12755728e-02, -1.25404820e-01,\n        -2.11261153e-01,  2.81398207e-01,  5.25147319e-02,\n        -1.50341004e-01,  3.05129498e-01, -2.56480694e-01],\n       [ 1.74578339e-01, -1.44612998e-01, -1.56785011e-01,\n         3.14969420e-02,  5.71815670e-02, -1.04570121e-01,\n        -2.95194328e-01, -4.80110645e-02,  2.53077239e-01,\n        -2.78191358e-01,  3.32802206e-01, -2.59734750e-01,\n         1.35148585e-01, -2.54090965e-01,  2.30719239e-01,\n         2.03275830e-01, -1.31253794e-01,  9.23401117e-02,\n        -2.61039376e-01, -2.98151851e-01, -3.18703771e-01,\n        -3.40460479e-01, -3.27955425e-01,  8.22440088e-02],\n       [-1.17491752e-01,  3.48533362e-01,  8.63094926e-02,\n        -3.51705581e-01,  4.95782495e-03,  5.03870547e-02,\n        -1.44381702e-01, -1.19952291e-01, -4.63326275e-02,\n        -1.65994689e-01,  3.02940339e-01,  1.07110828e-01,\n        -2.93217808e-01, -5.00211418e-02,  5.15336394e-02,\n        -3.21357667e-01,  2.25995213e-01, -2.93521285e-01,\n        -2.57753670e-01,  3.47422689e-01, -9.55821276e-02,\n         1.12767607e-01,  2.81868190e-01, -8.58017802e-03],\n       [ 2.61622697e-01, -1.84976026e-01,  4.59736884e-02,\n        -9.63616967e-02, -2.89831221e-01, -3.03084135e-01,\n        -2.32952803e-01,  2.36382693e-01,  1.26905680e-01,\n        -8.58344138e-02,  3.26334387e-01, -2.08826840e-01,\n        -1.56316414e-01, -1.85638830e-01, -2.63619244e-01,\n        -4.40931320e-03, -5.70854545e-02, -2.41204470e-01,\n         2.34948009e-01,  1.96883112e-01,  2.12658972e-01,\n        -3.13351035e-01,  2.34661430e-01,  2.18337685e-01],\n       [-3.34171832e-01,  2.37239867e-01,  3.12883943e-01,\n         3.03611070e-01,  3.31813127e-01,  3.18515271e-01,\n        -1.38060600e-01,  1.86555117e-01,  1.49922758e-01,\n        -8.80834460e-02,  2.80310243e-01,  1.56420022e-01,\n         8.99375081e-02,  1.42372817e-01,  3.16294402e-01,\n         2.17530996e-01,  1.33062571e-01, -1.86612010e-02,\n        -1.26456901e-01,  3.39040548e-01,  1.78367764e-01,\n         5.29951155e-02, -1.48770958e-01,  2.28095382e-01],\n       [ 2.31813580e-01,  5.36391139e-02, -3.36934030e-01,\n         1.30463451e-01, -1.08510554e-02, -1.52397528e-01,\n        -9.53957736e-02,  2.18039364e-01,  2.52915114e-01,\n         1.15840793e-01, -8.78053010e-02, -1.51782691e-01,\n        -2.94506997e-01,  3.42001528e-01, -1.70590296e-01,\n        -2.81523168e-01, -2.79484868e-01, -1.24582127e-01,\n         1.68911606e-01, -3.15503478e-01, -2.32293278e-01,\n         1.73179120e-01, -2.43788064e-01, -3.19569618e-01],\n       [-1.26172066e-01, -1.75687283e-01, -6.73918724e-02,\n        -6.13789558e-02,  3.02419990e-01,  3.77070010e-02,\n         1.78533524e-01, -2.88127065e-01, -2.82049745e-01,\n        -1.00557476e-01,  1.26769453e-01,  7.36209452e-02,\n         3.42923671e-01, -2.20874101e-01, -3.29478443e-01,\n         2.61381358e-01,  1.81275278e-01, -3.41936797e-01,\n         2.47613817e-01, -1.90893859e-01, -6.59191012e-02,\n        -1.78572237e-01,  3.04299921e-01,  4.33994532e-02],\n       [ 4.43808138e-02,  3.99500132e-03, -1.80347621e-01,\n         1.85773045e-01, -2.13627622e-01,  1.18882775e-01,\n         3.31914455e-01,  2.04884261e-01,  3.33813041e-01,\n         3.41421336e-01, -3.47029060e-01, -2.20463276e-02,\n         2.75879174e-01, -3.41501325e-01, -1.29386187e-01,\n        -8.64082873e-02, -2.74218351e-01, -1.62065163e-01,\n         5.13116717e-02,  3.38328689e-01, -7.20911622e-02,\n         3.70099843e-02, -1.77962109e-01, -2.49047831e-01],\n       [-6.48662746e-02,  3.20481151e-01, -1.36365876e-01,\n         2.93693036e-01,  1.07125908e-01, -1.08914703e-01,\n        -2.97641873e-01,  3.38963479e-01,  1.74271166e-02,\n         8.94053578e-02,  3.16336304e-01,  6.62846863e-02,\n        -7.24560022e-02, -9.71758068e-02,  2.80269355e-01,\n        -2.65209466e-01,  3.11863124e-02, -1.05550796e-01,\n         1.63530082e-01, -1.63235843e-01, -5.79845309e-02,\n         5.53600490e-02,  2.41564065e-01,  3.51293892e-01],\n       [-5.99926710e-02, -2.99474269e-01,  2.59357780e-01,\n         1.22749478e-01,  2.71549970e-01, -8.29260349e-02,\n         2.37493962e-01,  1.98788315e-01, -2.61851698e-01,\n         3.32593769e-01, -2.85216063e-01,  3.01644832e-01,\n        -7.08749890e-02,  3.24235171e-01,  3.06141406e-01,\n         3.02246422e-01, -3.19641113e-01,  2.90179938e-01,\n        -3.44806552e-01,  3.29677433e-01,  3.57868969e-02,\n        -2.96617806e-01,  2.32955426e-01,  1.39090002e-01],\n       [-7.62439966e-02,  3.09344620e-01,  2.31108636e-01,\n        -2.64932126e-01, -1.94627151e-01, -9.42838490e-02,\n         1.67420805e-02,  1.79550856e-01, -9.27484334e-02,\n         2.33082175e-02,  1.50486857e-01, -2.97598809e-01,\n         9.34302807e-04,  1.90984756e-01, -1.55371144e-01,\n         1.36079431e-01, -2.11238235e-01, -9.68559086e-02,\n         3.12958568e-01, -1.72788337e-01,  2.22465664e-01,\n        -2.85845309e-01, -2.55024076e-01,  2.96719462e-01],\n       [ 1.99767798e-01, -2.42863953e-01,  3.50551695e-01,\n        -7.31854737e-02, -3.93591821e-02, -2.27831781e-01,\n         1.44674689e-01,  2.64292032e-01,  1.24907583e-01,\n         8.12422633e-02,  3.28544885e-01,  1.99084491e-01,\n        -3.09346139e-01,  6.45959377e-02,  1.78401381e-01,\n         3.42782408e-01,  1.02955490e-01,  2.05068886e-02,\n         3.19102138e-01, -3.33489388e-01,  1.43406153e-01,\n         2.82489866e-01, -3.47688556e-01,  1.94488376e-01],\n       [-2.57780910e-01, -8.47013295e-02, -2.39464641e-01,\n        -1.65008456e-01, -3.14498425e-01,  2.49412626e-01,\n        -1.87281534e-01,  1.58576161e-01,  2.26825327e-01,\n         5.05886972e-02, -1.25491649e-01, -1.80718273e-01,\n         8.65601003e-02,  1.17273510e-01,  2.59034187e-01,\n         9.08396840e-02,  3.29933167e-02,  1.52660578e-01,\n        -1.42189816e-01,  3.89407277e-02,  3.25619370e-01,\n        -1.11255035e-01, -1.42130718e-01, -1.99040174e-01],\n       [ 2.39037126e-01,  1.09141022e-01,  7.21911490e-02,\n         2.01587766e-01, -2.72524208e-01, -1.92912444e-01,\n         4.20461893e-02,  1.01599604e-01, -3.20348233e-01,\n        -1.16330028e-01,  1.43635094e-01,  2.80508965e-01,\n         3.70856822e-02,  1.83600694e-01,  2.62638241e-01,\n         2.90303439e-01,  1.55043989e-01, -2.29949832e-01,\n         2.17387766e-01,  2.25584209e-02,  2.29687840e-01,\n        -1.17094561e-01,  1.28028721e-01,  1.01773351e-01],\n       [ 2.20347255e-01,  1.25896752e-01, -1.89725548e-01,\n        -3.00822705e-01,  4.20476198e-02, -2.13661790e-02,\n        -1.05814219e-01,  1.95859075e-02, -8.27440321e-02,\n         1.03424221e-01,  8.91851783e-02, -3.23803961e-01,\n         1.86009616e-01,  7.25042224e-02,  1.91919059e-01,\n        -3.99452448e-03, -1.81716129e-01, -2.94895470e-02,\n         1.73260957e-01,  2.96669006e-02, -1.61099434e-02,\n        -3.01803201e-01,  2.11545736e-01,  3.02223265e-02],\n       [-7.71180987e-02,  2.41716713e-01, -8.05872977e-02,\n         7.44897425e-02,  2.70001620e-01, -2.03752950e-01,\n         4.83959615e-02, -5.72658479e-02, -1.86348915e-01,\n        -1.77036405e-01,  1.11126661e-01, -5.11053205e-02,\n         1.50249690e-01,  1.80866420e-02,  1.23103201e-01,\n         2.27875501e-01,  8.65254700e-02,  1.44528210e-01,\n         1.15903914e-02,  1.97304577e-01, -3.42234761e-01,\n         1.40916049e-01, -3.48031819e-02,  3.32977802e-01],\n       [ 9.61515307e-02, -3.21163118e-01, -1.48233160e-01,\n        -2.31093764e-02,  9.74151194e-02, -1.80686235e-01,\n         2.24931091e-01,  2.03618437e-01,  9.31446254e-02,\n        -4.51138616e-03, -2.91858733e-01,  2.05938011e-01,\n        -1.46037981e-01,  2.16877311e-01,  9.15828943e-02,\n        -2.36156628e-01, -1.21395230e-01, -1.33773670e-01,\n        -2.10615382e-01, -1.76014170e-01, -7.20541775e-02,\n         2.26716131e-01, -3.14759403e-01, -2.11096793e-01],\n       [-1.10837534e-01, -1.87264264e-01, -1.04712069e-01,\n         3.29725057e-01, -3.33012521e-01, -1.10599905e-01,\n         1.96262807e-01,  1.78117484e-01, -2.30087996e-01,\n         3.11283976e-01, -1.33775443e-01,  7.84854293e-02,\n        -2.14216247e-01, -1.03812158e-01, -2.79525578e-01,\n         3.09877783e-01,  1.43689990e-01,  8.81973505e-02,\n         9.64766741e-03,  1.84037417e-01, -2.54454941e-01,\n        -2.77116358e-01, -3.08812559e-02, -2.87762761e-01]], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_64/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_65/kernel:0' shape=(24, 4) dtype=float32, numpy=\narray([[ 0.17717075,  0.19217223,  0.10382867, -0.30977255],\n       [ 0.05576956, -0.01819324,  0.2647009 , -0.37693003],\n       [ 0.15541756,  0.40690213, -0.12179613,  0.05719978],\n       [-0.4074706 , -0.4616447 ,  0.3620556 ,  0.08520925],\n       [-0.39488718,  0.02066445,  0.10020936,  0.01235971],\n       [-0.24468674, -0.05921364, -0.14317948,  0.0900104 ],\n       [-0.20092142, -0.14295512,  0.14316016, -0.1472219 ],\n       [ 0.35434276, -0.3533496 ,  0.18013722, -0.16426522],\n       [-0.09107146, -0.4597377 , -0.15649584,  0.188106  ],\n       [ 0.2818982 ,  0.00193793,  0.4061482 , -0.37473893],\n       [ 0.3366986 , -0.3294052 ,  0.3174044 , -0.00839832],\n       [ 0.14527291, -0.00091803, -0.01594937, -0.20620078],\n       [ 0.35587817,  0.1782974 , -0.32286972,  0.12324733],\n       [-0.38380706,  0.23575658, -0.00120211, -0.23461658],\n       [-0.4596442 , -0.13692856,  0.2936306 ,  0.2215085 ],\n       [ 0.3125615 ,  0.4136235 , -0.0320048 , -0.07149819],\n       [ 0.39992952,  0.06765592,  0.21445376, -0.2865541 ],\n       [ 0.09647453,  0.15749258, -0.27587485,  0.14043874],\n       [ 0.2409184 ,  0.26793796,  0.0563575 , -0.05462781],\n       [-0.10471705,  0.37063318, -0.29537326, -0.36840522],\n       [ 0.37996697,  0.20155913, -0.01237637,  0.34857208],\n       [ 0.30499983,  0.12110466,  0.29371113, -0.21986546],\n       [-0.41969633, -0.42436713, -0.2902856 ,  0.3767007 ],\n       [-0.22308551,  0.4605158 , -0.27953237,  0.36899227]],\n      dtype=float32)>), (None, <tf.Variable 'policy_network_19/dense_65/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FAsB3D3bCiBS",
        "outputId": "238b1c1a-d2e8-4819-a512-c790937502cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 12s 12s/step - loss: 2.4619 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4468 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4317 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4171 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4026 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3886 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3744 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3617 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3480 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3353 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3225 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3113 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2996 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2887 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2767 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2660 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2543 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2421 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2310 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2199 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.2063 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1959 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1842 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1717 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1601 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1493 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1320 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1175 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1057 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0912 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0763 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0599 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0478 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0369 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0187 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.0097 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9891 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.9620 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9502 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9294 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.9020 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8859 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8662 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8299 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8065 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.7808 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7487 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7282 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.6831 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6573 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6073 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5767 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5450 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5044 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4583 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4291 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3945 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3536 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3231 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2888 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2587 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2332 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2087 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1853 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1624 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1414 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1205 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0985 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0800 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0612 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0419 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0250 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0091 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9940 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9781 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.9632 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9484 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.9338 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.9201 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.9058 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8920 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8798 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8678 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.8561 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.8445 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8331 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8217 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8103 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7994 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.7884 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7777 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7680 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7584 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7490 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7395 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7304 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7212 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7123 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7032 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6942 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6854 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6776 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6695 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6619 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6541 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6465 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6389 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6313 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6239 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6164 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6091 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6024 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5959 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5894 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5829 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5766 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5701 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5638 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5576 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5512 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5450 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5394 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5338 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5283 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5228 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5174 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5119 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5065 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5011 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4957 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4904 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4856 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4808 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4761 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4714 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4667 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4620 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4574 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4528 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4481 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4435 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4394 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4353 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4313 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4272 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4231 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4191 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4151 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4111 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4070 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4031 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3995 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3959 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3924 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3888 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3853 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3818 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3783 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3748 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3713 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3679 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3647 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3616 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3586 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3554 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3524 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3493 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3463 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3432 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3401 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3371 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3344 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3317 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3290 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3262 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3235 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3209 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3182 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3155 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3128 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.3078 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3054 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.3030 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3006 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2982 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2959 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2935 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2912 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2888 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2865 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2844 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2823 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2802 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2781 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2761 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2740 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2719 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2698 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2678 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2657 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2638 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2620 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2602 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2583 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2565 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2547 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2528 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2510 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2492 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2474 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2457 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2441 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2425 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2408 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2392 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2376 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2360 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2344 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2328 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2312 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2297 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2283 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2268 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2254 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2239 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2225 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2211 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2197 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2182 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2168 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2155 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2142 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2129 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2117 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2104 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2091 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2079 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2066 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2053 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2040 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2029 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2018 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2006 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1995 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1983 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1972 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1961 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1949 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1938 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1927 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1916 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1906 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1896 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1886 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1876 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1866 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1856 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1846 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1836 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1825 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1817 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1808 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1798 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1790 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1781 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1771 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1762 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1753 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1745 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1736 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1728 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1719 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1712 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1703 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1695 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1687 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1679 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1671 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1663 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1655 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1648 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1641 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1634 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1626 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1619 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1612 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1605 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1598 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1590 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1583 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1576 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1570 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1564 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1557 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1551 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1544 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1538 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1531 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1525 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1519 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1513 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1507 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1501 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1495 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1490 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1484 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1478 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1472 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1466 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1461 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1456 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1450 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1445 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1440 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1435 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1430 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1425 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1419 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1414 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1409 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1405 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1400 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1395 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1391 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1386 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1381 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1377 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1372 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1368 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1363 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1359 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1355 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1351 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1346 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1342 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1338 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1334 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1330 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1326 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1321 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1317 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1314 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1310 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1306 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1302 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1299 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1295 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1292 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1288 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1284 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1281 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1278 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1274 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1271 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1267 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1264 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1261 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1257 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1254 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1251 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1247 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1245 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1242 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1239 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1236 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1233 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1229 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1227 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1224 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1221 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1218 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1215 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1213 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1210 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1207 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1204 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1202 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1199 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1196 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1193 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1191 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1189 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1186 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1184 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1181 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1179 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1177 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1174 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1172 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1169 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1167 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1165 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1163 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1161 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1158 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1156 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1155 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1152 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1150 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1148 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1146 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1144 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1142 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1140 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1138 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1136 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1134 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1132 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1130 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1128 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1126 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1124 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1123 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1121 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1119 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1118 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1115 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1114 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1112 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1111 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1109 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1107 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1106 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1104 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1102 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1101 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1099 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1098 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1096 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1094 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1093 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1092 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1090 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1089 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1087 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1086 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1084 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1083 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1082 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1080 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1079 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1078 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1076 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1075 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1074 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1073 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1071 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1070 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1069 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1067 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1066 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1065 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1064 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1063 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1062 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1060 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1059 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1058 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1057 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1056 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1055 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1054 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1053 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1052 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1051 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1050 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1048 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1048 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1047 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1046 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1045 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1044 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1043 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1042 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1041 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1040 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1039 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1038 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1037 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1036 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1035 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1035 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1034 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1033 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1032 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1032 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1030 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1029 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1029 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1028 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1027 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1026 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1026 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1025 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1024 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1023 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1022 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1022 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1021 - lr: 1.0880e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.KLDivergence())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vya5B81tFgZl",
        "outputId": "74b87067-4bc6-4ad8-c863-e7e51edf443e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step - loss: 2.4372 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4206 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4045 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3892 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3738 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3595 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3451 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3310 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3177 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3054 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2935 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2825 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2718 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2614 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2495 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2397 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2270 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2161 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2064 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1948 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1819 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1714 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1614 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1483 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1380 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1229 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1081 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0990 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0880 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.0715 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0560 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0413 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0321 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0126 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9985 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9753 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.9632 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.9402 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9165 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9020 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8813 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8502 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8262 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.7978 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7749 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7453 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7100 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.6896 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.6502 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6049 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5883 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5490 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5165 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4862 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4560 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4271 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3995 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.3711 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3478 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3198 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2968 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2736 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2518 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2323 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2107 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1908 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1711 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1514 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1327 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1142 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0962 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.0795 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0637 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0483 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0332 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.0179 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0026 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9883 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.9744 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9601 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9456 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9335 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9211 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9091 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8974 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8855 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8738 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8624 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8513 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.8399 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8287 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8189 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.8091 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7994 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7898 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7802 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.7709 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.7615 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7523 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7431 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7340 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7258 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7177 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7097 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7018 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6938 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6860 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6783 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6706 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6630 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6554 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6485 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6418 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6350 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6284 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6218 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6151 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6086 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6021 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5955 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5892 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5834 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5777 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5719 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5663 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5607 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5551 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5495 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5439 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5384 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5329 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5279 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5231 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5181 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5133 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5085 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5036 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4989 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4941 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4893 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4846 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4804 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4761 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4719 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4678 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4636 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4594 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.4553 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4511 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4471 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4429 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4392 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4356 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4319 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4283 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4247 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4210 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4174 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4139 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4103 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4067 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4036 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4004 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3972 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3940 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3909 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3877 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3846 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3814 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3783 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3752 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3724 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3696 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3669 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3641 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3613 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3586 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3558 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3531 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3503 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3476 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3452 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.3428 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3403 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3379 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3355 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3331 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3306 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3283 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3259 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3235 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3213 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3192 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3171 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3149 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3128 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3107 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3085 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3064 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3043 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3022 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3003 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2985 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2966 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2947 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2928 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2909 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2890 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2872 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2853 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2835 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2818 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2802 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2785 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2768 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2752 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2735 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2719 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2702 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2686 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2669 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2655 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2640 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2625 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2610 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2595 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2581 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2566 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2552 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2537 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2522 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2509 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2496 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2483 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2470 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2457 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2444 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2431 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2418 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2405 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2392 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2381 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2369 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2357 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2346 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2334 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2323 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2311 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2299 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2288 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2276 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2266 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2255 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2245 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2235 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2224 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2214 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2204 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2194 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2183 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2173 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2164 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2155 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2145 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2136 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2127 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2118 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2109 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2099 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2090 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2081 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2073 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2065 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2056 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2048 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2040 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2032 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2023 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2015 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2007 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1999 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1992 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1984 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1977 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1969 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1962 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1955 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1947 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1940 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1933 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1925 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1919 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1912 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1906 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1899 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1892 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1886 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1879 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1873 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1866 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1860 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1854 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1848 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1842 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1836 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1830 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1824 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1819 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1813 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1807 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1801 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1795 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1790 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1785 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1780 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1774 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1769 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1764 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1759 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1754 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1748 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1743 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1739 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1734 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1729 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1725 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1720 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1715 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1710 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1705 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1701 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1696 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1692 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1688 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1684 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1679 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1675 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1671 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1667 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1663 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1658 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1655 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1651 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1647 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1643 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1639 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1635 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1632 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1628 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1624 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1620 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1617 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1614 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1610 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1607 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1603 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1600 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1597 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1593 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1590 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1586 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1583 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1580 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1577 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1574 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1571 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1568 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1565 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1562 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1558 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1556 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1553 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1550 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1547 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1545 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1542 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1539 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1536 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1533 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1531 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1528 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1526 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1523 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1520 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1518 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1516 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1513 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1511 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1508 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1506 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1503 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1501 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1499 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1497 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1495 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1492 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1490 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1488 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1486 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1483 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1481 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1479 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1477 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1475 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1473 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1471 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1469 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1467 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1465 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1463 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1461 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1459 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1458 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1456 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1454 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1452 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1450 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1449 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1447 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1445 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1443 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1442 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1440 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1438 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1437 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1435 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1434 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1432 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1430 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1429 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1427 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1425 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1424 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1423 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1421 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1420 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1418 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1417 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1415 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1414 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1413 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1411 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1410 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1409 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1407 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1406 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1405 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1403 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1402 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1401 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1399 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1398 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1397 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1396 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1395 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1394 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1392 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1391 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1390 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1389 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1388 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1387 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1385 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1385 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1384 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1382 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1381 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1380 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1379 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1378 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1377 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1376 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1375 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1374 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1373 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1372 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1371 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1370 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1370 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1369 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1368 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1367 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1366 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1365 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1364 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1363 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1362 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1361 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1361 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1360 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1359 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1358 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1358 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1357 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1356 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1355 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1355 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1354 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1353 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1352 - lr: 1.0880e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='di_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='di_bits_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "    def mc_evaluation(self, num_simulations=1000):\n",
        "        results = []\n",
        "        for _ in range(num_simulations):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            predictions = self.model(x_y_combined, training=False)\n",
        "            loss = self.loss_fn(y, predictions)\n",
        "            results.append(loss.numpy())\n",
        "        return np.mean(results), np.std(results)\n",
        "\n",
        "    def mdp_evaluation(self, policy, num_steps=100):\n",
        "        state = self.data_iterators.gen_data()[0]\n",
        "        total_reward = 0\n",
        "        for _ in range(num_steps):\n",
        "            action = policy(state)\n",
        "            next_state, reward = self.data_iterators.gen_data()\n",
        "            total_reward += reward.numpy()\n",
        "            state = next_state\n",
        "        return total_reward / num_steps\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Monte Carlo Evaluation\n",
        "mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "# MDP Evaluation\n",
        "def random_policy(state):\n",
        "    return tf.random.uniform(shape=state.shape, minval=0, maxval=1)\n",
        "\n",
        "mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2u9fOgpfOe58",
        "outputId": "51b6eba0-8562-44eb-cbf0-dfa1bf798e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.4741 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4598 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4454 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4314 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4175 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4040 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3904 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3773 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3646 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3515 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3386 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3286 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3170 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3053 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2947 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2836 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2718 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2601 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2488 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.2373 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.2232 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2122 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2023 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1894 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1746 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1688 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1531 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1415 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1271 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1110 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0971 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0798 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0684 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0555 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0324 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0214 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.0022 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.9839 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9688 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9422 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9240 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8937 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8766 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8542 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8276 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7874 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7582 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7303 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6963 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6765 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6370 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5957 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5384 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5147 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4890 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4545 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4149 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3880 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3585 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3310 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3026 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2791 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2552 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2344 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2135 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1933 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1729 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1528 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1342 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1156 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0981 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0811 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0654 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0493 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0341 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0191 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0042 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9902 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9754 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9615 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.9474 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9354 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9230 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9112 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8995 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8875 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8760 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8643 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8533 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8422 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8314 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8213 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8117 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8018 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7925 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7831 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7735 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7642 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7551 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7459 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7370 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7288 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7207 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7127 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7049 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6969 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6892 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6814 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6737 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6662 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6585 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6519 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6450 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6384 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6317 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6252 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6185 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6121 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6055 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5991 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5927 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5870 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5812 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5756 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5699 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5643 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5587 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5531 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5476 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5421 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5366 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5317 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5268 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5220 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5170 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5122 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5074 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5026 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4979 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4931 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4884 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4842 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4800 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4758 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4716 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4674 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4632 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4591 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4550 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4509 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4467 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4431 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4394 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4358 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4321 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4285 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4249 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4213 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4177 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4141 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4106 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4073 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4042 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4009 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3978 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3946 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3914 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3883 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3851 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3820 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3789 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3761 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3733 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3705 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3678 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3650 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3622 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3595 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3568 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3540 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3513 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3488 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3464 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3440 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3415 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3391 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3367 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3342 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3319 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3294 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3270 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3248 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3227 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3205 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3185 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3163 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3142 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3121 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3099 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3078 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3057 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3038 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3019 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3001 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2981 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2962 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2944 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2925 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2906 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2887 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2869 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2852 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2836 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2819 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2802 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2786 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2769 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2752 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2736 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2719 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2703 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2688 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2673 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2658 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2643 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2628 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2614 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2599 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2585 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2570 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2555 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2542 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2529 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2516 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2503 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2489 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2476 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2463 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2450 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2437 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2424 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2413 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2401 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2389 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2377 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2366 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2354 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2343 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2331 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2319 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2308 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2297 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2287 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2277 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2266 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2256 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2246 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2235 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2225 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2214 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2204 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2195 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2176 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2167 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2158 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2148 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2139 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2130 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2120 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2112 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2103 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2095 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2087 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2078 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2070 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2062 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2054 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2045 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2037 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2029 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2022 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2014 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2007 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2000 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1992 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1985 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1977 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1970 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1962 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1955 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1948 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1942 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1935 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1929 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1922 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1915 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1909 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1902 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1895 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1889 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1883 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1877 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1871 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1865 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1859 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1853 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1847 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1841 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1836 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1830 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1824 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1819 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1813 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1808 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1803 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1798 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1792 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1787 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1782 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1777 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1772 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1767 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1762 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1758 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1753 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1748 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1743 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1739 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1734 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1729 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1725 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1720 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1716 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1712 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1708 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1703 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1699 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1695 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1691 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1686 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1682 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1679 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1675 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1671 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1667 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1664 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1659 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1656 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1652 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1648 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1644 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1641 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1638 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1634 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1631 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1627 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1624 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1621 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1617 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1614 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1611 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1608 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1605 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1601 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1598 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1595 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1592 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1589 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1586 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1583 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1580 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1577 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1574 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1572 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1569 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1566 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1563 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1561 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1558 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1555 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1553 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1550 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1548 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1545 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1543 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1540 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1538 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1535 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1533 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1530 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1528 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1526 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1524 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1521 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1519 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1517 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1515 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1512 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1510 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1508 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1506 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1504 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1502 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1500 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1498 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1496 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1494 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1492 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1490 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1488 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1486 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1484 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1482 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1481 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1479 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1477 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1475 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1473 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1472 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1470 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1468 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1466 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1465 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1463 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1462 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1460 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1458 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1457 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1455 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1454 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1452 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1450 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1449 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1447 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1446 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1445 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1443 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1442 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1440 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1439 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1437 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1436 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1435 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1434 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1432 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1431 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1430 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1428 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1427 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1426 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1425 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1423 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1422 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1421 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1420 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1419 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1417 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1416 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1415 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1414 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1413 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1412 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1411 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1410 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1409 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1408 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1407 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1405 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1404 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1403 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1402 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1401 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1400 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1399 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1398 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1398 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1396 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1395 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1395 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1394 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1393 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1392 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1391 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1390 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1389 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1388 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1388 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1387 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1386 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1385 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1384 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1384 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1383 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1382 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1381 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1381 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1380 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1379 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1378 - lr: 1.0880e-06\n",
            "Monte Carlo Evaluation - Mean Loss: 3.0167188924679067e-07, Std Loss: 3.753410082740771e-11\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='di_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='di_bits_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "    def mc_evaluation(self, num_simulations=1000):\n",
        "        results = []\n",
        "        for _ in range(num_simulations):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            predictions = self.model(x_y_combined, training=False)\n",
        "            loss = self.loss_fn(y, predictions)\n",
        "            results.append(loss.numpy())\n",
        "        return np.mean(results), np.std(results)\n",
        "\n",
        "    def mdp_evaluation(self, policy, num_steps=100):\n",
        "        state = self.data_iterators.gen_data()[0]\n",
        "        total_reward = 0\n",
        "        for _ in range(num_steps):\n",
        "            action = policy(state)\n",
        "            next_state, reward = self.data_iterators.gen_data()\n",
        "            total_reward += reward.numpy()\n",
        "            state = next_state\n",
        "        return total_reward / num_steps\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.KLDivergence())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Monte Carlo Evaluation\n",
        "mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "# MDP Evaluation\n",
        "def random_policy(state):\n",
        "    return tf.random.uniform(shape=state.shape, minval=0, maxval=1)\n",
        "\n",
        "mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mXJEnPxaOfYW",
        "outputId": "9fe31876-eca7-41e0-a21d-f757b9370253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step - loss: 2.8339 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8156 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7975 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7799 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.7628 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7464 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7297 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7138 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6996 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6843 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6699 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6572 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6442 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6306 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6178 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6046 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5910 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.5781 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5646 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5488 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5350 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5218 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5100 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4936 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.4793 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4657 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4492 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4341 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4190 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3995 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3817 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3639 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3439 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3228 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3018 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2846 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2622 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.2358 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2111 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1904 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1564 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1321 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1015 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0638 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0286 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9994 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9659 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9217 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8852 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8321 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7924 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7611 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7157 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6836 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6514 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6128 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5807 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5496 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5215 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4923 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4637 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4393 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4154 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3939 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3716 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3495 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3289 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3079 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2876 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.2681 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.2480 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.2307 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2132 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1966 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1795 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1636 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1474 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.1317 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1158 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1000 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0848 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0707 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0575 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0446 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0310 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0178 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0052 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9925 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9798 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9674 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.9552 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9440 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9332 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9224 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9117 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9010 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8905 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8803 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8699 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8597 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8495 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8404 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8314 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8225 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8136 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8050 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7961 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.7874 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7788 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7702 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7619 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7541 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7466 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7392 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7317 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7243 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7168 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7095 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7023 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6951 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6879 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6814 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6750 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6686 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6623 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6559 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6497 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6434 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6371 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6310 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6248 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6193 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6137 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6083 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6028 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5973 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5920 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5866 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5813 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5759 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5706 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5658 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5611 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5563 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5516 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5469 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5422 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5375 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5329 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5283 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5236 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5195 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5154 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5112 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5071 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5031 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4990 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4949 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4909 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4868 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4828 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4791 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4756 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4720 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4684 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4648 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4612 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4577 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4541 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4506 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4471 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4439 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4407 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4376 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4345 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4313 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4283 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4251 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4220 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4188 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4157 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4129 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4102 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4075 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4047 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4019 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3991 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3964 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3937 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3909 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3881 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3857 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3833 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3808 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3784 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3759 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3735 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3711 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3686 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3662 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3639 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3617 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3595 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3573 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3552 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3530 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3509 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3487 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3465 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3444 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3423 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3404 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3384 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3365 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3346 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3327 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3308 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3289 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3270 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3251 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3232 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3214 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3198 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3181 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3164 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3147 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3130 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3113 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3096 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3079 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3062 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3047 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3032 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3017 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3002 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2987 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2972 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2956 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2942 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2926 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2911 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2898 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2884 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2871 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2857 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2844 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2830 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2817 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2804 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2790 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2777 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2765 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2753 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2741 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2729 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2717 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2705 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2693 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2681 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2669 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2657 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2647 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2636 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2625 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2614 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2604 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2593 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2582 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2572 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2560 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2550 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2541 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2531 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2521 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2512 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2502 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2493 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2483 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2473 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2464 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2455 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2446 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2438 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2429 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2421 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2412 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2403 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2394 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2386 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2378 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2369 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2361 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2354 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2346 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2338 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2331 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2323 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2316 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2308 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2300 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2293 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2286 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2279 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2272 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2265 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2258 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2252 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2245 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2238 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2231 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2224 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2218 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2212 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2206 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2199 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2193 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2187 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2181 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2175 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2169 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2163 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2157 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2152 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2146 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2141 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2136 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2130 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2124 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2119 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2113 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2108 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2103 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2098 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2093 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2088 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2083 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2078 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2073 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2068 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2063 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2058 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2054 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2050 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2045 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2041 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2036 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2032 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2027 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2023 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2019 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2014 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2010 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2006 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2002 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1998 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1994 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1990 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1986 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1982 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1978 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1975 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1971 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1967 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1964 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1960 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1957 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1953 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1949 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1946 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1942 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1939 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1936 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1932 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1929 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1926 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1923 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1920 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1916 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1913 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1910 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1907 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1904 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1901 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1898 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1895 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1892 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1889 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1887 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1884 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1881 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1878 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1875 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1873 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1870 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1868 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1865 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1862 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1860 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1857 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1855 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1852 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1850 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1847 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1845 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1843 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1841 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1838 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1836 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1833 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1831 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1829 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1827 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1825 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1822 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1820 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1819 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1816 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1814 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1812 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1810 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1808 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1806 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1804 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1802 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1801 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1799 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1797 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1795 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1793 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1791 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1789 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1788 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1786 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1784 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1782 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1781 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1779 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1778 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1776 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1774 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1772 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1771 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1769 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1768 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1766 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1765 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1763 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1762 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1760 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1759 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1757 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1756 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1755 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1753 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1751 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1751 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1749 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1748 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1746 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1745 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1743 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1742 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1741 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1740 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1739 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1737 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1736 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1735 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1734 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1733 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1731 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1730 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1729 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1728 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1727 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1726 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1725 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1724 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1722 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1722 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1720 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1719 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1718 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1717 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1716 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1715 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1714 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1713 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1712 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1711 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1710 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1710 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1709 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1708 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1707 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1706 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1705 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1704 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1703 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1702 - lr: 1.0880e-06\n",
            "Monte Carlo Evaluation - Mean Loss: 2.9816543678506946e-10, Std Loss: 5.77801966428898e-13\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='di_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='di_bits_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "    def mc_evaluation(self, num_simulations=1000):\n",
        "        results = []\n",
        "        for _ in range(num_simulations):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            predictions = self.model(x_y_combined, training=False)\n",
        "            loss = self.loss_fn(y, predictions)\n",
        "            results.append(loss.numpy())\n",
        "        return np.mean(results), np.std(results)\n",
        "\n",
        "    def mdp_evaluation(self, policy, num_steps=100):\n",
        "        state = self.data_iterators.gen_data()[0]\n",
        "        total_reward = 0\n",
        "        for _ in range(num_steps):\n",
        "            action = policy(state)\n",
        "            next_state, reward = self.data_iterators.gen_data()\n",
        "            total_reward += reward.numpy()\n",
        "            state = next_state\n",
        "        return total_reward / num_steps\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=negative_log_likelihood)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Monte Carlo Evaluation\n",
        "mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "# MDP Evaluation\n",
        "def random_policy(state):\n",
        "    return tf.random.uniform(shape=state.shape, minval=0, maxval=1)\n",
        "\n",
        "mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "# Final evaluation and reporting\n",
        "def final_evaluation(capacity_estimator):\n",
        "    # Monte Carlo Evaluation\n",
        "    mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "    print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "    # MDP Evaluation\n",
        "    mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "    print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "    return {\n",
        "        \"MC Mean Loss\": mean_loss,\n",
        "        \"MC Std Loss\": std_loss,\n",
        "        \"MDP Average Reward\": mdp_reward\n",
        "    }\n",
        "\n",
        "evaluation_results = final_evaluation(capacity_estimator)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EchE9-UeRK8l",
        "outputId": "7b5ad73d-da50-4ef9-ac5e-d95b1d3fa1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 7s 7s/step - loss: 2.8664 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8489 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8315 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8145 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7976 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7814 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7652 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7490 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7337 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7188 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7038 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6895 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6759 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.6610 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6479 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6323 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6180 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6019 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.5863 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5716 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5569 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5399 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5239 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.5096 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.4932 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4745 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4566 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.4392 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4161 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3967 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3738 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3555 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3329 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3114 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2878 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2596 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.2313 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2137 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.1797 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1482 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1081 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0713 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0558 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0132 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9750 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9406 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8984 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8675 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8227 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.7807 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7372 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6997 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.6657 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.6283 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5936 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5594 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5264 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4948 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4622 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4344 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4030 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3780 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3504 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3274 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3022 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2803 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2571 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2351 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2122 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1914 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1710 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1516 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.1334 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1154 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0975 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0807 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0634 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0466 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0301 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0138 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9975 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9830 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9691 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9548 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.9412 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9275 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9138 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9004 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8874 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8743 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.8614 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8499 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.8385 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8271 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8161 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8050 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7939 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7829 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7722 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7615 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7509 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7414 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7319 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7226 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7134 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7042 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6950 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6859 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6769 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6680 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6592 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6512 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6433 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6354 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6276 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6199 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6122 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6045 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5969 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5894 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5818 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5751 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5684 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5617 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5550 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5485 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5418 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5353 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5288 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5224 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5159 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5101 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5044 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4986 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4929 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4873 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4816 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4760 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4703 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4648 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4592 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4542 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4492 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4443 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4394 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4345 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4295 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4246 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4198 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4150 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4102 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4058 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4015 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3972 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3929 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3886 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3844 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3801 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3759 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3717 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3675 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3636 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3599 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3561 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3524 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3487 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3450 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3413 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3375 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3338 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3302 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3269 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3236 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3203 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3170 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3137 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3104 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3072 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3039 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3007 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2974 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2945 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2916 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2888 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2859 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2830 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2801 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2773 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2744 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2715 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2686 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2661 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2635 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2610 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2585 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2559 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2534 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2508 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2483 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2458 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2432 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2410 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2387 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2365 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2342 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2320 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2297 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2275 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2252 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2230 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2208 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2187 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2167 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2148 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2128 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2108 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2088 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2068 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2048 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2028 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2008 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1991 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1973 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1955 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1937 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1920 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1902 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1884 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1867 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1849 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1831 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1816 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1800 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1784 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1768 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1753 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1737 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1721 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1705 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1690 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1674 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1660 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1646 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1632 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1618 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1604 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1590 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1576 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1562 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1548 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1534 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1521 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1509 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1497 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1484 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1472 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1459 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1446 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1434 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1422 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1409 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1398 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1387 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1376 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1365 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1353 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1342 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1331 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1320 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1309 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1297 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1288 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1278 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1268 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1258 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1248 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1238 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1228 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1218 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1208 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1199 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1189 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1181 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1172 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1163 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1154 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1145 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1136 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1128 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1118 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1109 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1101 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1094 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1086 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1078 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1070 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1062 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1054 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1046 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1038 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1030 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1023 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1016 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1009 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1002 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0995 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0988 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0980 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0974 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0966 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0959 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0953 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0947 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0940 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0934 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0928 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0921 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0915 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0908 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0902 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0896 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0890 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0884 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0879 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0873 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0861 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0856 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0850 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0845 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0839 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0834 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0829 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0824 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0819 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0813 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0808 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0803 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0798 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0793 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0788 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0783 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0779 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0774 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0769 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0765 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0760 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0756 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0751 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0747 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0742 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0738 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0734 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0730 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0725 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0721 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0717 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0713 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0709 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0705 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0701 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0697 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0693 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0690 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0686 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0682 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0679 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0675 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0671 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0668 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0664 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0661 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0658 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0654 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0651 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0648 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0644 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0641 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0637 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0634 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0631 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0628 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0625 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0622 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0619 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0616 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0613 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0610 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0607 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0605 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0601 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0599 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0596 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0593 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0591 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0588 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0585 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0582 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0580 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0577 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0575 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0572 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0570 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0567 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0565 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0563 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0560 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0558 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0555 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0553 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0551 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0548 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0546 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0544 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0542 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0540 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0538 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0535 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0533 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0531 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0529 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0527 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0525 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0523 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0521 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0519 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0517 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0515 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0513 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0511 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0510 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0508 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0506 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0504 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0503 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0501 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0499 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0497 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0496 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0494 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0492 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0491 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0489 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0487 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0486 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0484 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0483 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0481 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0479 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0478 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0477 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0475 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0474 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0472 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0471 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0469 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0468 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0467 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0465 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0464 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0462 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0461 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0460 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0459 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0457 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0456 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0455 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0454 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0452 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0451 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0450 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0448 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0448 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0446 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0445 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0444 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0443 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0442 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0441 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0439 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0438 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0438 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0436 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0435 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0434 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0433 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0432 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0431 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0430 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0429 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0428 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0427 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0426 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0425 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0425 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0423 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0423 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0422 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0421 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0420 - lr: 1.0880e-06\n",
            "Monte Carlo Evaluation - Mean Loss: 3.3163348689413397e-07, Std Loss: 7.843239252514067e-11\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n",
            "Monte Carlo Evaluation - Mean Loss: 3.316307299883192e-07, Std Loss: 0.0\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logger = logging.getLogger(\"logger\")\n",
        "\n",
        "class ModelMetrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelMetrics, self).__init__(name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits')]\n",
        "\n",
        "    def update_state(self, t_y, t_xy, **kwargs):\n",
        "        t_y = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_y]\n",
        "        t_xy = [tf.convert_to_tensor(t, dtype=tf.float32) for t in t_xy]\n",
        "\n",
        "        if not isinstance(t_y, (list, tuple)) or len(t_y) < 2:\n",
        "            raise ValueError(\"Invalid t_y format. Expected lists with at least two elements.\")\n",
        "        if not isinstance(t_xy, (list, tuple)) or len(t_xy) < 2:\n",
        "            raise ValueError(\"Invalid t_xy format. Expected lists with at least two elements.\")\n",
        "\n",
        "        self.metric_pool[0].update_state(t_xy[0], t_xy[1])\n",
        "        self.metric_pool[1].update_state(t_y[0], t_y[1])\n",
        "        self.metric_pool[2].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "        self.metric_pool[3].update_state(t_y[0], t_y[1], t_xy[0], t_xy[1])\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class DV(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='dv_loss', **kwargs):\n",
        "        super(DV, self).__init__(name=name, **kwargs)\n",
        "        self.T = self.add_weight(name='t', initializer='zeros')\n",
        "        self.exp_T_bar = self.add_weight(name='exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, T, T_bar, **kwargs):\n",
        "        self.T.assign_add(tf.reduce_sum(T))\n",
        "        self.exp_T_bar.assign_add(tf.reduce_sum(T_bar))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss = self.T / self.global_counter - K.log(self.exp_T_bar / self.global_counter_ref)\n",
        "        return loss\n",
        "\n",
        "class DI(tf.keras.metrics.Metric):  # estimated DI calculation metric class\n",
        "    def __init__(self, name='di_loss', **kwargs):\n",
        "        super(DI, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return loss_xy - loss_y\n",
        "\n",
        "class DI_bits(tf.keras.metrics.Metric):  # estimated DI calculation metric class in bits\n",
        "    def __init__(self, name='di_bits_loss', **kwargs):\n",
        "        super(DI_bits, self).__init__(name=name, **kwargs)\n",
        "        self.c_T = self.add_weight(name='c_t', initializer='zeros')\n",
        "        self.c_exp_T_bar = self.add_weight(name='c_exp_t_bar', initializer='zeros')\n",
        "        self.xc_T = self.add_weight(name='xc_t', initializer='zeros')\n",
        "        self.xc_exp_T_bar = self.add_weight(name='xc_exp_t_bar', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "        self.global_counter_ref = self.add_weight(name='n_ref', initializer='zeros')\n",
        "\n",
        "    def update_state(self, c_T, c_T_bar, xc_T, xc_T_bar, **kwargs):\n",
        "        self.c_T.assign_add(tf.reduce_sum(c_T))\n",
        "        self.c_exp_T_bar.assign_add(tf.reduce_sum(c_T_bar))\n",
        "\n",
        "        self.xc_T.assign_add(tf.reduce_sum(xc_T))\n",
        "        self.xc_exp_T_bar.assign_add(tf.reduce_sum(xc_T_bar))\n",
        "\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(c_T.shape[:-1]), dtype=tf.float32))\n",
        "        self.global_counter_ref.assign_add(tf.cast(tf.reduce_prod(c_T_bar.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        loss_y = self.c_T / self.global_counter - K.log(self.c_exp_T_bar / self.global_counter_ref)\n",
        "        loss_xy = self.xc_T / self.global_counter - K.log(self.xc_exp_T_bar / self.global_counter_ref)\n",
        "        return (loss_xy - loss_y) / math.log(2)\n",
        "\n",
        "class PMF(tf.keras.metrics.Metric):  # estimated DV loss calculation metric class\n",
        "    def __init__(self, name='p_mean', **kwargs):\n",
        "        super(PMF, self).__init__(name=name, **kwargs)\n",
        "        self.p = self.add_weight(name='p', initializer='zeros')\n",
        "        self.global_counter = self.add_weight(name='n', initializer='zeros')\n",
        "\n",
        "    def update_state(self, p, **kwargs):\n",
        "        self.p.assign_add(tf.reduce_sum(p))\n",
        "        self.global_counter.assign_add(tf.cast(tf.reduce_prod(p.shape[:-1]), dtype=tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        result = self.p / self.global_counter\n",
        "        return result\n",
        "\n",
        "class ModelWithEncMetrics(ModelMetrics):\n",
        "    def __init__(self, writer, name='', **kwargs):\n",
        "        super(ModelWithEncMetrics, self).__init__(writer=writer, name=name, **kwargs)\n",
        "        self.writer = writer\n",
        "        self.metric_pool = [DV(name='dv_xy_{}'.format(name)),\n",
        "                            DV(name='dv_y_{}'.format(name)),\n",
        "                            DI(name='di_{}'.format(name)),\n",
        "                            PMF(name='p_mean'),\n",
        "                            DI_bits(name='di_bits_{}'.format(name))]\n",
        "\n",
        "    def update_state(self, data, **kwargs):\n",
        "        [t_y, t_xy, p] = data\n",
        "        self.metric_pool[0].update_state(t_xy, t_xy)\n",
        "        self.metric_pool[1].update_state(t_y, t_y)\n",
        "        self.metric_pool[2].update_state(t_y, t_y, t_xy, t_xy)\n",
        "        self.metric_pool[3].update_state(p)\n",
        "        self.metric_pool[4].update_state(t_y, t_y, t_xy, t_xy)\n",
        "\n",
        "    def result(self):\n",
        "        return [metric.result() for metric in self.metric_pool]\n",
        "\n",
        "    def reset_states(self):\n",
        "        for metric in self.metric_pool:\n",
        "            metric.reset_states()\n",
        "        return\n",
        "\n",
        "    def log_metrics(self, epoch, model_name):\n",
        "        with self.writer.as_default():\n",
        "            for metric in self.metric_pool:\n",
        "                tf.summary.scalar(metric.name, metric.result(), epoch)\n",
        "\n",
        "        msg = [\"{} Epoch: {:05d}\\t\".format(self.name, epoch)]\n",
        "        for metric in self.metric_pool:\n",
        "            if np.isnan(metric.result()):\n",
        "                raise ValueError(\"NaN appeared in metric {}\".format(metric.name))\n",
        "            msg.append(\"{:s} {:3.6f}\\t\".format(metric.name, float(metric.result())))\n",
        "        msg.append(model_name)\n",
        "        logger.info(\"\\t\".join(msg))\n",
        "\n",
        "class CapEstDI(object):\n",
        "    def __init__(self, model, data, config):\n",
        "        self.model = model\n",
        "        self.data_iterators = data\n",
        "        self.config = config\n",
        "        self.loss_fn = tf.keras.losses.Huber()\n",
        "        self.learning_rate = config['lr']\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
        "        self.metrics = ModelWithEncMetrics(tf.summary.create_file_writer(config['tensor_board_dir']), name='cap_est_metrics')\n",
        "        self.feedback = (config['feedback'] == 1)\n",
        "        self.T = config['T']\n",
        "        self.capacity_estimates = []\n",
        "        self.dine_estimates = []\n",
        "        self.info_rates = []\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        self.reset_model_states()\n",
        "\n",
        "        for _ in range(self.config['batches']):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = self.model(x_y_combined, training=True)\n",
        "                loss = self.loss_fn(y, predictions)\n",
        "            gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "            self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Training\")\n",
        "\n",
        "        # Store estimates\n",
        "        self.capacity_estimates.append(self.metrics.metric_pool[0].result().numpy())\n",
        "        self.dine_estimates.append(self.metrics.metric_pool[2].result().numpy())\n",
        "        self.info_rates.append(self.metrics.metric_pool[3].result().numpy())\n",
        "\n",
        "    def evaluate(self, epoch):\n",
        "        self.metrics.reset_states()\n",
        "        x, y = self.data_iterators.gen_data()\n",
        "        x_y_combined = tf.concat([x, y], axis=-1)\n",
        "        predictions = self.model(x_y_combined, training=False)\n",
        "        loss = self.loss_fn(y, predictions)\n",
        "        self.metrics.update_state([loss, loss, tf.random.uniform(shape=[self.config['batch_size'], 1], minval=0, maxval=1)])\n",
        "        self.metrics.log_metrics(epoch, model_name=\"Evaluation\")\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config.get('num_epochs', 500)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % self.config['eval_freq'] == 0:\n",
        "                self.evaluate(epoch)\n",
        "            self.train_epoch(epoch)\n",
        "\n",
        "        self.evaluate(num_epochs)\n",
        "\n",
        "    def reset_model_states(self):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'reset_states') and layer.stateful:\n",
        "                layer.reset_states()\n",
        "\n",
        "    def mc_evaluation(self, num_simulations=1000):\n",
        "        results = []\n",
        "        for _ in range(num_simulations):\n",
        "            x, y = self.data_iterators.gen_data()\n",
        "            x_y_combined = tf.concat([x, y], axis=-1)\n",
        "            predictions = self.model(x_y_combined, training=False)\n",
        "            loss = self.loss_fn(y, predictions)\n",
        "            results.append(loss.numpy())\n",
        "        return np.mean(results), np.std(results)\n",
        "\n",
        "    def mdp_evaluation(self, policy, num_steps=100):\n",
        "        state = self.data_iterators.gen_data()[0]\n",
        "        total_reward = 0\n",
        "        for _ in range(num_steps):\n",
        "            action = policy(state)\n",
        "            next_state, reward = self.data_iterators.gen_data()\n",
        "            total_reward += reward.numpy()\n",
        "            state = next_state\n",
        "        return total_reward / num_steps\n",
        "\n",
        "class Ising_Data(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.p_x = 0.4503\n",
        "        self.p_ch = 0.5\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.bptt = config['bptt']\n",
        "        self.ising_ch_logits = self.gen_logits(self.p_ch)\n",
        "        self.ising_x_logits = self.gen_logits(1 - self.p_x)\n",
        "        self.initialize_channel()\n",
        "\n",
        "    def gen_logits(self, p):\n",
        "        p_t = p * tf.ones(shape=[self.batch_size, 1], dtype=tf.float32)\n",
        "        p_bar_t = tf.ones_like(p_t) - p_t\n",
        "        logits = tf.math.log(tf.concat([p_bar_t, p_t], axis=1) + 1e-10)\n",
        "        return logits\n",
        "\n",
        "    def gen_data(self):\n",
        "        y_l = []\n",
        "        x_l = []\n",
        "        for t in range(self.bptt):\n",
        "            self.encoder()\n",
        "            x_l.append(self.x)\n",
        "            self.channel()\n",
        "            y_l.append(self.y)\n",
        "        x = tf.concat(x_l, axis=1)\n",
        "        y = tf.concat(y_l, axis=1)\n",
        "        return x, y\n",
        "\n",
        "    def initialize_channel(self):\n",
        "        for step in [0, 1]:\n",
        "            self.encoder(step)\n",
        "            self.channel(step)\n",
        "\n",
        "    def encoder(self, step=None):\n",
        "        if step == 0:\n",
        "            self.s_past = tf.zeros(shape=[self.batch_size, 1, 1], dtype=tf.float32)\n",
        "            self.x = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            self.x = tf.expand_dims(self.x, axis=-1)\n",
        "        elif step == 1:\n",
        "            self.x = self.x\n",
        "        else:\n",
        "            z = tf.cast(tf.random.categorical(logits=self.ising_x_logits, num_samples=1), dtype=tf.float32)\n",
        "            z = tf.expand_dims(z, axis=-1)\n",
        "            x_p = tf.math.floormod(self.x + z, 2)\n",
        "            x_new = tf.where(tf.equal(self.y, self.s_past), self.s, x_p)\n",
        "            self.x = x_new\n",
        "\n",
        "    def channel(self, step=None):\n",
        "        z = tf.cast(tf.random.categorical(logits=self.ising_ch_logits, num_samples=1), dtype=tf.float32)\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        if step == 0:\n",
        "            self.s = self.s_past\n",
        "        self.y = tf.where(tf.equal(z, 0), self.x, self.s)\n",
        "        self.s_past = self.s\n",
        "        self.s = self.x\n",
        "\n",
        "def complex_lstm_model_v3(input_shape, config):\n",
        "    randN_05 = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "    bias_init = tf.keras.initializers.Constant(0.01)\n",
        "\n",
        "    if config['compression_flag'] == 1:\n",
        "        DV_hidden = config['hidden_size_compression']\n",
        "    else:\n",
        "        DV_hidden = config['hidden_size']\n",
        "\n",
        "    max_norm = config['max_norm_y']\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, batch_size=config['batch_size'])\n",
        "    x = tf.keras.layers.LSTM(DV_hidden[0], return_sequences=True, stateful=True, dropout=config['dropout'], recurrent_dropout=config['dropout'])(inputs)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[1], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    x = tf.keras.layers.Dense(DV_hidden[2], activation=\"relu\", kernel_initializer=randN_05, bias_initializer=bias_init)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=config['output_activation'], kernel_initializer=randN_05, bias_initializer=bias_init, kernel_constraint=tf.keras.constraints.MaxNorm(max_value=max_norm))(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "class LossHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.lr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.lr.append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "def negative_log_likelihood(y_true, y_pred):\n",
        "    # Assuming y_pred is the probability distribution (e.g., output of a softmax layer)\n",
        "    return -tf.reduce_mean(tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-10), axis=-1))\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'GE_b': 0.0005,\n",
        "    'GE_g': 0.0015,\n",
        "    'GE_p_b': 0.5,\n",
        "    'GE_p_g': 0.02,\n",
        "    'T': 3,\n",
        "    'alphabet_size': 2,\n",
        "    'batch_size': 100,\n",
        "    'batch_size_eval': 5000,\n",
        "    'batches': 15,\n",
        "    'bptt': 6,\n",
        "    'channel_name': 'trapdoor',\n",
        "    'clip_grad_norm': 1,\n",
        "    'clip_grad_norm_enc': 0.2,\n",
        "    'clip_grad_norm_q': 100,\n",
        "    'clip_likelihood_ratio': [-10.0, 10.0],\n",
        "    'compression_flag': 0,\n",
        "    'config': './configs/capacity_estimation.json',\n",
        "    'contrastive_duplicates': 5,\n",
        "    'data_name': 'encoder',\n",
        "    'decay': 0,\n",
        "    'dropout': 0,\n",
        "    'dtype': 'binary',\n",
        "    'enc_dropout': 0.0,\n",
        "    'enc_hidden': [100, 50],\n",
        "    'enc_hidden_lstm': 50,\n",
        "    'enc_last_hidden': 1,\n",
        "    'eta_post': 0.5,\n",
        "    'eval_epoch_len': 500,\n",
        "    'eval_freq': 200,\n",
        "    'exp_name': 'cap_est',\n",
        "    'feedback': 1,\n",
        "    'hidden_size': [100, 150, 10],\n",
        "    'hidden_size_compression': [100, 2, 100],\n",
        "    'long_eval_epoch_len': 100,\n",
        "    'lr': 0.00019,\n",
        "    'lr_SGD': 0.2,\n",
        "    'max_norm_xy': 5,\n",
        "    'max_norm_y': 5,\n",
        "    'model_name': 'cap_est',\n",
        "    'noise_layer_q_std': 0.05,\n",
        "    'num_epochs': 500,  # Number of epochs set to 500\n",
        "    'optimizer': 'adam',\n",
        "    'p_bec': 0.3,\n",
        "    'p_bsc': 0.5,\n",
        "    'p_ising': 0.5,\n",
        "    'p_post': 0.5,\n",
        "    'p_trapdoor': 0.5,\n",
        "    'p_z': 0.9,\n",
        "    'q_lstm_units': 25,\n",
        "    'q_train_freq': 5,\n",
        "    'quiet': False,\n",
        "    'reset_channel': 0,\n",
        "    'run_name': 'ff',\n",
        "    's_alphabet': 2,\n",
        "    'seed': 468695,\n",
        "    'tag_name': 'temp_debugging',\n",
        "    'tensor_board_dir': './results/cap_est/encoder/ff/temp_debugging/2024-06-17_14-22-31_468695',\n",
        "    'train_epoch_len': 50,\n",
        "    'trainer_name': 'cap_est',\n",
        "    'using_wandb': 0,\n",
        "    'visualize_epoch_len': 50,\n",
        "    'weight_decay': 0.0,\n",
        "    'with_p': 0,\n",
        "    'x_dim': 1,\n",
        "    'y_im': 1,\n",
        "    'output_activation': 'linear'\n",
        "}\n",
        "\n",
        "# Initialize the data generator\n",
        "ising_data = Ising_Data(config)\n",
        "x, y = ising_data.gen_data()\n",
        "\n",
        "print(\"x data check:\", np.isnan(x).sum(), np.isinf(x).sum())\n",
        "print(\"y data check:\", np.isnan(y).sum(), np.isinf(y).sum())\n",
        "\n",
        "x_y_combined = tf.concat([x, y], axis=-1)\n",
        "\n",
        "input_shape = (config['bptt'], 2)\n",
        "complex_model_v3 = complex_lstm_model_v3(input_shape, config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'], clipnorm=1.0)\n",
        "complex_model_v3.compile(optimizer=optimizer, loss=tf.keras.losses.KLDivergence())\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.9\n",
        "    decay_step = 10\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# Train the model to capture the loss history\n",
        "complex_model_v3.fit(x_y_combined, y, epochs=config['num_epochs'], batch_size=config['batch_size'], callbacks=[callback, loss_history])\n",
        "\n",
        "# Initialize metrics\n",
        "writer = tf.summary.create_file_writer(config['tensor_board_dir'])\n",
        "metrics = ModelWithEncMetrics(writer, name='training_metrics')\n",
        "\n",
        "# Initialize the capacity estimation object\n",
        "capacity_estimator = CapEstDI(complex_model_v3, ising_data, config)\n",
        "\n",
        "# Training loop with learning rate scheduler\n",
        "for epoch in range(config['num_epochs']):\n",
        "    capacity_estimator.train_epoch(epoch)\n",
        "    metrics.update_state([tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32),\n",
        "                          tf.zeros_like(tf.convert_to_tensor(loss_history.losses[-1], dtype=tf.float32))])\n",
        "    metrics.log_metrics(epoch, model_name='Training')\n",
        "\n",
        "    if epoch % config['eval_freq'] == 0:\n",
        "        capacity_estimator.evaluate(epoch)\n",
        "\n",
        "# Monte Carlo Evaluation\n",
        "mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "# MDP Evaluation\n",
        "def random_policy(state):\n",
        "    return tf.random.uniform(shape=state.shape, minval=0, maxval=1)\n",
        "\n",
        "mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "# Final evaluation and reporting\n",
        "def final_evaluation(capacity_estimator):\n",
        "    # Monte Carlo Evaluation\n",
        "    mean_loss, std_loss = capacity_estimator.mc_evaluation(num_simulations=1000)\n",
        "    print(f\"Monte Carlo Evaluation - Mean Loss: {mean_loss}, Std Loss: {std_loss}\")\n",
        "\n",
        "    # MDP Evaluation\n",
        "    mdp_reward = capacity_estimator.mdp_evaluation(policy=random_policy, num_steps=100)\n",
        "    print(f\"MDP Evaluation - Average Reward: {mdp_reward}\")\n",
        "\n",
        "    return {\n",
        "        \"MC Mean Loss\": mean_loss,\n",
        "        \"MC Std Loss\": std_loss,\n",
        "        \"MDP Average Reward\": mdp_reward\n",
        "    }\n",
        "\n",
        "evaluation_results = final_evaluation(capacity_estimator)\n",
        "\n",
        "# Plotting loss and learning rate\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(range(len(loss_history.losses)), loss_history.losses, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(len(loss_history.lr)), loss_history.lr, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Training Loss and Learning Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the results for Capacity Estimate, DINE Estimate, and Information Rate\n",
        "epochs = list(range(config['num_epochs']))\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Capacity Estimate\n",
        "axs[0].plot(epochs, capacity_estimator.capacity_estimates, label='Capacity Estimate')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Capacity Estimate')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot DINE Estimate\n",
        "axs[1].plot(epochs, capacity_estimator.dine_estimates, label='DINE Estimate', color='orange')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('DINE Estimate')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot Information Rate\n",
        "axs[2].plot(epochs, capacity_estimator.info_rates, label='Information Rate', color='green')\n",
        "axs[2].set_xlabel('Epoch')\n",
        "axs[2].set_ylabel('Information Rate')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.suptitle('Capacity Estimate, DINE Estimate, and Information Rate over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cYSasFg8UPDp",
        "outputId": "1a041056-d0bc-4b32-a89a-9c2dbdd16d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x data check: 0 0\n",
            "y data check: 0 0\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step - loss: 2.1783 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1645 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1507 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1372 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1240 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1112 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0986 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0855 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0738 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0001900000061141327.\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0611 - lr: 1.9000e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00017100000550271944.\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0483 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0386 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0268 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0153 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0047 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9931 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9835 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9714 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9595 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00017100000695791095.\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9490 - lr: 1.7100e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00015390000626211986.\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9347 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.9262 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.9117 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9002 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8887 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8745 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8707 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8483 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8356 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.00015390000771731138.\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8182 - lr: 1.5390e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.00013851000694558026.\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8078 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7922 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7852 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7568 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7537 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7329 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7220 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6951 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6767 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0001385100040351972.\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6604 - lr: 1.3851e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00012465900363167748.\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6325 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6231 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5949 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.5588 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5589 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.5291 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4985 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4661 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4313 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0001246590109076351.\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4148 - lr: 1.2466e-04\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.00011219310981687158.\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3694 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3413 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.3175 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2758 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2460 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2158 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1701 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1429 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1070 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.00011219311272725463.\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.0780 - lr: 1.1219e-04\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.00010097380145452916.\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0552 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0279 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0043 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9823 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9623 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9431 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9265 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9060 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8888 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.00010097380436491221.\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8715 - lr: 1.0097e-04\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 9.087642392842099e-05.\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8556 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8407 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8268 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8128 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7976 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7845 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7711 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7579 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7452 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 9.087642683880404e-05.\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7326 - lr: 9.0876e-05\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 8.178878415492364e-05.\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7200 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7095 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6986 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6879 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6771 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6668 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6566 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6463 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6363 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 8.17887848825194e-05.\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6265 - lr: 8.1789e-05\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 7.360990639426745e-05.\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6166 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6080 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5994 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5907 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5823 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5738 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5659 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5576 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5496 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 7.360990275628865e-05.\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5416 - lr: 7.3610e-05\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.624891248065979e-05.\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5336 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5263 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5192 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5124 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5054 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4987 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4917 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4850 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4783 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.624891102546826e-05.\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4717 - lr: 6.6249e-05\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 5.962401992292144e-05.\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4650 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4590 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4531 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4475 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4416 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4360 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4301 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4247 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4190 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 5.9624020650517195e-05.\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4134 - lr: 5.9624e-05\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 5.366161858546548e-05.\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4079 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4027 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3979 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3931 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3881 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3832 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3785 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3737 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3690 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 5.366161713027395e-05.\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3643 - lr: 5.3662e-05\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 4.829545541724656e-05.\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3596 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3554 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3511 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3469 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3428 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3387 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3346 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3305 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3265 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 4.82954565086402e-05.\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3225 - lr: 4.8295e-05\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 4.346591085777618e-05.\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3185 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3148 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3112 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3076 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3041 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3005 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2971 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2936 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2901 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 4.34659123129677e-05.\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2866 - lr: 4.3466e-05\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 3.911932108167093e-05.\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2831 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2800 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2768 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2738 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2708 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2676 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2646 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2616 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2586 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 3.911932071787305e-05.\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2555 - lr: 3.9119e-05\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 3.520738864608575e-05.\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2525 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2499 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2472 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2445 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2418 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2392 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2365 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2340 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2313 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 3.5207387554692104e-05.\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2286 - lr: 3.5207e-05\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 3.16866487992229e-05.\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2260 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2237 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2213 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2189 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2167 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2143 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2120 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2097 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2074 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 3.1686649890616536e-05.\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2051 - lr: 3.1687e-05\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2028 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2007 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1986 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1966 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1946 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1925 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1905 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1885 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1865 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 2.8517984901554883e-05.\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1844 - lr: 2.8518e-05\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 2.5666186411399396e-05.\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1824 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1806 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1787 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1770 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1752 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1734 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1716 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1698 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1680 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 2.5666186047601514e-05.\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1662 - lr: 2.5666e-05\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 2.3099567442841362e-05.\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1644 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1628 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1612 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1596 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1580 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1564 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1548 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1532 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1517 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 2.3099568352336064e-05.\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1501 - lr: 2.3100e-05\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 2.078961151710246e-05.\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1485 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1471 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1457 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1443 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1429 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1414 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1401 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1387 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1373 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 2.0789611880900338e-05.\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1358 - lr: 2.0790e-05\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1345 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1332 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1320 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1307 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1295 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1282 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1270 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1257 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1245 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 1.8710650692810304e-05.\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1232 - lr: 1.8711e-05\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 1.6839585623529273e-05.\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1220 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1209 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1197 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1187 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1175 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1164 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1153 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1142 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1131 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 1.6839585441630334e-05.\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1120 - lr: 1.6840e-05\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1109 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1099 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1089 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1079 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1069 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1059 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1049 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1039 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1029 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 1.51556268974673e-05.\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1020 - lr: 1.5156e-05\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 1.3640064207720571e-05.\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1010 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1001 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0992 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0983 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0974 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0965 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0956 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0948 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0939 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 1.364006402582163e-05.\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0930 - lr: 1.3640e-05\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 1.2276057623239467e-05.\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0921 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0913 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0906 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0898 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0890 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0882 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0874 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0866 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0858 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 1.2276057532289997e-05.\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0850 - lr: 1.2276e-05\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 1.1048451779060998e-05.\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0842 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0835 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0829 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0821 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0814 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0807 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0800 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0793 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0786 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 1.1048451597162057e-05.\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0779 - lr: 1.1048e-05\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 9.943606437445851e-06.\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0772 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0766 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0760 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0753 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0747 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0741 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0735 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0728 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0722 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 9.943606528395321e-06.\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0716 - lr: 9.9436e-06\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 8.94924587555579e-06.\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0709 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0703 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0698 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0693 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0687 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0681 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0675 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0670 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0664 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 8.94924596650526e-06.\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0658 - lr: 8.9492e-06\n",
            "\n",
            "Epoch 301: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0653 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 302: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0648 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 303: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0642 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 304: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0638 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 305: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0633 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 306: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0627 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 307: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0622 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 308: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0617 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 309: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0612 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 310: LearningRateScheduler setting learning rate to 8.054321369854733e-06.\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0607 - lr: 8.0543e-06\n",
            "\n",
            "Epoch 311: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0602 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 312: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0597 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 313: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0593 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 314: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0589 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 315: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0584 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 316: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0580 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 317: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0574 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 318: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0570 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 319: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0566 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 320: LearningRateScheduler setting learning rate to 7.24888923286926e-06.\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0561 - lr: 7.2489e-06\n",
            "\n",
            "Epoch 321: LearningRateScheduler setting learning rate to 6.524000309582334e-06.\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0556 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 322: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0552 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 323: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0548 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 324: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0544 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 325: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0540 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 326: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0536 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 327: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0532 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 328: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0528 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 329: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0525 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 330: LearningRateScheduler setting learning rate to 6.524000127683394e-06.\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0520 - lr: 6.5240e-06\n",
            "\n",
            "Epoch 331: LearningRateScheduler setting learning rate to 5.871600114915055e-06.\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0516 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 332: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0512 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 333: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0509 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 334: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0505 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 335: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0501 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 336: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0498 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 337: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0494 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 338: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0490 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 339: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0487 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 340: LearningRateScheduler setting learning rate to 5.871600023965584e-06.\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0483 - lr: 5.8716e-06\n",
            "\n",
            "Epoch 341: LearningRateScheduler setting learning rate to 5.284440021569026e-06.\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0479 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 342: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0476 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 343: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0473 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 344: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0469 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 345: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0466 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 346: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0463 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 347: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0460 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 348: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0456 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 349: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0453 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 350: LearningRateScheduler setting learning rate to 5.28443979419535e-06.\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0450 - lr: 5.2844e-06\n",
            "\n",
            "Epoch 351: LearningRateScheduler setting learning rate to 4.755995814775815e-06.\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0446 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 352: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0444 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 353: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0441 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 354: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0438 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 355: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0435 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 356: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0432 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 357: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0429 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 358: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0426 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 359: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0423 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 360: LearningRateScheduler setting learning rate to 4.755995632876875e-06.\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0420 - lr: 4.7560e-06\n",
            "\n",
            "Epoch 361: LearningRateScheduler setting learning rate to 4.280396069589187e-06.\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0417 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 362: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0414 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 363: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0412 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 364: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0409 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 365: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0407 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 366: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0404 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 367: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0401 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 368: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0399 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 369: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0396 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 370: LearningRateScheduler setting learning rate to 4.280395842215512e-06.\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0393 - lr: 4.2804e-06\n",
            "\n",
            "Epoch 371: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0390 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 372: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0388 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 373: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0386 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 374: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0383 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 375: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0381 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 376: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0379 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 377: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0376 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 378: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0374 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 379: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0371 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 380: LearningRateScheduler setting learning rate to 3.852356257993961e-06.\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0369 - lr: 3.8524e-06\n",
            "\n",
            "Epoch 381: LearningRateScheduler setting learning rate to 3.467120632194565e-06.\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0367 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 382: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0365 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 383: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0363 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 384: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0360 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 385: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0358 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 386: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0356 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 387: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0354 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 388: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0352 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 389: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0350 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 390: LearningRateScheduler setting learning rate to 3.4671206776692998e-06.\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0347 - lr: 3.4671e-06\n",
            "\n",
            "Epoch 391: LearningRateScheduler setting learning rate to 3.12040860990237e-06.\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0346 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 392: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0343 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 393: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0342 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 394: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0339 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 395: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0338 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 396: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0336 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 397: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0334 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 398: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0332 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 399: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0330 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 400: LearningRateScheduler setting learning rate to 3.1204085644276347e-06.\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0328 - lr: 3.1204e-06\n",
            "\n",
            "Epoch 401: LearningRateScheduler setting learning rate to 2.8083677079848714e-06.\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 402: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0324 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 403: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0323 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 404: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0321 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 405: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0319 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 406: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0317 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 407: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0316 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 408: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0314 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 409: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0313 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 410: LearningRateScheduler setting learning rate to 2.8083677534596063e-06.\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0310 - lr: 2.8084e-06\n",
            "\n",
            "Epoch 411: LearningRateScheduler setting learning rate to 2.527530978113646e-06.\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0308 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 412: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0307 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 413: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0306 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 414: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0304 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 415: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0303 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 416: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0301 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 417: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0300 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 418: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0298 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 419: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0297 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 420: LearningRateScheduler setting learning rate to 2.5275310235883808e-06.\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0295 - lr: 2.5275e-06\n",
            "\n",
            "Epoch 421: LearningRateScheduler setting learning rate to 2.2747779212295426e-06.\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0293 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 422: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0292 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 423: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0290 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 424: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0289 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 425: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0288 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 426: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0286 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 427: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0284 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 428: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0283 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 429: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0282 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 430: LearningRateScheduler setting learning rate to 2.274777898492175e-06.\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0281 - lr: 2.2748e-06\n",
            "\n",
            "Epoch 431: LearningRateScheduler setting learning rate to 2.0473001086429576e-06.\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0279 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 432: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0278 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 433: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0277 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 434: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0275 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 435: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0274 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 436: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0273 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 437: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0272 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 438: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0270 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 439: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0269 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 440: LearningRateScheduler setting learning rate to 2.04730008590559e-06.\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0268 - lr: 2.0473e-06\n",
            "\n",
            "Epoch 441: LearningRateScheduler setting learning rate to 1.8425700773150312e-06.\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0266 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 442: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0265 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 443: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0265 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 444: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0263 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 445: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0262 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 446: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 447: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0260 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 448: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0258 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 449: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0258 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 450: LearningRateScheduler setting learning rate to 1.8425701000523986e-06.\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0256 - lr: 1.8426e-06\n",
            "\n",
            "Epoch 451: LearningRateScheduler setting learning rate to 1.6583130900471589e-06.\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0256 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 452: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0254 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 453: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0253 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 454: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0252 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 455: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0251 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 456: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0250 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 457: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0249 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 458: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0248 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 459: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0247 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 460: LearningRateScheduler setting learning rate to 1.6583130673097912e-06.\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0246 - lr: 1.6583e-06\n",
            "\n",
            "Epoch 461: LearningRateScheduler setting learning rate to 1.4924817605788121e-06.\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0245 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 462: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0244 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 463: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0243 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 464: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0242 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 465: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0242 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 466: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0240 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 467: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0239 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 468: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0239 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 469: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0238 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 470: LearningRateScheduler setting learning rate to 1.492481715104077e-06.\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0237 - lr: 1.4925e-06\n",
            "\n",
            "Epoch 471: LearningRateScheduler setting learning rate to 1.3432335435936694e-06.\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0236 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 472: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0235 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 473: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0234 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 474: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0233 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 475: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0233 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 476: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0232 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 477: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0231 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 478: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0230 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 479: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0229 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 480: LearningRateScheduler setting learning rate to 1.3432335208563018e-06.\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0228 - lr: 1.3432e-06\n",
            "\n",
            "Epoch 481: LearningRateScheduler setting learning rate to 1.2089101687706717e-06.\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0228 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 482: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0227 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 483: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0226 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 484: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0225 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0225 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0224 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0223 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0222 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 1.2089101346646203e-06.\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0221 - lr: 1.2089e-06\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 1.0880191211981583e-06.\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0220 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0220 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0219 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0218 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0218 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0217 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0216 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0215 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0215 - lr: 1.0880e-06\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 1.0880190757234232e-06.\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0214 - lr: 1.0880e-06\n",
            "Monte Carlo Evaluation - Mean Loss: 2.5052361962707437e-08, Std Loss: 2.923632169693491e-10\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n",
            "Monte Carlo Evaluation - Mean Loss: 2.504648399792586e-08, Std Loss: 3.552713678800501e-15\n",
            "MDP Evaluation - Average Reward: [[[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [1.]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5Vx3jgoYVc8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}